<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>15445 Project 1</title>
    <link href="/2023/07/09/15445/15445-project-1/"/>
    <url>/2023/07/09/15445/15445-project-1/</url>
    
    <content type="html"><![CDATA[<h2 id="buffer-pool-manager">Buffer Pool Manager</h2><h3 id="task-1">Task 1</h3><p>先看<a href="https://15445.courses.cs.cmu.edu/fall2022/project1/">官网</a>给出的描述：</p><p>在该项目的第一部分中，您将构建一个通用哈希表，使用无序的桶来存储唯一的键/值对。您的哈希表必须支持插入/删除键/值条目的能力，而无需指定表的最大大小。您的表需要根据需要逐步增长，但您不需要将其缩小。也就是说，您不需要实现缩小或压缩哈希表的支持。您还需要支持检查哈希表中是否存在一个键，并返回其相应的值。</p><p>我们鼓励您首先手动演示一些拆分和目录增长情况的小例子，然后再开始实现。</p><p>您必须在项目源代码中的指定文件中实现您的哈希表。您只允许修改哈希表头文件（<code>src/include/container/hash/extendible_hash_table.h</code>）及其相应的实现文件（<code>src/container/hash/extendible_hash_table.cpp</code>）。您不需要修改任何其他文件。您不得在实现中内部使用另一个内置哈希表。您必须在<code>ExtendibleHashTable</code>类中实现以下函数：</p><ul><li><code>Find(K，V)</code>：对于给定的键K，请检查它是否存在于哈希表中。如果存在，则将其相应值的指针存储在V中并返回true。如果键不存在，则返回false。</li><li><code>Insert(K，V)</code>：将键/值对插入哈希表中。如果键K已经存在，则用新值V覆盖其值并返回true。如果无法将键/值对插入桶中（因为桶已满且该键不是更新现有对），请在重试之前执行以下步骤：如果桶的局部深度等于全局深度，则增加全局深度并将目录的大小加倍。增加桶的局部深度。拆分桶并重新分配目录指针和桶中的kv对。某些实现将在插入后如果桶变满就拆分桶。但是对于这个项目，请检测桶是否溢出并在插入之前执行拆分。</li><li><code>Remove(K)</code>：对于给定的键K，请从哈希表中删除其相应的键/值对并返回true。如果键K不存在于哈希表中，则返回false。</li><li><code>GetGlobalDepth()</code>：返回整个哈希表的当前全局深度。</li><li><code>GetLocalDepth(dir_index)</code>：返回给定目录索引指向的桶的当前局部深度。</li><li><code>GetNumBuckets()</code>：返回哈希表中分配的桶的总数。</li></ul><p>您可以使用提供的<code>IndexOf(K)</code>私有函数来计算给定键散列到的目录索引。此外，我们提供了一个Bucket嵌套类，表示可扩展哈希表中的桶。首先按照代码文档完成<code>Bucket</code>类的<code>TODO</code>，可以更轻松地实现<code>ExtendibleHashTable</code>API。但是您可以随意编写自己的内部类/辅助函数。</p><p>您需要确保哈希表中的所有操作都是线程安全的，使用<code>std::mutex</code>。您需要决定如何保护数据结构。</p><p><code>Extendible Hash Table</code>与正常的线性哈希不同，我们采取分裂bucket的方式而不是让bucket线性增长，多个哈希槽位置可以指向同一个桶链。在拆分时重新整理桶中的条目，并增加要检查的位数。具体的来说，<code>Extendible Hash Table</code>的结构中会维护一个<code>global depth</code>来记录哈希表中最长的位数，对每个<code>bucket</code>结构会维护一个<code>local depth</code>，来记录该<code>bucket</code>的寻址位数，当<code>bucket</code>进行分裂时，<code>local depth</code>会增加，如果<code>local depth</code>超过了<code>global depth</code>，那么<code>global depth</code>会同时加一。</p><p>我们采取自底向上的方法进行实现，先来介绍<code>Extendible Hash Table</code>中<code>Bucket</code>的实现：</p><ul><li><p><code>Bucket</code>中维护一个<code>(key,value)</code>pair的<code>list</code>来存储数据，<code>size_</code>来记录<code>Bucket</code>中<code>(key,value)</code>pair的最大个数(<code>2^depth_</code>)，<code>depth_</code>来记录上述中记录<code>local depth</code>的大小</p></li><li><p><code>Find(k,v)</code>：在<code>Bucket</code>中给定key寻找value的方法，该方法实现较简单，对<code>list</code>中的pair进行遍历，如果寻找到相等的<code>key</code>则将对应的<code>value</code>返回并返回<code>true</code>，若没找到则返回<code>false</code></p></li><li><p><code>Remove(k)</code>：在<code>Bucket</code>中给定key删除对应的<code>(key,value)</code>pair，与<code>Find</code>类似，直接遍历，若找到相等的<code>key</code>则删除并返回<code>true</code>，否则遍历完成并返回<code>false</code></p></li><li><p><code>Insert(k,v)</code>：在<code>Bucket</code>中插入新的<code>(key,value)</code>pair，如果<code>list</code>为空，则直接插入并返回<code>true</code>；否则需要先遍历<code>Bucket</code>寻找是否该key已存在，若已存在更新即可；若不存在则需要判断<code>Bucket</code>是否已满，若未满直接插入并返回<code>true</code>即可；若已满需要返回<code>false</code>来通知上层需要分裂该<code>Bucket</code></p></li></ul><p>接下来我们介绍<code>Extendible Hash Table</code>的实现：</p><ul><li><code>Extendible Hash Table</code>维护一个<code>Bucket</code>的<code>vector</code>，一个控制并发操作的锁<code>latch</code>，一个记录<code>Bucket</code>数量的变量，记录<code>Bucket</code>最大size的变量以及一个<code>global depth</code></li><li><code>IndexOf(key)</code>&amp;<code>IndexOf(key,depth)</code>：这两个函数都是寻找<code>Bucket index</code>的函数，与PPT中的寻址方法相同，直接匹配前<code>depth</code>/<code>global depth</code>的位数来寻址即可</li><li><code>GetDepth</code>一类的函数(包括<code>local depth</code>/<code>global depth</code>等)：这类函数获取<code>depth</code>的值，需要注意的是，<code>depth</code>的值是会因为<code>Bucket</code>的分裂而动态变化的，由于我们需要考虑并发操作，所以在访问无论是<code>global depth</code>还是<code>local depth</code>时都需要对<code>latch</code>进行上锁，再进行访问；访问<code>local depth</code>时就到对应的<code>Bucket</code>中读取数据即可</li><li><code>Find(k,v)</code>：该函数在哈希表中寻找key对应的value，同样的，由于<code>Bucket</code>中的数据在动态变化，所以在查找前需要对整个哈希表上锁，然后对<code>key</code>进行对应的<code>Bucket</code>编号查找，找到对应的<code>Bucket</code>后调用<code>Bucket</code>的Find函数进行查找即可</li><li><code>Remove(key)</code>：与<code>Find(k,v)</code>同理</li><li><code>Insert(k,v)</code>：该函数向哈希表中插入一个<code>(key,value)</code>pair，这个函数应该是哈希表中<strong>最复杂</strong>的一个函数了。首先由于我们需要对表中数据进行修改，所以需要对整个哈希表上锁；在插入之前，我们需要对<code>Bucket</code>是否已满进行判断，若已满则需要进行分裂处理，(需要注意的是，在极端情况下分裂处理是需要递归进行的，因为我们分裂的方法是继续看<code>key</code>的下一位bit的值，而此时有可能<code>Bucket</code>中下一位bit都是相同的，这时候就需要递归进行处理，但这样的递归总有尽头，直到剩余bits的位数小于等于<code>Bucket</code>中个数时，一定会出现不满的<code>Bucket</code>，这时即可进行插入)<ul><li>不需要分裂(要插入的<code>Bucket</code>非满)：直接调用<code>Bucket</code>的插入进行插入即可</li><li>需要分裂(要插入的<code>Bucket</code>已满)：若目标<code>Bucket</code>的深度已经达到<code>global depth</code>，则需要扩展整个哈希表的<code>global depth</code>并扩大<code>Bucket vector</code>；然后建两个新<code>Bucket</code>，把原<code>Bucket</code>中的元素按照key下一位bit的不同分别插入到两个<code>Bucket</code>中，最后把两个<code>Bucket</code>按照索引位的不同放到<code>Bucket vector</code>的相应位置中</li></ul></li></ul><h3 id="task-2">Task 2</h3><p>先看<a href="https://15445.courses.cs.cmu.edu/fall2022/project1/">官网</a>给出的描述：</p><p>该组件负责跟踪缓冲池中页面的使用情况。您将在<code>src/include/buffer/lru_k_replacer.h</code>中实现一个名为<code>LRUKReplacer</code>的新类，以及其相应的实现文件<code>src/buffer/lru_k_replacer.cpp</code>。请注意，<code>LRUKReplacer</code>是一个独立的类，与其他Replacer类无关。您只需要实现<code>LRU-K</code>替换策略，不需要实现<code>LRU</code>或时钟替换策略，即使有相应的文件也不需要。</p><ul><li><p><code>LRU-K</code>算法会淘汰最长时间未被访问的页框。后向<code>k</code>距离是指当前时间戳与第k次之前访问的时间戳之间的时间差。如果一个页框历史访问次数小于<code>k</code>，则将其后向k距离设为正无穷。当有多个页框的后向k距离都是正无穷时，替换器会淘汰时间戳最早的那个页框。</p></li><li><p><code>LRUKReplacer</code>的最大大小与缓冲池的大小相同，因为它包含了<code>BufferPoolManager</code>中所有页框的占位符。然而，在任何时刻，替换器中不是所有的页框都被视为可淘汰的。<code>LRUKReplacer</code>的大小由可淘汰的页框数量表示。<code>LRUKReplacer</code>被初始化为不含任何页框。只有当一个页框标记为可淘汰时，替换器的大小才会增加。</p></li></ul><p>您需要实现课堂上讨论的<code>LRU-K</code>策略。您需要实现以下方法：</p><ul><li><p><code>Evict(frame_id_t*)</code>：从替换器中淘汰后向k距离与其他可淘汰的页框中最大的那个页框。将页框的id存储在输出参数中并返回True。如果没有可淘汰的页框，则返回False。</p></li><li><p><code>RecordAccess(frame_id_t)</code>：记录给定页框id在当前时间戳下被访问。在<code>BufferPoolManager</code>中固定页面后，应调用此方法。</p></li><li><p><code>Remove(frame_id_t)</code>：清除与页框关联的所有访问历史记录。仅在<code>BufferPoolManager</code>中删除页面时调用此方法。</p></li><li><p><code>SetEvictable(frame_id_t, bool set_evictable)</code>：此方法控制页框是否可淘汰。它还控制<code>LRUKReplacer</code>的大小。当页的引用计数达到0时，对应的页框被标记为可淘汰，并增加替换器的大小。</p></li><li><p><code>Size()</code>：此方法返回当前<code>LRUKReplacer</code>中可淘汰的页框数量。</p></li></ul><p><code>LRU-K</code>算法简介：</p><p><code>LRU-K</code>算法是一种页面替换算法，它通过记录缓存数据被访问的历史来判断哪些数据最有可能被淘汰。在<code>LRU-K</code>算法中，<code>K</code>代表最近使用的次数。与<code>LRU</code>算法不同的是，<code>LRU-K</code>算法将“最近使用过1次”的判断标准扩展为“最近使用过<code>K</code>次”，从而解决了<code>LRU</code>算法中可能出现的“缓存污染”的问题。</p><p><code>LRU-K</code>算法需要维护一个访问历史队列，用于记录缓存数据被访问的历史。当一个数据第一次被访问时，它会被加入到访问历史队列中。如果一个数据在访问历史队列中的访问次数没有达到<code>K</code>次，则按照一定规则（例如<code>FIFO</code>或<code>LRU</code>）淘汰。当一个数据的访问次数达到<code>K</code>次后，它将被移到缓存队列中，并缓存此数据。缓存队列会按照时间排序，以便淘汰最久未使用的数据。</p><p>当需要淘汰数据时，<code>LRU-K</code>算法会淘汰缓存队列中排在末尾的数据，即“倒数第<code>K</code>次访问离现在最久”的数据。当一个数据再次被访问时，它会被重新排序，以确保最近使用的数据总是在缓存队列的前面。</p><p>总的来说，<code>LRU-K</code>算法是一种比较复杂的页面替换算法，但它能够更准确地判断哪些数据最有可能被淘汰，从而提高了缓存系统的性能。</p><p>具体实现方法：</p><ul><li><code>LRUKReplacer</code>维护的数据包括：一个记录每个页对应的访问次数的<code>map</code>；上文中提到的一个历史队列、一个缓存队列；缓存队列和历史队列都需要的一个页号对应迭代器的<code>map</code>；一个记录每个页是否可以被换出的<code>map</code>；记录<code>LRU-K</code>的<code>K</code>值；此时包含的页数<code>size</code>；一个保持安全并发操作的锁<code>latch</code>(<strong>需要强调的是，LRU-K替换器本身就是一个公共资源，所以在执行任何操作时都需要加锁，下文的操作中不再赘述</strong>)；一个<code>replacer_size</code></li><li><code>Evict(frame_id_t*)</code>：该函数换出<code>LRU-K</code>策略选出的页，若无页可选直接返回<code>false</code>；在有页可选的情况下，我们优先从历史队列中挑选可被换出的页，直接从历史队列队尾回溯选择，若可换出则在历史队列中将该项移除，历史队列的map中溢出，记录访问次数设置为0，并设置不可换出并减少当前的<code>size</code>，返回<code>true</code>；若历史队列中无可换出的页，则遍历缓存队列(遍历方向相同)，操作也相同；若均无可换出的页，则返回<code>false</code></li><li><code>RecordAccess(frame_id_t)</code>：若<code>frame_id</code>超过了<code>replacer</code>的<code>size</code>，说明是非法页框号，需要特殊处理，否则开始访问记录，先增加对应<code>frame</code>的访问计数，若访问计数达到<code>k</code>次则需要在缓存队列/map中删除，并添加到历史队列/map中；若访问计数大于<code>k</code>次，则需要将其移到队尾；若访问计数未达到<code>k</code>次，则需要移动到缓存队列的队尾</li><li><code>SetEvictable(frame_id_t, bool set_evictable)</code>：该函数设置该<code>frame</code>是否可以被换出，若可换出则<code>set_evictable=true</code>，反之为<code>false</code>，同理，若<code>frame_id</code>超过了<code>replacer</code>的<code>size</code>，说明是非法页框号，需要特殊处理，若访问次数为0，则不需要设置；若此时状态不可换出并设置可换出，则需要增加当前的<code>size</code>；若次数状态可换出且要设置不可换出，则需要减小<code>size</code>；最后设置是否可换出为<code>set_evictable</code>即可</li><li><code>Remove(frame_id_t)</code>：若<code>frame_id</code>超过了<code>replacer</code>的<code>size</code>，说明是非法页框号，需要特殊处理，否则开始执行删除，若访问次数为0可直接返回无需删除；若不可换出则直接抛出异常；剩下的工作就是在历史/缓存队列和map中删除对应的项，减小当前<code>size</code>，初始化count和是否可换出即可</li><li><code>Size()</code>：由于我们维护了当前的<code>size</code>，所以直接返回即可</li></ul><h3 id="task-3">Task 3</h3><p>先看<a href="https://15445.courses.cs.cmu.edu/fall2022/project1/">官网</a>给出的描述：</p><p>最后，您需要在系统中实现缓冲池管理器（<code>BufferPoolManagerInstance</code>）。<code>BufferPoolManagerInstance</code>负责从<code>DiskManager</code>中获取数据库页面并将其存储在内存中。当需要为新页面腾出空间时，<code>BufferPoolManagerInstance</code>也可以将脏页面写回磁盘，或者在明确指示时进行写回。</p><p>为确保您的实现与系统的其余部分正确配合，我们将为您提供一些已填充的函数。您也不需要实现实际读写数据到磁盘的代码（在我们的实现中称为<code>DiskManager</code>），我们将为您提供该功能。</p><p>系统中的所有内存页面都由<code>Page</code>对象表示。<code>BufferPoolManagerInstance</code>不需要理解这些页面的内容。但是，作为系统开发人员，了解<code>Page</code>对象只是缓冲池中内存的容器，因此不属于唯一的页面是很重要的。也就是说，每个<code>Page</code>对象包含一块内存块，<code>DiskManager</code>将使用该内存块作为从磁盘读取的物理页面内容的位置。<code>BufferPoolManagerInstance</code>将重用相同的<code>Page</code>对象来存储数据，因为它在磁盘和内存之间来回移动。这意味着同一个<code>Page</code>对象可能在系统的整个生命周期内包含不同的物理页面。<code>Page</code>对象的标识符（<code>page_id</code>）跟踪它包含的物理页；如果<code>Page</code>对象不包含物理页，则必须将其<code>page_id</code>设置为<code>INVALID_PAGE_ID</code>。</p><p>每个<code>Page</code>对象还维护一个计数器，用于记录“固定”该页面的线程数。您的<code>BufferPoolManagerInstance</code>不允许释放被固定的<code>Page</code>。每个<code>Page</code>对象还跟踪它是否是脏的。您的任务是在取消固定<code>Page</code>之前记录页面是否已修改。在可以重复使用该对象之前，您的<code>BufferPoolManagerInstance</code>必须将脏<code>Page</code>的内容写回磁盘。</p><p>您的<code>BufferPoolManagerInstance</code>实现将使用您在先前步骤中创建的<code>ExtendibleHashTable</code>和<code>LRUKReplacer</code>类。它将使用<code>ExtendibleHashTable</code>来映射<code>page_id</code>到<code>frame_id</code>的表。它还将使用<code>LRUKReplacer</code>来跟踪<code>Page</code>对象的访问时间，以便在必须释放帧以为从磁盘复制新的物理页面时决定哪个页面被淘汰。</p><p>您需要在源文件（<code>src/buffer/buffer_pool_manager_instance.cpp</code>）中实现头文件（<code>src/include/buffer/buffer_pool_manager_instance.h</code>）中定义的以下函数：</p><ul><li><code>FetchPgImp(page_id)</code></li><li><code>UnpinPgImp(page_id, is_dirty)</code></li><li><code>FlushPgImp(page_id)</code></li><li><code>NewPgImp(page_id)</code></li><li><code>DeletePgImp(page_id)</code></li><li><code>FlushAllPagesImpl()</code></li></ul><p>对于<code>FetchPgImp</code>函数，如果在空闲列表中没有可用页面且所有其他页面当前都被固定，则应返回<code>nullptr</code>。<code>FlushPgImp</code>应该无论页面的固定状态如何都会刷新页面。</p><p>对于<code>UnpinPgImp</code>，<code>is_dirty</code>参数跟踪页面在固定期间是否被修改。</p><p><code>AllocatePage</code>私有方法为<code>BufferPoolManager</code>提供一个新的唯一页面标识符，当您想在<code>NewPgImp()</code>中创建新页面时使用。另一方面，<code>DeallocatePage()</code>方法是一个仿真在磁盘上释放页面的无操作，您应该在<code>DeletePgImp()</code>实现中调用此方法。</p><p><code>BufferPoolManager</code>的具体实现方法如下：</p><ul><li><code>BufferPoolManager</code>要维护的数据包括：一个常量缓冲池的大小；一个原子页id记录下一个页面id；一个常量记录哈希表的<code>Bucket</code>大小；一个存储页面的数组；一个从物理页号映射到缓冲池帧号的可扩展哈希表；一个<code>LRU-K</code>替换器；一个用来管理并发操作的锁(<strong>与Task2相同，每个操作都在改写公共资源<code>BufferPoolManager</code>的内容，所以几乎每个操作都需要加锁，后面不特殊说明的话就说明该操作是需要上锁的</strong>)；一个<code>list</code>记录空闲帧；一个磁盘管理器来负责将数据向磁盘出读入/写回</li><li><code>NewPgImp(page_id)</code>：该函数在缓冲池中新建一个page，若空闲帧<code>list</code>非空，则存在空闲帧，可以在空闲帧中存放page，从队尾取出一个空闲帧；若空闲帧<code>list</code>为空，则不存在空闲帧，先判断是否所有页面均已被占用(<code>pin count &gt; 0</code>)，若是则无法新建，返回<code>false</code>，若不是则换出一个未被任何进程<code>pin</code>过的页面(若该页为脏页则需要<code>disk manager</code>将内容写回磁盘)，从页表中删除原page并添加新page并将该页在<code>BufferPoolManager</code>中进行初始化即可，而且需要注意的是，我们需要在此处对该帧进行<code>RecordAccess</code>，因为我们对该帧进行了替换操作(无论之前是否在空闲帧<code>list</code>中)</li><li><code>FetchPgImp(page_id)</code>：该函数从磁盘中调入一个页号为<code>page_id</code>的页，若该页未在<code>BufferPool</code>中，需要找到一个帧(优先考虑空闲帧，最大化缓冲池的利用率)，找到可换的帧后将页换出(若该页为脏页则需要<code>disk manager</code>将内容写回磁盘)，重新初始化刚刚选取的帧，调用<code>disk manager</code>将该页换到帧中并设置页表项即可；若该页已在缓冲池中(注：换回页后也同样需要这个操作)，该操作需要记录<code>RecordAccess</code>，设置<code>pin count</code>表明上级调用正在使用该<code>page</code>，并将该<code>page</code>返回即可</li><li><code>UnpinPgImp(page_id, is_dirty)</code>：该函数取消页的<code>pin</code>状态，<code>is_dirty</code>参数记录该页是否被修改，首先需要确定该页是否在缓冲池中，若该页不在缓冲池中或<code>pin count &lt;= 0</code>，则无需取消<code>pin</code>状态，直接返回<code>false</code>即可；否则将该页维护的<code>pin count--</code>即可；若<code>pin count</code>变为0，则需要设定可被替换状态；若<code>is_dirty</code>参数为<code>true</code>，则需要改变该页是否为脏页的状态，需要注意的是，如果<code>is_dirty</code>为<code>false</code>则不需要执行任何操作，因为有可能其他进程修改了页面，该进程未进行改变，最后返回<code>true</code>即可</li><li><code>FlushPgImp(page_id)</code>：该函数的作用是将给定页号的页写回磁盘，若该页不在缓冲池中，则无需做任何操作，直接返回<code>false</code>即可；若该页对应的帧号不合法也返回<code>false</code>；否则为合法情况，将页写回磁盘并设置<code>is_dirty</code>为<code>false</code>并返回<code>true</code>即可</li><li><code>FlushAllPagesImpl()</code>：该函数将所有页写回内存，遍历页数组执行<code>FlushPgImp</code>即可，<strong>需要注意的是这个操作无需上锁</strong>，因为每个<code>FlushPgImp</code>都会上锁并进行写操作，而且按照并发执行的语义来说，写回后的页就可以为后续进程所用，无需对写回后的page进行阻塞了</li><li><code>DeletePgImp(page_id)</code>：该函数删除参数页号对应的页，若不在缓存池中则无需删除，直接返回<code>true</code>即可；若在缓冲池中但仍处于<code>pin</code>状态，则无法删除，返回<code>false</code>；若在缓冲池中但处于<code>unpin</code>状态，则从页表中删除该页，执行初始化并将帧放回空闲帧<code>list</code>即可</li></ul>]]></content>
    
    
    <categories>
      
      <category>database</category>
      
    </categories>
    
    
    <tags>
      
      <tag>database</tag>
      
      <tag>15445</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>cs188 lecture8</title>
    <link href="/2023/01/21/CS188/cs188-lec8/cs188-lec8/"/>
    <url>/2023/01/21/CS188/cs188-lec8/cs188-lec8/</url>
    
    <content type="html"><![CDATA[<h2 id="reinforcement-learning">Reinforcement Learning</h2><ul><li>Basic idea:<ul><li>Receive feedback in the form of <strong>rewards</strong></li><li>Agent's utility is defined by the reward function</li><li>Must (learn to) act so as to <strong>maximize expectedrewards</strong></li><li>All learning is based on observed samples of outcomes</li></ul></li></ul><h3 id="model-based-learning">Model-Based Learning</h3><ul><li>Model-Based Idea:<ul><li>Learn an approximate model based on experiences</li><li>Solve for values as if the learned model were correct</li></ul></li><li>Step 1: Learn empirical MDP model<ul><li>Count outcomes s' for each s,a</li><li>Normalize to give an estimate of <span class="math inline">\(\hat{T}(s,a,s&#39;)\)</span></li><li>Discover each <span class="math inline">\(\hat{R}(s,a,s&#39;)\)</span> when we experience<span class="math inline">\((s,a,s&#39;)\)</span></li></ul></li><li>Step 2: Solve the learned MDP</li></ul><h3 id="passive-reinforcement-learning">Passive ReinforcementLearning</h3><ul><li>Simplified task: policy evaluation<ul><li>Input: a fixed policy <span class="math inline">\(\pi(s)\)</span></li><li>You don't know the transitions <span class="math inline">\(T(s,a,s&#39;)\)</span></li><li>You don't know the rewards <span class="math inline">\(R(s,a,s&#39;)\)</span></li><li><strong>Goal: learn the state values</strong></li></ul></li><li>In this case:<ul><li>Learner is "along for the ride"</li><li>No choice about what actions to take</li><li>Just execute the policy and learn from experience</li><li>This is NOT offline planning! You actually take actions in theworld.</li></ul></li></ul><h4 id="direct-evaluation">Direct Evaluation</h4><ul><li>Goal: Compute values for each state under <span class="math inline">\(\pi\)</span></li><li>Idea: Average together observed sample values<ul><li>Act according to <span class="math inline">\(\pi\)</span></li><li>Every time you visit a state, write down what the sum of discountedrewards turned out to be</li><li>Average those samples</li></ul></li><li>This is called direct evaluation</li></ul><h4 id="problems-with-direct-evaluation">Problems with DirectEvaluation</h4><ul><li>Good about direct evaluation:<ul><li>It's easy to understand</li><li>It doesn't require any knowledge of T,R</li><li>It eventually computes the correct average values, using just sampletransitions</li></ul></li><li>Bad about direct evaluation:<ul><li>It wastes information about state connections</li><li>Each state must be learned separately</li><li>So, it takes a long time to learn</li></ul></li></ul><p>The reason why we can't use policy evaluation is we don't know <span class="math inline">\(T,R\)</span> to update <span class="math inline">\(V\)</span></p><h4 id="temporal-difference-learning">Temporal Difference Learning</h4><ul><li>Big idea: learn from every experience!<ul><li>Update <span class="math inline">\(V(s)\)</span> each time weexperience a transition <span class="math inline">\((s,a,s&#39;,r)\)</span></li><li>Likely outcomes s' will contributes updates more often</li></ul></li><li>Temporal difference learning of values<ul><li>Policy still fixed, still doing evaluation!</li><li>Move values toward value of whatever successor occurs: runningaverage<ul><li>Sample of <span class="math inline">\(V(s)\)</span>: <span class="math inline">\(sample = R(s,\pi(s),s&#39;) + \gammaV^{\pi}(s&#39;)\)</span></li><li>Update to <span class="math inline">\(V(s)\)</span>: <span class="math inline">\(V^{\pi}(s) \leftarrow (1 - \alpha)V^{\pi}(s) +(\alpha)sample\)</span></li><li>Same update: <span class="math inline">\(V^{\pi}(s) \leftarrowV^{\pi}(s) + \alpha(sample - V^{\pi}(s))\)</span></li></ul></li></ul></li></ul><h4 id="exponential-moving-average">Exponential Moving Average</h4><ul><li><p>Exponential moving average</p><ul><li><p>The running interpolation update: <span class="math inline">\(\bar{x}_n = (1 - \alpha)\cdot \bar{x}_{n - 1} +\alpha \cdot x_n\)</span></p></li><li><p>Makes recent samples more important <span class="math display">\[\bar{x}_n = \frac{x_n + (1 - \alpha) \cdot x_{n - 1} + (1 - \alpha)^2\cdot x_{n - 2} + ...}{1 + (1 - \alpha) + (1 - \alpha)^2 + ...}\]</span></p></li><li><p>Forgets about the past(distant past values were wronganyway)</p></li></ul></li><li><p>Decreasing learning rate (alpha) can give convergingaverages</p></li></ul><h4 id="problems-with-td-value-learning">Problems with TD ValueLearning</h4><ul><li><p>TD value learning is a model-free way to do policy evaluation,mimicking Bellman updates with running sample averages</p></li><li><p>However, if we want to turn values into a (new) policy, we'resunk: <span class="math display">\[\begin{align*}\pi(s) &amp;= arg\,max_a Q(s,a) \\Q(s,a) &amp;= \sum_{s&#39;}T(s,a,s&#39;)[R(s,a,s&#39;) + \gammaV(s&#39;)]\end{align*}\]</span></p></li><li><p>Idea: learn Q-values, not values</p></li><li><p>Makes action selection model-free too!</p></li></ul><h3 id="active-reinforcement-learning">Active ReinforcementLearning</h3><ul><li>Full reinforcement learning: optimal policies (like value iteration)<ul><li>You don't know the transitions <span class="math inline">\(T(s,a,s&#39;)\)</span></li><li>You don't know the rewards <span class="math inline">\(R(s,a,s&#39;)\)</span></li><li>You choose the actions now</li><li><strong>Goal: learn the optimal policy/ values</strong></li></ul></li><li>In this case:<ul><li>Learner makes choices!</li><li>Fundamental tradeoff: exploration vs. exploitation</li><li>This is NOT offline planning! You actually take actions in the worldand find out what happens...</li></ul></li></ul><h4 id="q-learning">Q-learning</h4><ul><li><p>Q-Learning: sample-based Q-value iteration <span class="math display">\[Q_{k + 1}(s,a) \leftarrow \sum_{s&#39;}T(s,a,s&#39;)[R(s,a,s&#39;) +\gamma max_{a&#39;}Q_k(s&#39;,a&#39;)]\]</span></p></li><li><p>Learn <span class="math inline">\(Q(s,a)\)</span> values as yougo</p><ul><li><p>Receive a sample (s,a,s',r)</p></li><li><p>Consider your old estimate: <span class="math inline">\(Q(s,a)\)</span></p></li><li><p>Consider your new sample estimate: <span class="math display">\[sample = R(s,a,s&#39;) + \gamma max_{a&#39;}(s&#39;,a&#39;)\]</span></p></li><li><p>Incorporate the new estimate into a running average: <span class="math display">\[Q(s,a) \leftarrow (1 - \alpha)Q(s,a) + (\alpha)[sample]\]</span></p></li></ul></li></ul><h4 id="q-learning-properties">Q-Learning Properties</h4><ul><li><p>Amazing result: Q-learning converges to optimal policy -- even ifyou’re acting suboptimally!</p></li><li><p>This is called <strong>off-policy learning</strong></p></li><li><p>Caveats:</p><ul><li>You have to explore enough</li><li>You have to eventually make the learning rate small enough</li><li>... but not decrease it too quickly</li><li>Basically, in the limit, it doesn't matter how you select actions(!)</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>网课笔记</category>
      
      <category>CS188</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS188</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>cs188 lecture7</title>
    <link href="/2023/01/21/CS188/cs188-lec7/cs188-lec7/"/>
    <url>/2023/01/21/CS188/cs188-lec7/cs188-lec7/</url>
    
    <content type="html"><![CDATA[<h2 id="the-bellman-equations">The Bellman Equations</h2><ul><li><p>How to be optimal?</p><ul><li>Step 1: Take correct first action</li><li>Step 2: Keep being optimal</li></ul></li><li><p>Definition of "optimal utility" via expectimax recurrence gives asimple one-step lookahead relationship amongst optimal utility values<span class="math display">\[\begin{align*}V^*(s) &amp;= {max}_{a}\,Q^*(s,a) \\Q^*(s,a) &amp;= \sum_{s&#39;}T(s,a,s&#39;)[R(s,a,s&#39;) + \gammaV^*(s&#39;)] \\V^*(s) &amp;= max_a\sum_{s&#39;}T(s,a,s&#39;)[R(s,a,s&#39;) + \gammaV^*(s&#39;)]\end{align*}\]</span></p></li><li><p>These are the Bellman equations, and they characterize optimalvalues in a way we'll use over and over</p></li></ul><p>The value iteration method mentioned in lecture 6 is just a fixedpoint solution method</p><h2 id="policy-evaluation">Policy Evaluation</h2><ul><li><p>How do we calculate the V's for a fixed policy <span class="math inline">\(\pi\)</span> ?</p></li><li><p>Idea 1: Turn recursive Bellman equations into updates (like valueiteration) <span class="math display">\[\begin{align*}V_0^{\pi}(s) &amp;= 0 \\V_0^{\pi}(s) &amp;\leftarrow\sum_{s&#39;}T(s,\pi(s),s&#39;)[R(s,\pi(s),s&#39;) + \gammaV_k^{\pi}(s&#39;)]\end{align*}\]</span></p></li><li><p>Efficiency: <span class="math inline">\(O(S^2)\)</span> periteration</p></li><li><p>Idea 2: Without the maxes, the Bellman equations are just alinear system</p></li></ul><h3 id="computing-actions-from-values">Computing Actions fromValues</h3><ul><li><p>We need to do a mini-expectimax (one step) to get policy <span class="math display">\[\pi^*(s) = arg\, max_a \sum_{s&#39;}T(s,a,s&#39;)[R(s,a,s&#39;) + \gammaV^*(s&#39;)]\]</span></p></li><li><p>This is called <strong>policy extraction</strong>, since it getsthe policy implied by the values</p></li><li><p>Efficiency: <span class="math inline">\(O(S^2a)\)</span></p></li></ul><h3 id="computing-actions-from-q-values">Computing Actions fromQ-values</h3><ul><li><p>Completely trivial to decide how to act <span class="math display">\[\pi^*(s) = arg\,max_a Q^*(s,a)\]</span></p></li><li><p><strong>Important lesson</strong>: actions are easier to selectfrom q-values than values</p></li></ul><h3 id="problems-with-value-iteration">Problems with ValueIteration</h3><ul><li><p>Value iteration repeats the Bellman updates: <span class="math display">\[V_{k + 1}(s) \leftarrow max_{a}\sum_{s&#39;}T(s,a,s&#39;)[R(s,a,s&#39;)+ \gamma V_k(s&#39;)]\]</span></p></li><li><p>Problem 1: It's slow -- <span class="math inline">\(O(S^2A)\)</span> per iteration</p></li><li><p>Problem 2: The "max" at each state rarely changes</p></li><li><p>Problem 3: The policy often converges long before thevalues</p></li></ul><h2 id="policy-iteration">Policy Iteration</h2><ul><li><p>Alternative approach for optimal values:</p><ul><li><strong>Step 1: Policy evaluation: </strong> calculate utilities forsome fixed policy (not optimal utilities!) until convergence</li><li><strong>Step 2: Policy improvement: </strong> update policy usingone-step look-ahead with resulting converged (but not optimal!)utilities as future values</li></ul></li><li><p>This is <strong>policy iteration</strong></p><ul><li>It's still optimal</li><li>Can converge (much) faster under some conditions</li></ul></li><li><p>Evaluation: For a fixed current policy <span class="math inline">\(\pi\)</span>, find values with policyevaluation:</p><ul><li>Iterate until values converge: <span class="math display">\[V_{k + 1}^{\pi_i}(s) \leftarrow\sum_{s&#39;}T(s,\pi_i(s),s&#39;)[R(s,\pi_i(s),s&#39;) + \gammaV_k^{\pi_i}(s&#39;)]\]</span></li></ul></li><li><p>Improvement: For fixed values, get a better policy using policyextraction</p><ul><li>One step look-ahead: <span class="math display">\[\pi_{i + 1}(s) = arg\,max_a \sum_{s&#39;}T(s,a,s&#39;)[R(s,a,s&#39;) +\gamma V^{\pi_i}(s&#39;)]\]</span></li></ul></li></ul><h2 id="comparison">Comparison</h2><ul><li>Both value iteration and policy iteration compute the same thing(all optimal values)</li><li>In value iteration:<ul><li>Every iteration updates both the values and (implicitly) thepolicy</li><li>We don't track the policy, but taking the max over actionsimplicitly recomputes it</li></ul></li><li>In policy iteration:<ul><li>We do several passes that update utilities with fixed policy (eachpass is fast because we consider only one action, not all of them)</li><li>After the policy is evaluated, a new policy is chosen (slow like avalue iteration pass)</li><li>The new policy will be better(or done)</li></ul></li><li>Both are dynamic programs for solving MDPs</li></ul>]]></content>
    
    
    <categories>
      
      <category>网课笔记</category>
      
      <category>CS188</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS188</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>cs188 lecture6</title>
    <link href="/2023/01/17/CS188/cs188-lec6/cs188-lec6/"/>
    <url>/2023/01/17/CS188/cs188-lec6/cs188-lec6/</url>
    
    <content type="html"><![CDATA[<h2 id="markov-decision-process">Markov Decision Process</h2><ul><li>An MDP is defined by:<ul><li>A set of states <span class="math inline">\(s \in S\)</span></li><li>A set of actions <span class="math inline">\(a \in A\)</span></li><li>A transition function <span class="math inline">\(T(s,a,s&#39;)\)</span><ul><li>Probability that <span class="math inline">\(a\)</span> from <span class="math inline">\(s\)</span> leads to <span class="math inline">\(s&#39;\)</span></li><li>Also called the mode or the dynamics</li></ul></li><li>A reward function <span class="math inline">\(R(s,a,s&#39;)\)</span><ul><li>Sometimesjust <span class="math inline">\(R(s)\)</span> or <span class="math inline">\(R(s&#39;)\)</span></li></ul></li><li>A start state</li><li>Maybe a terminal state</li></ul></li><li>MDPs are non-deterministic search problems<ul><li>One way to solve them is with expectimax search</li></ul></li></ul><p>Markov generally means that given the present state, the future andthe past are independent</p><p>For Markov decision processes, "Markov" means action outcomes dependonly on the current state</p><h2 id="policies">Policies</h2><ul><li>In deterministic single-agent search problems, we wanted an optimal<strong>plan</strong>, or sequence of actions, from start to a goal</li><li>For MDPs, we want an optimal <strong>policy</strong> <span class="math inline">\(\pi^*:\,S \rightarrow A\)</span><ul><li>A policy <span class="math inline">\(\pi\)</span> gives an actionfor each state</li><li>An optimal policy is one that maximizes expected utility iffollowed</li><li>An explicit policy defines a reflex agent</li></ul></li><li>Expectimax didn't compute entire policies<ul><li>It computed the action for a single state only</li></ul></li></ul><h2 id="utilities-of-sequences">Utilities of Sequences</h2><p>We prefer get reward as early as possible([1,0,0] is better than[0,0,1])</p><h3 id="discounting">Discounting</h3><ul><li><p>It's reasonable to maximize the sum of rewards</p></li><li><p>It's also reasonable to prefer rewards now to rewardslater</p></li><li><p>One solution: values of rewards decay exponentially</p></li><li><p>How to discount?</p><ul><li>Each time we descend a level, we multiply in the discount once</li></ul></li><li><p>Why discount?</p><ul><li>Sooner rewards probably do have higher utility than laterrewards</li><li>Also helps our algorithms converge</li></ul></li></ul><h3 id="stationary-preferences">Stationary Preferences</h3><ul><li><p>Theorem: if we assume <strong>stationary preferences</strong>:<span class="math display">\[\begin{align*}[a_1,a_2,...] &amp;\succ [b_1,b_2,...] \\&amp;\Updownarrow \\[r,a_1,a_2,...] &amp;\prec [r,b_1,b_2,...]\end{align*}\]</span></p></li><li><p>Then: there are only two ways to define utilities</p><ul><li>Additive utility: <span class="math inline">\(U([r_0,r_1,r_2,...]) =r_0 + r_1 + r_2 + ...\)</span></li><li>Discounted utility: <span class="math inline">\(U([r_0,r_1,r_2,...])= r_0 + \gamma r_1 + \gamma^2 r_2+...\)</span></li></ul></li></ul><h3 id="infinite-utilities">Infinite Utilities</h3><ul><li><p>Problem: What if the game lasts forever? Do we get infiniterewards?</p></li><li><p>Solutions:</p><ul><li>Finite horizon:<ul><li>Terminates episodes after a fixed T steps</li><li>Gives nonstationary policies</li></ul></li><li>Discounting: use <span class="math inline">\(0 &lt; \gamma &lt;1\)</span> <span class="math display">\[U([r_0,r_1,...,r_{ \infty }]) = \sum_{t = 0}^{\infty}\gamma^t r_t \leq\frac{R_{max}}{1 - \gamma}\]</span><ul><li>Smaller <span class="math inline">\(\gamma\)</span> means smaller"horizon" - shorter term focus</li></ul></li><li>Absorbing state: guarantee that for every policy, a terminal statewill eventually be reached</li></ul></li></ul><h2 id="optimal-quantities">Optimal Quantities</h2><ul><li>The value (utility) of a state <span class="math inline">\(s\)</span>:<ul><li>$V^*(s) = $ expected utility starting in s and acting optimally</li></ul></li><li>The value (utility) of a q-state (s,a):<ul><li>$Q^*(s,a) = $ expected utility starting out having taken action<span class="math inline">\(a\)</span> from state <span class="math inline">\(s\)</span> and (thereafter) acting optimally</li></ul></li><li>The optimal policy:<ul><li>$^*(s) = $ optimal action from state <span class="math inline">\(s\)</span></li></ul></li></ul><h2 id="value-of-states">Value of States</h2><ul><li>Fundamental operation: compute the (expectimax) value of a state<ul><li>Expected utility under optimal action</li><li>Average sum of (discounted) rewards</li><li>This is just what expectimax computed!</li></ul></li><li>Recursive definition of value: <span class="math display">\[\begin{align*}V^*(s) &amp;= max_{a} Q^*(s,a)\\Q^*(s,a) &amp;= \sum_{s&#39;}T(s,a,s&#39;)[R(s,a,s&#39;) + \gammaV^*(s&#39;)] \\V^*(s) &amp;= max_a\sum_{s&#39;}T(s,a,s&#39;)[R(s,a,s&#39;) + \gammaV^*(s&#39;)]\end{align*}\]</span></li></ul><h2 id="value-iteration">Value Iteration</h2><ul><li><p>Start with <span class="math inline">\(V_0(s) = 0\)</span> : notime steps left means an expected reward sum of zero</p></li><li><p>Given vector of V_k(s)$ value, do one ply of expectimax from eachstate: <span class="math display">\[V_{k + 1} \leftarrow max_{a}\sum_{s&#39;}T(s,a,s&#39;)[R(s,a,s&#39;) +\gamma V_k(s&#39;)]\]</span></p></li><li><p>Repeat until convergence</p></li></ul>]]></content>
    
    
    <categories>
      
      <category>网课笔记</category>
      
      <category>CS188</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS188</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>cs188 lecture5</title>
    <link href="/2023/01/15/CS188/cs188-lec5/cs1881-lec5/"/>
    <url>/2023/01/15/CS188/cs188-lec5/cs1881-lec5/</url>
    
    <content type="html"><![CDATA[<h2 id="expectimax-search">Expectimax Search</h2><ul><li><p>Why wouldn’t we know what the result of an action will be?</p><ul><li>Explicit randomness: rolling dice</li><li>Unpredictable opponents: the ghosts respond randomly</li><li>Actions can fail: when moving a robot, wheels might slip</li></ul></li><li><p>Values should now reflect average-case (expectimax) outcomes, notworst-case (minimax) outcomes</p></li><li><p><strong>Expectimax search</strong>: compute the average scoreunder optimal play</p><ul><li>Max nodes as in minimax search</li><li>Chance nodes are like min nodes but the outcome is uncertain</li><li>Calculate their <strong>expected utilities</strong></li></ul></li></ul><h3 id="expectimax-pseudocode">Expectimax Pseudocode</h3><p>The value function is:</p><figure class="highlight pf"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></div></td><td class="code"><pre><code class="hljs pf">def value(<span class="hljs-keyword">state</span>):<br>if the <span class="hljs-keyword">state</span> is a terminal <span class="hljs-keyword">state</span>: return <span class="hljs-keyword">state</span>&#x27;s utility<br>if the next agent is MAX: return max-value(<span class="hljs-keyword">state</span>)<br>if the next agent is EXP: return exp-value(<span class="hljs-keyword">state</span>)<br></code></pre></td></tr></table></figure><p>The max-value function mentioned before is:</p><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs pf">def max-value(<span class="hljs-keyword">state</span>):<br>initialize v = -inf<br><span class="hljs-keyword">for</span> each successor of <span class="hljs-keyword">state</span>:<br>v = <span class="hljs-keyword">max</span>(v,value(successor))<br>return v<br></code></pre></td></tr></table></figure><p>The exp-value mentioned before is:</p><figure class="highlight pf"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs pf">def exp-value(<span class="hljs-keyword">state</span>):<br>initialize v = <span class="hljs-number">0</span><br><span class="hljs-keyword">for</span> each successor of <span class="hljs-keyword">state</span>:<br>p = <span class="hljs-keyword">probability</span>(successor)<br>v += p * value(successor)<br>return v<br></code></pre></td></tr></table></figure><p>Expectimax Search can't pruning because you will never know theaffect of the value of the next node</p><h2 id="other-game-types">Other Game Types</h2><h3 id="mixed-layer-types">Mixed Layer Types</h3><ul><li>Expectiminimax<ul><li>Environment is an extra "random agent" player that moves after eachmin/max agent</li><li>Each node computes the appropriate combinations of its children</li></ul></li></ul><h3 id="multi-agent-utilities">Multi-Agent Utilities</h3><p>The game is not zero-sum, or has multiple players</p><ul><li>Generalization of minimax:<ul><li>Terminals have utility tuples</li><li>Node values are also utility tuples</li><li>Each player maximizes its own component</li><li>Can give rise tio cooperation and competition dynamically</li></ul></li></ul><h2 id="maximum-expected-utility">Maximum Expected Utility</h2><p>Why choose average utilities instead of minimax?</p><p>Minimax consider a lot of bad situations with quite smallprobabilities</p><ul><li>Principle of maximum expected utility:<ul><li>A rational agent should chose the action that <strong>maximizes itsexpected utility,given its knowledge of the world</strong></li></ul></li><li>But it also get some questions:<ul><li>Where do utilities come from?</li><li>How do we know such utilities even exist?</li><li>How do we know that averaging even makes sense?</li><li>What if our behavior (preferences) can't be described byutilities?</li></ul></li></ul><h2 id="utilities">Utilities</h2><ul><li><p><strong>Utilities are functions from outcomes (states of theworld) to real numbers that describe an agent’spreferences</strong></p></li><li><p>Where do utilities come from?</p><ul><li>Utilieties sumarize the agent's goals</li><li>Theorem: any “rational” preferences can be summarized as a utilityfunction</li></ul></li><li><p>We hard-wire utilities and let behaviors emerge</p><ul><li>Why don't we let agents pick utilities?</li><li>Why don't we prescribe behaviors?</li></ul></li></ul><h2 id="preference">Preference</h2><ul><li><p>An agent must have preferences among:</p><ul><li><p>Prizes: <span class="math inline">\(A,B,\)</span>etc</p></li><li><p>Lotteries: situations with uncertain prizes: <span class="math display">\[L = [p,A;\;\;(1-p),B]\]</span></p></li></ul></li><li><p>Notation:</p><ul><li>Preference: <span class="math inline">\(A \succ B\)</span></li><li>Indifference: <span class="math inline">\(A \sim B\)</span></li></ul></li></ul><h2 id="rational-preferences">Rational Preferences</h2><ul><li>We want some constraints on preferences before we call themrational: <span class="math display">\[Axiom\;of\;Transtivity: (A \succ B) \,\wedge\,(B \succ C)\,\Rightarrow\, (A \succ C)\]</span></li></ul><p>Intransitive preference will leads to error(bad utilities)</p><figure><img src="/.com//2023winter\CS188\lecture%20notes\lec5-1.png" alt="lec5-1"><figcaption aria-hidden="true">lec5-1</figcaption></figure><p>Theorem: Rational preferences imply behavior describable asmaximization of e</p><ul><li>Given any preferences satisfying these constraints, there exists areal-valued function U such that:</li></ul><p><span class="math display">\[U(A) \geq U(B) \Leftrightarrow A \succeq B \\U([p_1,S_1;...;p_n,S_n]) = \sum_{i}p_iU(S_i)\]</span></p><ul><li>Maximum expected utility(MEU) principle:<ul><li>Choose the action that maximizes expected utility</li><li>Note: an agent can be entirely rational (consistent with MEU)without ever representing or manipulating utilities andprobabilities</li><li>E.g., a lookup table for perfect tic-tac-toe, a reflex vacuumcleaner</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>网课笔记</category>
      
      <category>CS188</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS188</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>cs188 lecture4</title>
    <link href="/2023/01/15/CS188/cs188-lec4/cs1881-lec4/"/>
    <url>/2023/01/15/CS188/cs188-lec4/cs1881-lec4/</url>
    
    <content type="html"><![CDATA[<h2 id="deterministic-games">Deterministic Games</h2><p>Many possible formalizations, one is:</p><ul><li>States: S (start at <span class="math inline">\(s_0\)</span>)</li><li>Players: P={1,2,...,N} (usually take turns)</li><li>Actions: A (may depend on player / state)</li><li>Transition Function: <span class="math inline">\(S\times A\rightarrow S\)</span></li><li>Terminal Test: <span class="math inline">\(S \rightarrow\{t,f\}\)</span></li><li>Terminal Utilities:<span class="math inline">\(S\times P \rightarrowR\)</span></li></ul><p>Solution for a player is a <strong>policy</strong>: <span class="math inline">\(S \rightarrow A\)</span></p><h2 id="zero-sum-games">Zero-Sum Games</h2><p>Zero-Sum Games:</p><ul><li>Agents have opposite utilities (values on outcomes)</li><li>Let's think of a single value that one maximizes and the otherminimizes</li><li>Adversarial, pure competition</li></ul><p>General Games:</p><ul><li>Agents have independent utilities (values on outcomes)</li><li>Cooperation, indifference, competition, and more are allpossible</li><li>More later on non-zero-sum games</li></ul><h2 id="adversarial-search">Adversarial Search</h2><h4 id="value-of-a-state">Value of a state</h4><p><strong>Value of a state</strong>: The best achievable outcome(utility) from that state.</p><p>Non-Terminal States: <span class="math display">\[V(s) = max_{s&#39; \in children(s)}V(s&#39;)\]</span> Terminal States: <span class="math display">\[V(s) = known\]</span></p><h4 id="minimax-values">Minimax Values</h4><ul><li><p>States Under Agent's Control: <span class="math display">\[V(s) = max_{s&#39; \in successors(s)}V(s&#39;)\]</span></p></li><li><p>States Under Opponent's Control: <span class="math display">\[V(s&#39;) = min_{s \in successor(s&#39;)}V(s)\]</span></p></li></ul><p>The problem solved means we can compute the value of the rootstate.</p><h4 id="adversarial-search-minimax">Adversarial Search (Minimax)</h4><ul><li>Deterministic, zero-sum games:<ul><li>One player maximizes result</li><li>The other minimizes result</li></ul></li><li>Minimax search:<ul><li>A state-space search tree</li><li>Players alternate turns</li><li>Compute each node's <strong>minimax value</strong>: the bestachievable utility against a rational (optimal) adversary</li></ul></li></ul><h3 id="minimax-efficiency">Minimax Efficiency</h3><ul><li>How efficient is minimax?<ul><li>Time: <span class="math inline">\(O(b^m)\)</span></li><li>Space:<span class="math inline">\(O(bm)\)</span></li></ul></li></ul><h2 id="alpha-beta-pruning">Alpha-Beta Pruning</h2><ul><li>General configuration (MIN version)<ul><li>We’re computing the MIN-VALUE at some node <em>n</em></li><li>We’re looping over <em>n</em>’s children</li><li><em>n</em>’s estimate of the childrens’ min is dropping</li><li>Who cares about <em>n</em>’s value? MAX</li><li>Let <em>a</em> be the best value that MAX can get at any choicepoint along the current path from the root</li><li>If <em>n</em> becomes worse than <em>a</em>, MAX will avoid it, sowe can stop considering <em>n</em>’s other children (it’s already badenough that it won’t be played)</li></ul></li><li>MAX version is symmetric</li></ul><h3 id="alpha-beta-pruning-properties">Alpha-Beta PruningProperties</h3><ul><li>This pruning has <strong>no effect</strong> on minimax valuecomputed for the root!</li><li>Values of intermediate nodes might be wrong<ul><li>Important: children of the root may have the wrong value</li><li>So the most naive version won't let you do action selection</li></ul></li><li>Good child ordering improves effectiveness of pruning</li><li>With "perfect ordering":<ul><li>Time complexity drops to <span class="math inline">\(O(b^{\frac{m}{2}})\)</span></li><li>Doubles solvable depth</li><li>Full search of, e.g. chess, is still hopeless...</li></ul></li><li>This is a simple example of <strong>metareasoning</strong>(computing about what to compute)</li></ul><h2 id="resource-limits">Resource Limits</h2><ul><li>Problem: In realistic games, cannot search to leaves!</li><li>Solution: Depth-limited search<ul><li>Instead, search only to a limited depth in the tree</li><li>Replace terminal utilities with an evaluation function fornon-terminal positions</li></ul></li><li>Guarantee of optimal play is gone</li><li>More plies makes a BIG difference</li><li>Use iterative deepening for an anytime algorithm</li></ul><h2 id="evaluation-functions">Evaluation Functions</h2><ul><li>Evaluation functions score non-terminals in depth-limitedsearch</li><li>Ideal function: returns the actual minimax value of theposition</li><li>In practice: typically weighted linear sum of features:</li></ul><p><span class="math display">\[Eval(s) = w_1f_1(s)+w_2f_2(s)+...+w_nf_n(s)\]</span></p>]]></content>
    
    
    <categories>
      
      <category>网课笔记</category>
      
      <category>CS188</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS188</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>cs188 lecture3</title>
    <link href="/2023/01/15/CS188/cs188-lec3/cs1881-lec3/"/>
    <url>/2023/01/15/CS188/cs188-lec3/cs1881-lec3/</url>
    
    <content type="html"><![CDATA[<h2 id="abstract">Abstract</h2><p>Informed Search:</p><ul><li>Heuristics</li><li>Greedy Search</li><li>A* Search</li></ul><p>Graph Search</p><h2 id="general-tree-search">General Tree Search</h2><figure><img src="/.com//2023winter\CS188\lecture%20notes\lec3-1.png" alt="lec3-1"><figcaption aria-hidden="true">lec3-1</figcaption></figure><p>We call it "general" because we can change the strategy depending onthe search algorithm we use.</p><h2 id="search-heuristics">Search Heuristics</h2><p>A heuristic is:</p><ul><li>A function tat estimates how close a state is to a goal</li><li>Designed for a particular search problem</li></ul><p>Need to find a heuristic function.</p><p>A good selection of heuristic function maybe cost less inalgorithms.</p><h2 id="greedy-search">Greedy Search</h2><p>Expand the node that seems closest…</p><ul><li>Strategy: expand a node that you think is closest to a goal state<ul><li>Heuristic: estimate of distance to nearest goal for each state</li></ul></li><li>A common case:<ul><li>Best-first takes you straight to the (wrong) goal</li></ul></li><li>Worst-case: like a badly-guided DFS</li></ul><h2 id="a-search">A* Search</h2><ul><li><strong>Uniform-cost</strong> orders by path cost, or backward cost<span class="math inline">\(g(n)\)</span></li><li><strong>Greedy</strong> orders by goal proximity, or forward cost<span class="math inline">\(h(n)\)</span></li><li><strong>A* search</strong> orders by the sum: <span class="math inline">\(f(n) = g(n) + h(n)\)</span></li></ul><h3 id="when-should-a-terminate">When should A* terminate</h3><ul><li><p>Should we stop when we enqueue a goal?</p></li><li><p>No: only stop when we dequeue a goal</p></li></ul><h3 id="is-a-optimal">Is A* optimal</h3><p>A* is not generally optimal.</p><p>Actual bad cost &lt; estimated good goal cost.</p><p>We need estimates to be less than actual costs.</p><h3 id="idea-admissibility">Idea: Admissibility</h3><p>If heuristics satisfy the property, then it's optimistic, then A* isoptimal.</p><h3 id="admissible-heuristics">Admissible Heuristics</h3><p>A heuristic <span class="math inline">\(h\)</span> is<em>admissible</em> (optimisitic) if: <span class="math display">\[0 \leq h(n) \leq h^*(n)\]</span> where <span class="math inline">\(h^*(n)\)</span> is the truecost to a nearest goal.</p><p>Coming up with admissible heuristics is most of what’s involved inusing A* in practice.</p><h3 id="creating-admissible-heuristics">Creating AdmissibleHeuristics</h3><ul><li>Most of the work in solving hard search problems optimally is incoming up with admissible heuristics</li><li>Often, admissible heuristics are solutions to <em>relaxedproblems,</em> where new actions are available</li><li>Inadmissible heuristics are often useful too</li></ul><h3 id="semi-lattice-of-heuristics">Semi-Lattice of Heuristics</h3><ul><li>With A*: a trade-off between quality of estimate and work per node<ul><li>As heuristics get closer to the true cost, you will expand fewernodes but usually do more work per node to compute the heuristicitself</li></ul></li></ul><h3 id="trivial-heuristics-dominance">Trivial Heuristics, Dominance</h3><ul><li>Dominance: <span class="math inline">\(h_a \geq h_c\)</span> if</li></ul><p><span class="math display">\[\forall n:h_a(n) \geq h_c(n)\]</span></p><ul><li><p>Heuristics form a semi-lattice:</p><ul><li>Max of admissible heuristics is admissible <span class="math display">\[h(n) = max(h_a(n),h_b(n))\]</span></li></ul></li><li><p>Trivial heuristics</p><ul><li>Bottom of lattice is zero heuristic</li><li>Top of lattice is the exact heuristic</li></ul></li></ul><h2 id="graph-search">Graph Search</h2><ul><li>Idea: never <strong>expand</strong> a state twice</li><li>How to implement:<ul><li>Tree search + set of expanded states (“closed set”)</li><li>Expand the search tree node-by-node, but…</li><li>Before expanding a node, check to make sure its state has never beenexpanded before</li><li>If not new, skip it, if new add to closed set</li></ul></li><li>Important: <strong>store the closed set as a set</strong>, not alist</li><li>Can graph search wreck completeness? Why/Why not?</li><li>Optimality?</li></ul><h3 id="consistency-of-heuristics">Consistency of Heuristics</h3><ul><li>Main idea: estimated heuristic costs <span class="math inline">\(\leq\)</span> actual costs<ul><li>Admissibility: heuristic cost <span class="math inline">\(\leq\)</span> actual cost to goal</li><li>Consistency: heuristic "arc" cost <span class="math inline">\(\leq\)</span> actual cost for each arc</li></ul></li><li>Consequences of consistency:<ul><li>The f value along path never decreases</li><li>A* graph search is optimal</li></ul></li></ul>]]></content>
    
    
    <categories>
      
      <category>网课笔记</category>
      
      <category>CS188</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS188</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CS188 lecture2</title>
    <link href="/2023/01/15/CS188/cs188-lec2/"/>
    <url>/2023/01/15/CS188/cs188-lec2/</url>
    
    <content type="html"><![CDATA[<p>Today, we focus on <strong>searching methods</strong>, especiallyuninformed search methods.</p><h2 id="abstraction">Abstraction</h2><ul><li>Agents that Plan Ahead</li><li>Search Problems</li><li>Uninformed Search Methods(dfs, bfs, uniform-cost search)</li></ul><h2 id="planning-agents-reflex-agents">Planning Agents &amp; ReflexAgents</h2><p><strong>Reflex agents</strong>:</p><ul><li>Choose action based on current percept (and maybe memory)</li><li>May have memory or a model of the world’s current state</li><li>Do not consider the future consequences of their actions</li><li><strong>Consider how the world IS</strong></li></ul><p><strong>Reflex agents CAN be rational</strong></p><p><strong>Planning agents</strong>:</p><ul><li>Ask "what if"</li><li>Decisions based on (hypothesized) consequences of actions</li><li>Must have a model of how the world evolves in response toactions</li><li>Must formulate a goal (test: eg "do you have an apple or not")</li><li><strong>Consider how the world WOULD BE</strong></li></ul><h2 id="search-problems">Search Problems</h2><p>A <strong>search problem</strong> consists of:</p><ul><li>a state space</li><li>a successor function (with actions, costs)</li><li>a start state and a goal test</li></ul><p>A <strong>solution</strong> is a sequence of actions (a plan)which</p><p>transforms the start state to a goal state</p><h2 id="state-space-graphs">State Space Graphs</h2><p><strong>State space graph: A mathematical representation of a searchproblem</strong>:</p><ul><li>Nodes are (abstracted) world configurations</li><li>Arcs represent successors (action results)</li><li>The goal test is a set of goal nodes (maybe only one)</li></ul><p><strong>In a state space graph, each state occurs onlyonce!</strong></p><p>We can rarely build this full graph in memory (it’s too big), butit’s a useful idea</p><h2 id="search-trees">Search Trees</h2><p>root node: start state</p><p>Every possible futures will become a vertex</p><p>A search tree:</p><ul><li>A “what if” tree of plans and their outcomes</li><li>The start state is the root node</li><li>Children correspond to successors</li><li>Nodes show states, but correspond to PLANS that achieve thosestates</li><li><strong>For most problems, we can never actually build the wholetree</strong></li></ul><p>Every node occurs only once in state space graphs but not necessarilyoccurs only once in search trees.</p><p><strong>Important: Lots of repeated structure in the searchtree!</strong></p><h3 id="searching-with-a-search-tree">Searching with a Search Tree</h3><p>Search:</p><ul><li>Expand out potential plans (tree nodes)</li><li>Maintain a <strong>fringe</strong> of partial plans underconsideration</li><li>Try to expand as few tree nodes as possible</li></ul><figure><img src="/.com//2023winter\CS188\lecture%20notes\lec2-1.png" alt="lec2-1"><figcaption aria-hidden="true">lec2-1</figcaption></figure><p>important ideas:</p><ul><li>Fringe</li><li>Expansion</li><li>Exploration strategy</li></ul><p>Main question: which fringe nodes to explore</p><h2 id="depth-first-searchdfs">Depth-First Search(DFS)</h2><p>Strategy: Expand a deepest node first.</p><p>Implementation: Fringe is a LIFO stack</p><h3 id="depth-first-search-properties">Depth-First SearchProperties</h3><p>What nodes DFS expand?</p><ul><li>Some left perfix of the tree</li><li>Could process the whole tree</li><li>if m is finite, takes time <span class="math inline">\(O(bm)\)</span></li></ul><p><strong>DFS is NOT optimal, because it find the "left-most"solution.</strong></p><h2 id="breadth-first-searchbfs">Breadth-First Search(BFS)</h2><p>Strategy: Expand a shallowest node first.</p><p>Implementation: Fringe is a FIFO queue.</p><h3 id="breadth-first-searchbfs-properties">Breadth-First Search(BFS)Properties</h3><p>What nodes BFS expand?</p><ul><li>Processes all nodes above shallowest solution.</li><li>Let depth of shallowest solution be s</li><li>Search takes time <span class="math inline">\(O(n^s)\)</span></li></ul><p>Takes time <span class="math inline">\(O(b^s)\)</span></p><p><strong>It is optimal ONLY IF costs are all 1</strong></p><h2 id="dfs-vs-bfs">DFS vs BFS</h2><p>DFS will be better when you don't have enough space costs. In otherwords, when you have so many situations or you want to save time, DFS isbetter.</p><p>BFS will be better when all your costs are 1, it can give an optimalsolution based on its strategy.</p><h2 id="iterative-deepening">Iterative Deepening</h2><p>Idea: get DFS's space advantage with BFS's time / shallow-solutionadvantages</p><p>Run a DFS with a depth limit, find all paths with depth limit. if nosolution, update depth limit and do the search again.</p><h2 id="uniform-cost-search">Uniform Cost Search</h2><p>Strategy: Expand a cheapest node first.(Greedy)</p><p>Fringe is a priority queue.</p><p>When we find a path costs n, we ensure that we have searched all thepaths that costs smaller than n.</p><h3 id="uniform-cost-search-ucs-properties">Uniform Cost Search (UCS)Properties</h3><p>What nodes does UCS expand?</p><ul><li>Processes all nodes with cost less than cheapest solution</li><li>If that solution costs <span class="math inline">\(C^*\)</span> andarcs cost at least <span class="math inline">\(\epsilon\)</span>, thenthe "effective depth" is roughly <span class="math inline">\(\frac{C^*}{\epsilon}\)</span></li><li>Takes time <span class="math inline">\(O(b^{\frac{C^*}{\epsilon}})\)</span> (exponentialin effective depth)</li></ul><p><strong>It is completely optimal</strong></p><h3 id="uniform-cost-issues">Uniform Cost Issues</h3><p><strong>UCS explores increasing cost contours.</strong></p><p>disadvantages:</p><ul><li>Explores options in every "direction"</li><li>No information about goal location</li></ul><h2 id="the-one-queue">The One Queue</h2><p><strong>All these search algorithms are the same except for fringestrategies.</strong></p><ul><li>Conceptually, all fringes are priority queues (i.e. collections ofnodes with attached priorities)</li><li>Practically, for DFS and BFS, you can avoid the log(n) overhead froman actual priority queue, by using stacks and queues</li><li>Can even code one implementation that takes a variable queuingobject</li></ul>]]></content>
    
    
    <categories>
      
      <category>网课笔记</category>
      
      <category>CS188</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS188</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Ubuntu上ssh的配置方法</title>
    <link href="/2022/12/29/ssh-init/"/>
    <url>/2022/12/29/ssh-init/</url>
    
    <content type="html"><![CDATA[<ol type="1"><li><p>升级apt-get</p><figure class="highlight shell"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></div></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">sudo apt-get update</span> <br><span class="hljs-meta prompt_">$ </span><span class="language-bash">sudo apt-get upgrade</span><br></code></pre></td></tr></table></figure></li><li><p>安装ssh服务器，客户端</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">sudo apt install openssh-server</span><br><span class="hljs-meta prompt_">$ </span><span class="language-bash">sudo apt install openssh-client</span><br></code></pre></td></tr></table></figure></li><li><p>修改sudoers文件权限</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">sudo <span class="hljs-built_in">chmod</span> 770 /etc/sudoers</span><br></code></pre></td></tr></table></figure></li><li><p>使用vim，修改sudoers配置文件</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">sudo vi /etc/sudoers</span><br></code></pre></td></tr></table></figure></li><li><p>修改sudoers配置文件如下</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_"># </span><span class="language-bash">Allow members of group sudo to execute any <span class="hljs-built_in">command</span></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">%sudo ALL=(ALL:ALL) ALL</span><br><span class="hljs-meta prompt_">%</span><span class="language-bash">sudo ALL=NOPASSWD: ALL</span><br><br></code></pre></td></tr></table></figure></li><li><p>将权限改回去</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">sudo <span class="hljs-built_in">chmod</span> 440 /etc/sudoers</span><br></code></pre></td></tr></table></figure></li><li><p>重启生效</p><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs shell"><span class="hljs-meta prompt_">$ </span><span class="language-bash">reboot</span><br></code></pre></td></tr></table></figure></li><li></li></ol>]]></content>
    
    
    <categories>
      
      <category>misc</category>
      
    </categories>
    
    
    <tags>
      
      <tag>misc</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>群论</title>
    <link href="/2022/11/01/grouptheory/grouptheory/"/>
    <url>/2022/11/01/grouptheory/grouptheory/</url>
    
    <content type="html"><![CDATA[<h2 id="循环群">循环群</h2><p>设 <span class="math inline">\(G\)</span> 为群，<span class="math inline">\(S\)</span> 是 <span class="math inline">\(G\)</span> 的子集，<span class="math inline">\(G\)</span> 中包含 <span class="math inline">\(S\)</span> 的最小子群 <span class="math inline">\(A\)</span> 的叫做由 <span class="math inline">\(S\)</span> 生成的子群，表示为 <span class="math inline">\(A = &lt;S&gt;\)</span></p><p>如果群 <span class="math inline">\(G\)</span> 自身由子集 <span class="math inline">\(S\)</span> 生成，即 <span class="math inline">\(G= &lt;S&gt;\)</span>，则称 <span class="math inline">\(S\)</span> 是<span class="math inline">\(G\)</span>的一个<strong>生成元系</strong>，如果 <span class="math inline">\(G =&lt;S&gt;\)</span>并且 <span class="math inline">\(S\)</span>是有限集，称 <span class="math inline">\(G\)</span>是<strong>有限生成群</strong>. 特别若群 <span class="math inline">\(G\)</span> 由一个元素 <span class="math inline">\(a\)</span> 生成，即 <span class="math inline">\(G= &lt;a&gt;\)</span>，称 <span class="math inline">\(G\)</span>是<strong>循环群</strong>.</p><p><strong>定理</strong>：无限循环群同构于整数加法群 <span class="math inline">\(Z\)</span>， <span class="math inline">\(n\)</span> 阶有限循环群同构于 <span class="math inline">\(Z_n\)</span>. 从而同阶循环群彼此同构</p><p><strong>定理</strong>：循环群的子群均是循环群，则：</p><ol type="1"><li>若 <span class="math inline">\(G\)</span>是无限循环群，则对每一个正整数 <span class="math inline">\(m\)</span>，<span class="math inline">\(G\)</span>恰有一个指数为 <span class="math inline">\(m\)</span> 的子群 <span class="math inline">\(G_m = &lt;a^m&gt;\)</span>，并且它们和 {1}是 <span class="math inline">\(G\)</span> 的全部子群</li><li>若 <span class="math inline">\(G\)</span> 是有限循环群，则对 <span class="math inline">\(n\)</span> 的每个正因子 <span class="math inline">\(m\)</span>， <span class="math inline">\(G\)</span> 恰有一个指数为 <span class="math inline">\(m\)</span> 的 <span class="math inline">\(\frac{n}{m}\)</span> 阶子群 <span class="math inline">\(G_m = &lt;a^m&gt;\)</span>，并且它们是 <span class="math inline">\(G\)</span> 的全部子群</li></ol><p><strong>定理</strong>：设 <span class="math inline">\(G =&lt;a&gt;\)</span> 是循环群，则：</p><ol type="1"><li>若 <span class="math inline">\(G\)</span> 为无限循环群，则 <span class="math inline">\(G\)</span> 的生成元只有 <span class="math inline">\(a\)</span> 和 <span class="math inline">\(a^{-1}\)</span></li><li>若 <span class="math inline">\(G\)</span> 为 <span class="math inline">\(n\)</span> 阶有限循环群，则 <span class="math inline">\(G\)</span> 的生成元共有 <span class="math inline">\(\phi(n)\)</span> 个，它们是 <span class="math inline">\(a^k (1 \leq k \leq n;(k,n) = 1)\)</span></li></ol><h2 id="正规子群-商群-同态定理">正规子群 &amp; 商群 &amp; 同态定理</h2><p><strong>定义</strong>：群 <span class="math inline">\(G\)</span>的子群 <span class="math inline">\(N\)</span> 叫做 <span class="math inline">\(G\)</span> 的<strong>正规子群</strong>，是指堆每个<span class="math inline">\(g \in G\)</span>，<span class="math inline">\(g^{-1}Ng = N\)</span>，如果 <span class="math inline">\(N\)</span> 是 <span class="math inline">\(G\)</span> 的正规子群，则表示成 <span class="math inline">\(N \lhd G\)</span></p><p><strong>引理</strong>：设 <span class="math inline">\(N\)</span> 是<span class="math inline">\(G\)</span> 的子群，则下列条件彼此等价：</p><ol type="1"><li><span class="math inline">\(N \lhd G\)</span></li><li>对于每个 <span class="math inline">\(g \in G\)</span>，<span class="math inline">\(gN = Ng\)</span></li><li><span class="math inline">\(N_G(N) = G\)</span></li><li><span class="math inline">\(G\)</span> 对于 <span class="math inline">\(N\)</span> 的每个左陪集均是右陪集</li></ol>]]></content>
    
    
    <categories>
      
      <category>math</category>
      
      <category>近世代数</category>
      
    </categories>
    
    
    <tags>
      
      <tag>近世代数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Chap19 斐波那契堆</title>
    <link href="/2022/10/23/Introduction%20to%20Algorithms/fibonacciheap/fibonacciheap/"/>
    <url>/2022/10/23/Introduction%20to%20Algorithms/fibonacciheap/fibonacciheap/</url>
    
    <content type="html"><![CDATA[<h2 id="思考题">思考题</h2><h3 id="problem-2">Problem 2</h3><h4 id="sub-problem-a">Sub Problem a</h4><p>二项树的第k项由一个根节点和k个子树构成，其子树节点依次为<span class="math inline">\(B_0,...,B_{k - 1}\)</span>，所以有</p><ol type="1"><li>其节点个数为<span class="math inline">\(1 + \sum_{i = 0}^{k -1}|B_i|\)</span>，由数学归纳法可证为<span class="math inline">\(2^k\)</span>个节点</li><li>同理，二项树的高度为最大子树高+1，那么由归纳法同理可证为k(<span class="math inline">\(B_0\)</span>的节点数为1，高为0)，</li><li>由二项树的构造方式，我们可以将其看作一个根节点起的<span class="math inline">\(B_{k - 1}\)</span>再插入一颗为<span class="math inline">\(B_{k -1}\)</span>的子树得到的二项树，那么其深度为i的节点个数为<span class="math inline">\(C_{k - 1}^{i} + C_{k}^{i - 1} =C_{k}^{i}\)</span></li><li>由二项树构造方式，其根节点有k棵子树，由高度升高子树数量减少一个，所以根节点度数最大</li></ol>]]></content>
    
    
    <categories>
      
      <category>algorithms</category>
      
      <category>算法导论题解</category>
      
    </categories>
    
    
    <tags>
      
      <tag>algorithms</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>聚类算法</title>
    <link href="/2022/10/17/machine%20learning/cluster/cluster/"/>
    <url>/2022/10/17/machine%20learning/cluster/cluster/</url>
    
    <content type="html"><![CDATA[<h2 id="聚类的基本概念">聚类的基本概念</h2><h3 id="相似度和距离">相似度和距离</h3><h4 id="闵可夫斯基距离">闵可夫斯基距离</h4><p>在聚类中，可将样本集合看作是向量空间中点的集合，以该空间的距离表示样本之间的相似度。常用距离有闵可夫斯基距离，特别是欧氏距离。闵可夫斯基距离越大，相似度越小</p><p><strong>定义</strong>：给定样本集合矩阵 <span class="math inline">\(X\)</span>，<span class="math inline">\(X\)</span>是 <span class="math inline">\(m\)</span> 维实数向量空间中点的集合，其中<span class="math inline">\(x_i,x_j \in X\)</span>，<span class="math inline">\(x_i =(x_{1i},x_{2i},...,x_{mi})^T\)</span>，样本<span class="math inline">\(x_i,x_j\)</span>的闵可夫斯基距离定义为 <span class="math display">\[d_{ij} = (\sum_{k = 1}^{m}{|x_{ki} - x_{kj}|}^p)^{\frac{1}{p}}\]</span> 这里 <span class="math inline">\(p \geq 1\)</span>，当 <span class="math inline">\(p = 2\)</span> 时称为欧氏距离，<span class="math inline">\(p = 1\)</span> 时称为曼哈顿距离， <span class="math inline">\(p = \infty\)</span>时称为切比雪夫距离，取各个坐标数值差的绝对值的最大值，即 <span class="math display">\[d_{ij} = {max}_{k} |x_{ki} - x_{kj}|\]</span></p><h4 id="马哈拉诺比距离">马哈拉诺比距离</h4><p>马哈拉诺比距离简称马氏距离，是另一种常用的相似度，考虑各个分量(特征)之间的相关性并与各个分量的尺度无关。马哈拉诺比距离越大，相似度越小</p><p><strong>定义</strong>：给定一个样本集合矩阵 <span class="math inline">\(X\)</span>，其协方差矩阵记为 <span class="math inline">\(S\)</span>。样本 <span class="math inline">\(x_i\)</span> 和样本 <span class="math inline">\(x_j\)</span> 之间的马哈拉诺比距离 <span class="math inline">\(d_{ij}\)</span> 定义为： <span class="math display">\[d_{ij} = [(x_i - x_j)^TS^{-1}(x_i - x_j)]^{\frac{1}{2}}\]</span> 其中， <span class="math display">\[\begin{align*}x_i &amp;= (x_{1i},x_{2i},...,x_{mi})^T \\x_j &amp;= (x_{1j},x_{2j},...,x_{mj})^T \\\end{align*}\]</span></p><p>容易看出当 <span class="math inline">\(S\)</span>为单位阵时，马哈拉诺比距离就是欧氏距离，所以马氏距离也是欧氏距离的推广</p><h4 id="相关系数">相关系数</h4><p>样本之间的相似度也可以用相关系数表示。相关系数越接近1表示越相似；相关系数越接近0表示越不相似</p><p><strong>定义</strong>：样本 <span class="math inline">\(x_i\)</span>和 <span class="math inline">\(x_j\)</span> 之间的相关系数定义为 <span class="math display">\[r_{ij} = \frac{\sum_{k = 1}^m(x_{ki} - \bar{x}_i)(x_{kj} -\bar{x}_j)}{[\sum_{k = 1}^m(x_{ki} - \bar{x}_i)^2 \sum_{k = 1}^m(x_{kj}- \bar{x}_j)^2]^{\frac{1}{2}}}\]</span> 其中， <span class="math display">\[\begin{align*}\bar{x}_i &amp;= \frac{1}{m}\sum_{k = 1}^{m}x_{ki}\bar{x}_j &amp;= \frac{1}{m}\sum_{k = 1}^{m}x_{kj}\end{align*}\]</span></p><h4 id="夹角余弦">夹角余弦</h4><p>样本之间的相似度也可以用夹角余弦来表示。夹角余弦越接近1，表示样本越相似；越接近0，表示样本越不相似<strong>定义</strong>：样本 <span class="math inline">\(x_i\)</span> 和<span class="math inline">\(x_j\)</span> 之间的夹角余弦定义为 <span class="math display">\[s_{ij} = \frac{\sum_{k = 1}^{m}x_{ki}x_{kj}}{(\sum_{k =1}^{m}x_{ki}^2\sum_{k = 1}^{m}x_{kj}^2)^{\frac{1}{2}}}\]</span></p><p>由上述定义可见，用距离度量相似度时，距离越小样本越相似；用相关系数度量时，相关系数越大样本越相似。注意不同相似度度量得到的结构并不一定一致</p><h3 id="类或簇">类或簇</h3><p>通过聚类得到类或簇的本质是样本的子集，如果一个聚类方法假定一个样本只能属于一个类或类的交集为空集，那么成为硬聚类方法；否则称为软聚类方法。此处我们只讨论硬聚类方法，聚类的方法有多种，在此我们列举一种最常见的定义，且由该种定义可推出其他的定义方法</p><p><strong>定义</strong>；设 <span class="math inline">\(T\)</span>为给定的正数，若对于集合 <span class="math inline">\(G\)</span>种任意两个样本 <span class="math inline">\(x_i,x_j\)</span>，有 <span class="math display">\[d_{ij} \leq T\]</span> 则称 <span class="math inline">\(G\)</span> 为一个类或簇 其中<span class="math inline">\(d_{ij}\)</span> 表示样本 <span class="math inline">\(x_i,x_j\)</span> 之间的距离</p><p>类的特征可以通过不同角度来刻画，常用的有以下三种： 1. 类的均值 <span class="math inline">\(\bar{x}_{G}\)</span>，又称类的中心 <span class="math display">\[\bar{x}_{G} = \frac{1}{n_{G}}\sum_{i = 1}^{n_G}x_i\]</span> 其中 <span class="math inline">\(n_G\)</span> 表示类 <span class="math inline">\(G\)</span> 的样本数量 2. 类的直径 <span class="math inline">\(D_G\)</span>，其表示类种任意两个样本之间的最大距离，即<span class="math display">\[D_G = \mathop{max}_{x_i,x_j \in G}d_{ij}\]</span> 3. 类的样本散布矩阵 <span class="math inline">\(A_{G}\)</span>与样本协方差矩阵 <span class="math inline">\(S_G\)</span>类的样本散布矩阵 <span class="math inline">\(A_G\)</span> 为 <span class="math display">\[A_G = \sum_{i = 1}^{n_G}(x_i - \bar{x}_G)(x_i - \bar{x}_G)^T\]</span> 样本协方差矩阵 <span class="math inline">\(S_G\)</span> 为<span class="math display">\[\begin{align*}S_G &amp;= \frac{1}{n_G - 1}A_G \\&amp;= \frac{1}{n_G - 1}\sum_{i = 1}^{n_G}(x_i - \bar{x}_G)(x_i -\bar{x}_G)^T\end{align*}\]</span></p><h3 id="类与类之间的距离">类与类之间的距离</h3><p>下面考虑类 <span class="math inline">\(G_p\)</span> 与类 <span class="math inline">\(G_q\)</span> 之间的距离 <span class="math inline">\(D(p,q)\)</span>，也称为连接。类与类之间的距离也有多种定义。</p><p>设类 <span class="math inline">\(G_p\)</span> 包含 <span class="math inline">\(n_p\)</span> 个样本， <span class="math inline">\(G_q\)</span> 包含 <span class="math inline">\(n_q\)</span> 个样本，分别用 <span class="math inline">\(\bar{x}_p\)</span> 和 <span class="math inline">\(\bar{x}_q\)</span> 表示 <span class="math inline">\(G_p\)</span> 和 <span class="math inline">\(G_q\)</span> 的均值，即类的中心 1.最短距离或单连接 定义类 <span class="math inline">\(G_p\)</span>的样本与类 <span class="math inline">\(G_q\)</span>的样本之间的最短距离为两类之间的距离 2. 最长距离或完全连接 定义类 <span class="math inline">\(G_p\)</span> 的样本与类 <span class="math inline">\(G_q\)</span> 的样本之间的最长距离为两类之间的距离3. 中心距离 定义类 <span class="math inline">\(G_p\)</span> 的样本与类<span class="math inline">\(G_q\)</span> 的中心 <span class="math inline">\(\bar{x}_p\)</span> 和 <span class="math inline">\(\bar{x}_q\)</span> 之间的距离为两类之间的距离 4.平均距离 定义类 <span class="math inline">\(G_p\)</span> 的样本与类<span class="math inline">\(G_q\)</span>任意两个样本之间距离的平均值为两类之间的距离</p><h2 id="层次聚类">层次聚类</h2><p>层次聚类假设类别之间存在层次结构，将样本聚到层次化的类中。层次聚类又有聚合和分裂两种方法，由于每个样本只属于一个类，所以层次聚类属于硬聚类。</p><p>我们在这里介绍聚合聚类的方法，其具体过程如下：对于给定的样本集合，开始将每个样本分到一个类；然后按照一定规则(eg:类间距离最小)，将最满足规则条件的两个类进行合并；如此反复进行，每次减少一个类，直到满足停止条件，如所有样本聚为一类</p><p>由此可知，聚合聚类需要预先确定下面三个要素： 1. 距离/相似度 2.合并规则 3. 停止条件</p><p>根据要素的不同组合，就可以构成不同的聚类方法。(距离/相似度的选取；合并规则是哪种类之间距离；停止条件的选取)</p><p>在这里我们介绍一种特定的聚合聚类算法 <strong>算法</strong>： 输入：<span class="math inline">\(n\)</span>个样本组成的样本集合及样本之间的距离输出：对样本集合的一个层次化聚类</p><ol type="1"><li>计算 <span class="math inline">\(n\)</span>个样本两两之间的欧氏距离<span class="math inline">\(\{d_{ij}\}\)</span>，记作矩阵 <span class="math inline">\(D = [d_{ij}]_{n \times n}\)</span></li><li>构造 <span class="math inline">\(n\)</span>个类，每个类只包含一个样本</li><li>合并类间距离最小的两个类，其中最短距离为类间距离，构架你个新类</li><li>计算新类与当前各类的距离。若类的个数为1，停止计算；否则回到步骤3</li></ol><h2 id="k均值聚类">k均值聚类</h2><p>k均值聚类是基于样本集合划分的聚类算法。k均值聚类将样本集合划分为k个子集，构成k个类，将n个样本分到k个类中，每个样本到其所属类的中心的距离最小。每个样本只能属于1个类，所以k均值聚类是硬聚类。下面我们介绍k均值聚类算法</p><h3 id="策略">策略</h3><p>k均值聚类归结为样本集合 <span class="math inline">\(X\)</span>的划分，或者从样本到类的函数的选择问题。k均值聚类的策略是通过最小化损失函数来选取最优的划分函数<span class="math inline">\(C^*\)</span></p><p>首先，采取欧氏距离平方作为样本之间的距离 <span class="math display">\[\begin{align*}d(x_i,x_j) &amp;= \sum_{k = 1}^{m}(x_{ki} - x_{kj})^2 \\&amp;= ||x_i - x_j||^2\end{align*}\]</span> 然后定义样本与其所属类的中心之间的距离总和为损失函数 <span class="math display">\[\begin{align*}W(C) = \sum_{l = 1}^{k}\sum_{C(i) = l}||x_{i} - \bar{x}_l||^2\end{align*}\]</span> 式中 ${x}<em>l =({x}</em>{1l},{x}<em>{2l},...,{x}</em>{ml})^T是第 <span class="math inline">\(l\)</span> 个类的均值或中心</p><p>k均值聚类就是求解最优化问题： <span class="math display">\[\begin{align*}C^* &amp;= arg\, min_{C} W(C) \\&amp;= arg \, min_{C}\sum_{l = 1}^{k}\sum_{C(i) = l}||x_{i} -\bar{x}_l||^2\end{align*}\]</span></p><p>相似的样本被聚到同类时，损失函数值最小，这个目标函数的最优化能达到聚类的目的。但是这个组合优化问题的所有可能分类方法过多，只能通过迭代的方法求解</p><h3 id="算法">算法</h3><p>k均值聚类的算法是一个迭代的过程，每次迭代包括两个步骤： *首先选择k个类的中心，将样本诸葛指派到与其最近的中心的类中，得到一个聚类结果；* 然后更新每个类的样本的均值，作为类的新的中心； *重复以上步骤直到收敛为止</p><p><strong>算法</strong>： 输入：<span class="math inline">\(n\)</span>个样本的集合 <span class="math inline">\(X\)</span> 输出：样本集合的聚类<span class="math inline">\(C^*\)</span> 1. 初始化：令 <span class="math inline">\(t = 0\)</span>，随机选择 <span class="math inline">\(k\)</span> 个样本点作为初始聚类中心 <span class="math inline">\(m^{(0)} =(m_1^{(0)},...,m_l^{(0)},...,m_k^{(0)})\)</span> 2.对样本进行聚类。对固定的类中心 <span class="math inline">\(m^{(t)} =(m_1^{(t)},...,m_l^{(t)},...,m_k^{(t)})\)</span>，其中 <span class="math inline">\(m_l^{(t)}\)</span> 为类 <span class="math inline">\(G_l\)</span>的中心，计算每个样本到类中心的距离，将每个样本指派到与其最近的中心的类中，构成聚类结果<span class="math inline">\(C^{(t)}\)</span>。 3. 计算新的类中心。对聚类接过<span class="math inline">\(C^{(t)}\)</span>，计算当前各个类中的样本的均值，作为新的类中心<span class="math inline">\(m^{(t + 1)} = (m_1^{(t + 1)},...,m_l^{(t +1)},...,m_k^{(t + 1)})\)</span> 4. 如果迭代收敛或符合停止条件，输出<span class="math inline">\(C^* = C^{(t)}\)</span>; 否则，令 <span class="math inline">\(t = t + 1\)</span>，返回步骤2</p>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Boosting算法</title>
    <link href="/2022/10/09/machine%20learning/adaboost/adaboost/"/>
    <url>/2022/10/09/machine%20learning/adaboost/adaboost/</url>
    
    <content type="html"><![CDATA[<h2 id="adaboost算法">AdaBoost算法</h2><h3 id="boosting基本思路">Boosting基本思路</h3><p>Boosting基于这样一种思想：对于一个复杂任务来说，将多个专家的判断进行适当的综合得出的判断比其中任何一个专家单独的判断都好</p><p>强可学习和弱可学习：对于一个概念，如果存在一个多项式的学习算法能够学习它，并且成功率很高，那么就称这个概念是强可学习的；而如果学习的正确率仅比随即猜测略好，那么就称这个概念是弱可学习的；后来证明得强可学习和弱可学习的概念是等价的，这样一来问题就变为如何将弱学习算法提升为强学习算法</p><p>Boosting是一种从弱学习器算法出发，反复学习，得到一系列弱分类器，然后组合这些弱分类器构成一个强分类器。大多数Boosting都是改变训练数据的概率分布(训练数据的权值分布)，针对不同的训练数据分布调用弱学习算法学习一系列弱分类器</p><p>这样一来，对Boosting来说，有两个问题：</p><ol type="1"><li>每一轮如何改变训练数据的权值分布或概率分布</li><li>如何将弱分类器组合成强分类器</li></ol><p>第一个问题，AdaBoost的方法是提高前一轮弱分类器错误分类的样本的权值，降低那些分类正确的样本的权值；第二个问题，AdaBoost采取多数表决的方法，加大误差率小的分类器的权值，减小误差率大的分类器的权值</p><h3 id="adaboost算法-1">AdaBoost算法</h3><p><strong>算法(AdaBoost)</strong>：</p><p>输入：训练数据集<span class="math inline">\(T =\{(x_1,y_1),(x_2,y_2),...,(x_N,y_N)\}\)</span>，实例<span class="math inline">\(x_i \in \mathcal{X} \subseteq\mathcal{R}^n\)</span>，<span class="math inline">\(y_i \in \mathcal{Y}= \{-1,+1\}\)</span>；弱学习算法</p><p>输出：最终分类器<span class="math inline">\(G(x)\)</span></p><ol type="1"><li><p>初始化训练数据的权值分布 <span class="math display">\[D_1 = (w_{11},...,w_{1i},...,w_{1N}),\;\;w_{1i} = \frac{1}{N},\;\;i =1,2,3,...,N\]</span></p></li><li><p>对 <span class="math inline">\(m = 1,2,3,...,M\)</span></p><p>​ 使用具有权值分布 <span class="math inline">\(D_m\)</span>的训练数据集学习，得到基本分类器： <span class="math display">\[G_m(x):\mathcal{X} \rightarrow \{-1,+1\}\]</span></p></li></ol><p>​ 计算 <span class="math inline">\(G_m(x)\)</span>在训练数据集上的分类误差率： <span class="math display">\[e_m = \sum_{i = 1}^{N}P(G_m(x_i) \neq y_i) = \sum_{i =1}^{N}w_{mi}I(G_m(x_i) \neq y_i)\]</span></p><p>​ 计算 <span class="math inline">\(G_m(x)\)</span> 的系数 <span class="math display">\[\alpha_m = \frac{1}{2}log\,\frac{1 - e_m}{e_m}\]</span> ​ 更新训练数据集的权值分布： <span class="math display">\[\begin{align*}D_{m + 1} &amp;= (w_{m + 1,1},...,w_{m+1,i},...,w_{m + 1,N}) \\w_{m + 1,i} &amp;= \frac{w_{mi}}{Z_m}exp(-\alpha_my_iG_m(x_i)) \\\end{align*}\]</span> 这里， <span class="math inline">\(Z_m\)</span>是规范化因子，且： <span class="math display">\[Z_m = \sum_{i = 1}^{N}w_{mi}exp(-\alpha_my_iG_m(x_i))\]</span> 它使得 <span class="math inline">\(D_{m + 1}\)</span>成为一个概率分布，并用新的样本分布训练第 <span class="math inline">\(m +1\)</span> 轮分类器 <span class="math inline">\(G_{m +1}(x)\)</span></p><ol start="3" type="1"><li>构建基本分类器的线性组合</li></ol><p><span class="math display">\[f(x) = \sum_{i = 1}^{M}\alpha_mG_m(x)\]</span></p><p>得到最终分类器： <span class="math display">\[\begin{align*}G(x) &amp;= sign(f(x)) \\&amp;= sign(\sum_{m = 1}^{M}\alpha_mG_m(x))\end{align*}\]</span> <strong>我们需要做一些说明：</strong></p><ul><li>AdaBoost算法由基本分类器 <span class="math inline">\(G_1(x)\)</span>反复学习基本分类器，在每一轮执行以下操作：<ol type="1"><li>使用当前分布 <span class="math inline">\(D_m\)</span>加权的训练数据集学习基本分类器 <span class="math inline">\(G_m(x)\)</span></li><li>计算基本分类器 <span class="math inline">\(G_m(x)\)</span>在加权训练数据集上的分类误差率</li><li>计算基本分类器 <span class="math inline">\(G_m(x)\)</span> 的系数<span class="math inline">\(\alpha_m\)</span>，表示第 <span class="math inline">\(m\)</span> 轮分类器在最终分类器的重要性，<span class="math inline">\(\alpha_m\)</span> 随着 <span class="math inline">\(e_m\)</span>的减小而增大，所有分类误差率越小的分类器在最终的分类器的作用越大</li><li>更新训练数据的权值分布，由算法中的定义知误分类样本的权值被放大了<span class="math inline">\(e^{2\alpha_m}\)</span>倍，因此未改变训练数据也提高了误分类样本在下一轮学习中的重要性</li></ol></li></ul><p><span class="math display">\[\begin{align*}e_m &amp;= \sum_{i = 1}^{N} P(G_m(x_i) \neq y_i) \\&amp;= \sum_{G_m(x_i) \neq y_i}w_{mi}\end{align*}\]</span></p><p>这里，<span class="math inline">\(w_{mi}\)</span> 表示第 <span class="math inline">\(m\)</span> 轮中第 <span class="math inline">\(i\)</span> 个实例的权值， <span class="math inline">\(\sum_{i = 1}^{N}w_{mi} =1\)</span>，由定义知显然成立。</p><ul><li>最后在线性组合中实现了 <span class="math inline">\(M\)</span>个基本分类器的加权表决。系数 <span class="math inline">\(\alpha_m\)</span> 表示了基本分类器 <span class="math inline">\(G_m(x)\)</span> 的重要性，这里系数和非1</li></ul><h2 id="adaboost-算法的训练误差分析">AdaBoost 算法的训练误差分析</h2><p><strong>定理(AdaBoost的训练误差界)</strong>：AdaBoost算法最终分类器的训练误差界为 <span class="math display">\[\frac{1}{N}\sum_{i = 1}^{N}I(G(x_i) \neq y_i) \leq\frac{1}{N}\sum_{i}exp(-y_if(x_i)) = \prod_{m}Z_m\]</span> <strong>定理(二分类问题 AdaBoost 的训练误差界)</strong>：<span class="math display">\[\begin{align*}\prod_{m = 1}^{M}Z_m &amp;= \prod_{m = 1}^{M}2\sqrt{e_m(1 - e_m)} \\&amp;= \prod_{m = 1}^{M}\sqrt{1 - 4\gamma_m^2} \\&amp;\leq exp(-2\sum_{i = 1}^{M}\gamma_m^2)\end{align*}\]</span> 这里， <span class="math inline">\(\gamma_m = \frac{1}{2} -e_m\)</span></p><p><strong>推论</strong>：如果存在 <span class="math inline">\(\gamma&gt; 0\)</span>，对所有 <span class="math inline">\(m\)</span> 有 <span class="math inline">\(\gamma_m \geq \gamma\)</span>，则 <span class="math display">\[\frac{1}{N}\sum_{i = 1}^{N}I(G(x_i) \neq y_i) \leq exp(-2M\gamma^2)\]</span></p>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Chap5 指数与原根</title>
    <link href="/2022/09/27/math/numbertheory/numbertheory/"/>
    <url>/2022/09/27/math/numbertheory/numbertheory/</url>
    
    <content type="html"><![CDATA[<h3 id="整数的次数">整数的次数</h3><p><strong>定义</strong>：设<span class="math inline">\(m &gt;0\)</span>，<span class="math inline">\((a,m) = 1\)</span>，<span class="math inline">\(l\)</span> 是使 <span class="math display">\[a^l \equiv 1 \;(mod \,m)\]</span> 成立的最小正整数，则 <span class="math inline">\(l\)</span>叫做 <span class="math inline">\(a\)</span> 对模数 <span class="math inline">\(m\)</span> 的<strong>次数</strong></p><p><strong>定理</strong>：设 <span class="math inline">\(a\)</span>对模数 <span class="math inline">\(m\)</span> 的次数为 <span class="math inline">\(l\)</span>， <span class="math inline">\(a^n\equiv 1 \;(mod\, m)\)</span>，<span class="math inline">\(n &gt;0\)</span>，则<span class="math inline">\(l \,|\, n\)</span></p><p><strong>定理</strong>：设 <span class="math inline">\(a\)</span>对模数 <span class="math inline">\(m\)</span> 的次数为 <span class="math inline">\(l\)</span>，则 <span class="math display">\[1,a,a^2,...,a^{l - 1}\]</span> 对模数 <span class="math inline">\(m\)</span> 两两不同余</p><p><strong>定理</strong>：设 <span class="math inline">\(a\)</span>对模数 <span class="math inline">\(m\)</span> 的次数为 <span class="math inline">\(l\)</span>，<span class="math inline">\(\lambda&gt; 0\)</span>，<span class="math inline">\(a^\lambda\)</span> 对模数<span class="math inline">\(m\)</span> 的次数为 <span class="math inline">\(l_1\)</span>，则<span class="math inline">\(l_1 =\frac{l}{(l,\lambda)}\)</span></p><p><strong>推论</strong>：设 <span class="math inline">\(a\)</span>对模数 <span class="math inline">\(m\)</span> 的次数为 <span class="math inline">\(l\)</span>，则 <span class="math inline">\(\phi(l)\)</span> 个数 <span class="math display">\[a^\lambda,(\lambda,l) = 1, 0 &lt; \lambda \leq l\]</span> 对模数 <span class="math inline">\(m\)</span> 的次数均为 <span class="math inline">\(l\)</span></p><p><strong>定理</strong>：设 <span class="math inline">\(p\)</span>是一个素数，如果存在整数 <span class="math inline">\(a\)</span>，它对模数 <span class="math inline">\(p\)</span> 的次数是 <span class="math inline">\(l\)</span>，则恰有 <span class="math inline">\(\phi(l)\)</span> 个对模数 <span class="math inline">\(p\)</span> 两两不同余的整数，它们对模数 <span class="math inline">\(p\)</span> 的次数都为 <span class="math inline">\(l\)</span></p><p><strong>定理</strong>：设 <span class="math inline">\(l\,|\,p -1\)</span>，则次数是 <span class="math inline">\(l\)</span> 的，模数<span class="math inline">\(p\)</span> 互不同余的整数个数是 <span class="math inline">\(\phi(l)\)</span> 个</p><h3 id="原根">原根</h3><p><strong>定义</strong>：设整数 <span class="math inline">\(m &gt;0\)</span> ，<span class="math inline">\((g,m) = 1\)</span>，如果整数<span class="math inline">\(g\)</span> 对 <span class="math inline">\(m\)</span> 的次数为 <span class="math inline">\(\phi(m)\)</span> ，则 <span class="math inline">\(g\)</span> 叫做 <span class="math inline">\(m\)</span> 的一个<strong>原根</strong></p><p><strong>定理</strong>：设 <span class="math inline">\((g,m) =1\)</span>，<span class="math inline">\(m &gt; 0\)</span>，则 <span class="math inline">\(g\)</span> 是 <span class="math inline">\(m\)</span> 的一个原根的充要条件是 <span class="math display">\[g,g^2,...,g^{\phi(m)}\]</span> 组成模数 <span class="math inline">\(m\)</span> 的一组缩系</p><p><strong>原根的重要意义：原根的存在使得一个模数 <span class="math inline">\(m\)</span>的一组缩系课表示成一组几何级数</strong></p><p><strong>定理</strong>：设 <span class="math inline">\(m &gt;1\)</span>，若 <span class="math inline">\(m\)</span> 有原根，则 <span class="math inline">\(m\)</span> 必为下列诸数之一：2，4，<span class="math inline">\(p^l\)</span>，<span class="math inline">\(2p^l\)</span>，这里 <span class="math inline">\(l\geq 1\)</span>，<span class="math inline">\(p\)</span> 是奇素数</p><p><strong>定理</strong>：<span class="math inline">\(m =2,4,p^l,2p^l\)</span>(<span class="math inline">\(l \geq1\)</span>，<span class="math inline">\(p\)</span> 为奇素数)时，<span class="math inline">\(m\)</span> 有原根</p><p><strong>定理</strong>：设 <span class="math inline">\(m\)</span>有一个原根 <span class="math inline">\(g\)</span>，则 <span class="math inline">\(m\)</span> 恰有 <span class="math inline">\(\phi(\phi(m))\)</span> 个对模数 <span class="math inline">\(m\)</span> 不同余的原根，它们由集 <span class="math display">\[S = \{g^t\,|1 \leq t \leq \phi(m)，(t,\phi(m)) = 1\}\]</span> 中的数给出</p><h3 id="计算次数的方法">计算次数的方法</h3><p><strong>定理</strong>：如果 <span class="math inline">\(m =p_1^{l_1}p_2^{l_2}...p_k^{l_k}\)</span> 是 <span class="math inline">\(m\)</span> 的标准分解式，整数 <span class="math inline">\(a\)</span> 对模数 <span class="math inline">\(m\)</span> 的次数等于整数 <span class="math inline">\(a\)</span> 对模数 <span class="math inline">\(p_i^{l_i}\)</span> 的诸次数的最小公倍数</p><p><strong>定理</strong>： 设 <span class="math inline">\(p\)</span>是一个素数，<span class="math inline">\(a\)</span> 对模数 <span class="math inline">\(p^j\)</span> 的次数是 <span class="math inline">\(f_j\)</span>，则 <span class="math inline">\(f_{j+ 1} = f_j\)</span> 或 <span class="math inline">\(f_{j + 1} =pf_j\)</span>. 又设 <span class="math inline">\(p^i || a^{f_2} -1\)</span>，进而有 <span class="math display">\[    f_j = \begin{cases}f_2,\;\;\;\;\;\;({if}\;\;\; 2 \leq j \leqi)\\p^{j - 1}f_2\;\;\;(if\;\;j &gt; i)\end{cases}\]</span></p><h3 id="计算原根的方法">计算原根的方法</h3><p><strong>定理</strong>：设 <span class="math inline">\(m &gt;2\)</span>，<span class="math inline">\(\phi(m)\)</span>的所有不同的素因子是 <span class="math inline">\(q_1,q_2,...,q_s\)</span>，<span class="math inline">\((g,m) = 1\)</span>，则 <span class="math inline">\(g\)</span> 是 <span class="math inline">\(m\)</span> 的一个原根的充要条件是： <span class="math display">\[    g^{\frac{\phi(m)}{q_i}} \not \equiv 1 \;\;(mod\;m)\]</span></p><p><strong>定理</strong>：设 <span class="math inline">\(a\)</span>对模数奇素数 <span class="math inline">\(p\)</span> 的次数是 <span class="math inline">\(d\)</span>，<span class="math inline">\(d &lt; p -1\)</span>，则 <span class="math display">\[    a^\lambda,\;\;\; \lambda = 1,2,...,d\]</span> 都不是 <span class="math inline">\(p\)</span> 的原根</p><h3 id="指数">指数</h3><p><strong>定义</strong>：任一整数 <span class="math inline">\(n\)</span>，<span class="math inline">\((n,m) =1\)</span>，必有唯一的整数 <span class="math inline">\(k\)</span>，<span class="math inline">\(0 \leq k &lt; \phi(m)\)</span>，满足 <span class="math display">\[    n ≡ g^k \;\;(mod\, m)\]</span> <span class="math inline">\(k\)</span> 叫做 <span class="math inline">\(n\)</span> 对模数 <span class="math inline">\(m\)</span> 的<strong>指数</strong>，记为 <span class="math inline">\(k = ind_g n\)</span>，在不易引起混淆的情况下，把<span class="math inline">\(ind_g n\)</span>简写成 <span class="math inline">\(ind \,n\)</span>.有时也把指数叫做<strong>离散对数</strong></p><p>指数具有类似对数的性质，我们有如下定理 <strong>定理</strong>：设<span class="math inline">\(g\)</span> 是 <span class="math inline">\(m\)</span> 的原根，如果 <span class="math inline">\((a,m) = (b,m) = 1\)</span>，我们有： 1. <span class="math inline">\(ind(ab) ≡ ind\,a + ind\,b\;(mod\,m) = 1\)</span>2. <span class="math inline">\(ind\,a^n ≡ nind\,a\;(mod\, m)\)</span> 3.<span class="math inline">\(ind\,1 = 0,\,ind\,g = 1\)</span> 4. <span class="math inline">\(ind(-1) = \frac{\phi(m)}{2}\;(m &gt; 2)\)</span>5. 设 <span class="math inline">\(g_1\)</span> 也是 <span class="math inline">\(m\)</span> 的一个原根，则 <span class="math display">\[    ind_ga ≡ ind_{g_1}a \cdot ind_{g}g_1\;(mod\, \phi(m))\]</span></p><p><strong>定义</strong>：设 <span class="math inline">\(k &gt;0\)</span>，<span class="math inline">\(m &gt; 0\)</span>，一个形如<span class="math display">\[    x^k ≡ n\;(mod\, m)\]</span> 的同余式，叫做<strong>二项同余式</strong></p><p><strong>定理</strong>：设 <span class="math inline">\(m\)</span>有原根 <span class="math inline">\(g\)</span>，<span class="math inline">\((n,m) = 1\)</span>，二项同余式 <span class="math display">\[    x^k ≡ n\;(mod\, m)\]</span> 有解的充要条件是 <span class="math inline">\(d = (k,\phi(m)) |ind_gn\)</span>. 如果此同余式有解，则恰有 <span class="math inline">\(d\)</span> 个解</p>]]></content>
    
    
    <categories>
      
      <category>math</category>
      
      <category>数论</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数论</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>主成分分析</title>
    <link href="/2022/09/13/machine%20learning/PCA/PCA/"/>
    <url>/2022/09/13/machine%20learning/PCA/PCA/</url>
    
    <content type="html"><![CDATA[<h2 id="总体主成分分析">总体主成分分析</h2><p>统计分析中，数据的变量之间可能存在相关性，以致增加了分析的难度。于是考虑由少数不相关的变量代替相关变量，用来表示数据，并且要求能够保留数据中的大部分信息。</p><p>主成分分析中：</p><ul><li>首先对给定数据进行归一化，使得数据每一变量变为均值为0，方差为1.</li><li>之后对数据进行正交变换，原来由线性相关变量表示的数据通过正交变换变成由若干个线性无关的新变量表示的数据。新变量是可能的正交变换中变量的方差的和最大的，方差表示在新变量上信息的大小</li></ul><p>主成分分析的一种直观解释：数据集合中的样本由实数空间中的点表示，空间的一个坐标轴表示一个变量，规范化处理后得到的数据分布在原点附近。对原坐标系中的数据进行主成分分析等价于进行坐标系旋转变换，将数据投影到心新坐标系的坐标轴上，数据在每个轴上的坐标值的平方表示相应变量的方差；并且，这个坐标系是在所有可能的坐标系中，坐标轴上的方差的和是最大的。</p><p>在数据总体上进行的主成分分析称为总体主成分分析，在有限样本上进行的主成分分析称为样本主成分分析</p><h3 id="定义和导出">定义和导出</h3><p>假设<span class="math inline">\(\boldsymbol{x} =(x_1,x_2,...,x_m)^T\)</span>是<span class="math inline">\(\;m\;\)</span>维随机变量其均值变量是<span class="math inline">\(\boldsymbol{\mu}\)</span>： <span class="math display">\[\boldsymbol{x} = E(x) = (\mu_1,\mu_2,...,\mu_m)^T\]</span> 协方差矩阵是<span class="math inline">\(\boldsymbol{\varSigma}\)</span>： <span class="math display">\[\boldsymbol{\varSigma} = cov(\boldsymbol{x},\boldsymbol{x}) =E[(\boldsymbol{x} - \boldsymbol{\mu})((\boldsymbol{x} -\boldsymbol{\mu})^T]\]</span> 考虑由<span class="math inline">\(\;m\;\)</span>维随机变量<span class="math inline">\(\;\boldsymbol{x}\;\)</span>到<span class="math inline">\(\;m\;\)</span>维随机变量<span class="math inline">\(\;\boldsymbol{y} =(y_1,y_2,...,y_m)^T\;\)</span>的线性变换： <span class="math display">\[y_i = \boldsymbol{\alpha}_i^T\boldsymbol{x} = \alpha_{1i}x_1 +\alpha_{2i}x_2 + \,...\, + \alpha_{mi}x_m\]</span> 其中，</p><p><span class="math inline">\(\boldsymbol{\alpha}_i^T =(\alpha_{1i},\alpha_{2i},...,\alpha_{mi})\)</span>，<span class="math inline">\(i = 1,2,...,m\)</span></p><p>由随机变量的性质知： <span class="math display">\[\begin{align*}E(y_i) &amp;= \boldsymbol{\alpha}_i^T\boldsymbol{\mu} \\var(y_i) &amp;=\boldsymbol{\alpha}_i^T\boldsymbol{\varSigma}\boldsymbol{\alpha}_i \\cov(y_i,y_j) &amp;=\boldsymbol{\alpha}_i^T\boldsymbol{\varSigma}\boldsymbol{\alpha}_j\end{align*}\]</span><strong>定义(主成分分析)：</strong>给定一个线性变换，如果它们满足下列条件：</p><ol type="1"><li>系数向量<span class="math inline">\(\boldsymbol{\alpha}_i^T\)</span>是单位向量</li><li>变量<span class="math inline">\(y_i\)</span>和<span class="math inline">\(y_j\)</span>互不相关，即<span class="math inline">\(cov(y_i,y_j) = 0(i \neq j)\)</span></li><li>变量<span class="math inline">\(y_i\)</span>按照<span class="math inline">\(\boldsymbol{x}\)</span>所有线性变化中方差最大的第i个，这时<span class="math inline">\(y_i\)</span>称为第i主成分</li></ol><h3 id="主要性质">主要性质</h3><p>首先叙述一个关于总体主成分的定理。这一定理阐述了总体主成分与协方差矩阵的特征值与特征向量的关系，同时给出了一个求主成分的方法。</p><p><strong>定理：</strong>设<span class="math inline">\(\,\boldsymbol{x}\,\)</span>是<span class="math inline">\(\,m\,\)</span>维随机变量，<span class="math inline">\(\boldsymbol{\varSigma}\)</span>是<span class="math inline">\(\,\boldsymbol{x}\,\)</span>的协方差矩阵，<span class="math inline">\(\boldsymbol{\varSigma}\,\)</span>的特征值分别是<span class="math inline">\(\lambda_1 \geq \lambda_2 \geq ... \geq\lambda_m\geq 0\)</span>，特征值对应的单位特征向量分别是<span class="math inline">\(\boldsymbol{\alpha_1},\boldsymbol{\alpha_2},...,\boldsymbol{\alpha_m}\)</span>，则<span class="math inline">\(\,\boldsymbol{x}\,\)</span>的第k主成分是： <span class="math display">\[y_k = \boldsymbol{\alpha_k}^T\boldsymbol{x} = \alpha_{1k}x_1 +\alpha_{2k}x_2 + ... + \alpha_{mk}x_m\]</span> <span class="math inline">\(\boldsymbol{x}\,\)</span>的第k主成分的方差是：<span class="math display">\[var(y_k) =\boldsymbol{\alpha_k}^T\boldsymbol{\varSigma}\boldsymbol{\alpha_k} =\lambda_k\]</span> 即协方差矩阵的第k个特征值</p><p>总体主成分的性质如下：</p><ol type="1"><li>总体主成分<span class="math inline">\(\,\boldsymbol{y}\,\)</span>的协方差矩阵是对角矩阵</li><li>总体主成分<span class="math inline">\(\,\boldsymbol{y}\,\)</span>的方差之和等于随机变量<span class="math inline">\(\,\boldsymbol{x}\,\)</span>的方差之和，即</li></ol><p><span class="math display">\[\sum_{i = 1}^m \lambda_i = \sum_{i = 1}^m \sigma_{ii}\]</span></p><ol start="3" type="1"><li>第k个主成分<span class="math inline">\(y_k\)</span>与变量<span class="math inline">\(x_i\)</span>的相关系数<span class="math inline">\(\,\rho(y_k,x_i)\,\)</span>称为因子负荷量，它表示第k个主成分<span class="math inline">\(y_k\)</span>与变量<span class="math inline">\(x_i\)</span>的相关关系。计算公式是</li></ol><p><span class="math display">\[\rho(y_k,x_i) = \frac{\sqrt{\lambda_k}\alpha_{ik}}{\sqrt{\sigma_{ii}}}\]</span></p><p>因为 <span class="math display">\[\rho(y_k,x_i) = \frac{cov(y_k,x_i)}{\sqrt{var(y_k)var(x_i)}} =\frac{cov(\boldsymbol{\alpha}_k^T\boldsymbol{x},\boldsymbol{e}_i^T\boldsymbol{x})}{\sqrt{\lambda_k}\sqrt{\sigma_{ii}}}\]</span> 其中，<span class="math inline">\(\,\boldsymbol{e}_i\,\)</span>为基本单位向量。</p><ol start="4" type="1"><li>第i个主成分<span class="math inline">\(y_k\)</span>与<span class="math inline">\(m\)</span>个变量因子的负荷量满足：</li></ol><p><span class="math display">\[\sum_{i = 1}^m \sigma_{ii}\rho^2(y_k,x_i) = \lambda_k\]</span></p><ol start="5" type="1"><li>m个主成分与第i个变量<span class="math inline">\(x_i\)</span>的因子负荷量满足：</li></ol><p><span class="math display">\[\sum_{k = 1}^m \rho^2(y_k,x_i) = 1\]</span></p><p>由于<span class="math inline">\(y_1,y_2,...,y_m\)</span>互不相关且<span class="math inline">\(x_i\)</span>可被<span class="math inline">\(\boldsymbol{y}\)</span>表示，故 <span class="math display">\[\rho^2(x_i,(y_1,...,y_m)) = \sum_{k = 1}^m \rho^2(y_k,x_i) = 1\]</span></p>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>奇异值分解</title>
    <link href="/2022/09/12/machine%20learning/SVD/SVD/"/>
    <url>/2022/09/12/machine%20learning/SVD/SVD/</url>
    
    <content type="html"><![CDATA[<h2 id="奇异值分解的定义与性质">奇异值分解的定义与性质</h2><h3 id="定义和定理">定义和定理</h3><p><strong>定义(奇异值分解)：</strong>矩阵的奇异值分解是指将一个非0的<span class="math inline">\(m\times n\)</span>实矩阵<span class="math inline">\(\mathbf{A}\)</span>，<span class="math inline">\(\mathbf{A} \in \mathbf{R}^{m\timesn}\)</span>，表示为以下三个实矩阵乘积形式的运算，即进行矩阵的因子分解：<span class="math display">\[\mathbf{A} = \mathbf{U\varSigma V^T}\]</span> 其中，<span class="math inline">\(\mathbf{U}\)</span>是<span class="math inline">\(m\)</span>阶正交矩阵，<span class="math inline">\(\mathbf{V}\)</span>是<span class="math inline">\(n\)</span>阶正交矩阵，<span class="math inline">\(\varSigma\)</span>是由降序排列的非负的对角线元素组成的<span class="math inline">\(m\times n\)</span>矩形对角矩阵，满足： <span class="math display">\[\begin{align*}\mathbf{UU^T} &amp;= \mathbf{I} \\\mathbf{VV^T} &amp;= \mathbf{I} \\\varSigma &amp;= diag(\sigma_1,\sigma_2,...,\sigma_p) \\\sigma_1 \geq \sigma_2 &amp;\geq ... \geq \sigma_p \geq 0 \\p &amp;= min(m,n)\end{align*}\]</span> <span class="math inline">\(\mathbf{U\varSigmaV^T}\)</span>称为矩阵<span class="math inline">\(\mathbf{A}\)</span>的奇异值分解(sigular valuedecomposition, SVD)，<span class="math inline">\(\sigma_i\)</span>称为矩阵<span class="math inline">\(\mathbf{A}\)</span>的奇异值，<span class="math inline">\(\mathbf{U}\)</span>的列向量被称为左奇异向量，<span class="math inline">\(\mathbf{V}\)</span>的列向量被称为右奇异向量</p><p>注意到奇异值分解不要求原矩阵为方阵，事实上奇异值分解可看作是对方阵对角化的推广</p><p>矩阵的奇异值分解不一定是唯一的(这是因为其左右奇异向量均为两个特定空间的正交向量，其可能可以通过线性组合组成新的左右奇异向量从而构成新的奇异值分解)</p><p><strong>定理(奇异值分解基本定理)</strong>：若<span class="math inline">\(\mathbf{A}\)</span>为一个<span class="math inline">\(m\times n\)</span>实矩阵，<span class="math inline">\(\mathbf{A} \in \mathbf{R}^{m\timesn}\)</span>，则<span class="math inline">\(\mathbf{A}\)</span>的奇异值分解存在： <span class="math display">\[\mathbf{A} = \mathbf{U}\varSigma V^T\]</span> 其中，<span class="math inline">\(\mathbf{U}\)</span>是<span class="math inline">\(m\)</span>阶正交矩阵，<span class="math inline">\(\mathbf{V}\)</span>是<span class="math inline">\(n\)</span>阶正交矩阵，<span class="math inline">\(\varSigma\)</span>是由降序排列的非负的对角线元素组成的<span class="math inline">\(m\timesn\)</span>矩形对角矩阵，其对角线元素按降序排列</p><h3 id="紧奇异值分解与截断奇异值分解">紧奇异值分解与截断奇异值分解</h3><p>上述的奇异值分解给出的是完全奇异值分解，实际上我们常用的是奇异值分解的紧凑形式和截断形式。紧奇异值分解是与原始矩阵等秩的奇异值分解；截断奇异值分解是比原始矩阵低秩的奇异值分解</p><h4 id="紧奇异值分解">紧奇异值分解</h4><p><strong>定义：</strong>设有<span class="math inline">\(m\timesn\)</span>的实矩阵<span class="math inline">\(\mathbf{A}\)</span>，其秩为<span class="math inline">\(rank(A) = r\)</span>，<span class="math inline">\(r \leq min(m,n)\)</span>，则称<span class="math inline">\(\mathbf{U}_r\varSigma_r\mathbf{V}_r^T\)</span>为<span class="math inline">\(\mathbf{A}\)</span>的紧奇异值分解，即： <span class="math display">\[\mathbf{A} = \mathbf{U}_r\varSigma_r\mathbf{V}_r^T\]</span> 其中，<span class="math inline">\(\mathbf{U}_r\)</span>是<span class="math inline">\(m\times r\)</span>矩阵，<span class="math inline">\(\mathbf{V}_r\)</span>是<span class="math inline">\(n\times r\)</span>矩阵，<span class="math inline">\(\varSigma_r\)</span>是<span class="math inline">\(r\)</span>阶对角矩阵，矩阵<span class="math inline">\(U_r\)</span>由完全奇异值分解种<span class="math inline">\(\mathbf{U}\)</span>的前r列、矩阵<span class="math inline">\(\mathbf{V}_r\)</span>由<span class="math inline">\(\mathbf{V}\)</span>的前r列、矩阵<span class="math inline">\(\varSigma_{r}\)</span>由<span class="math inline">\(\varSigma\)</span>的前<span class="math inline">\(r\)</span>个对角线元素得到，紧奇异值分解的对角矩阵<span class="math inline">\(\varSigma_{r}\)</span>的秩与原始矩阵<span class="math inline">\(\mathbf{A}\)</span>的秩相等</p><h4 id="截断奇异值分解">截断奇异值分解</h4><p>在矩阵的奇异值分解中，只取最大的<span class="math inline">\(k\)</span>个奇异值（<span class="math inline">\(k&lt; r\)</span>，<span class="math inline">\(r\)</span>为矩阵的秩）对应的部分，就得到矩阵的截断奇异值分解。实际应用中提到矩阵的奇异值分解时，通常指截断奇异值分解</p><p><strong>定义：</strong>设有<span class="math inline">\(m\timesn\)</span>的实矩阵<span class="math inline">\(\mathbf{A}\)</span>，其秩为<span class="math inline">\(rank(A) = r\)</span>，<span class="math inline">\(0 &lt; k &lt; r\)</span>，则称<span class="math inline">\(\mathbf{U}_k\varSigma_k\mathbf{V}_k^T\)</span>为<span class="math inline">\(\mathbf{A}\)</span>的截断奇异值分解，即： <span class="math display">\[\mathbf{A} \approx \mathbf{U}_k\varSigma_k\mathbf{V}_k^T\]</span> 其中，<span class="math inline">\(\mathbf{U}_k\)</span>是<span class="math inline">\(m\times k\)</span>矩阵，<span class="math inline">\(\mathbf{V}_k\)</span>是<span class="math inline">\(n\times k\)</span>矩阵，<span class="math inline">\(\varSigma_r\)</span>是<span class="math inline">\(k\)</span>阶对角矩阵，矩阵<span class="math inline">\(U_k\)</span>由完全奇异值分解种<span class="math inline">\(\mathbf{U}\)</span>的前k列、矩阵<span class="math inline">\(\mathbf{V}_k\)</span>由<span class="math inline">\(\mathbf{V}\)</span>的前k列、矩阵<span class="math inline">\(\varSigma_{k}\)</span>由<span class="math inline">\(\varSigma\)</span>的前<span class="math inline">\(k\)</span>个对角线元素得到，截断奇异值分解的对角矩阵<span class="math inline">\(\varSigma_{k}\)</span>的秩比原始矩阵<span class="math inline">\(\mathbf{A}\)</span>的秩小</p><p><strong>奇异值分解的意义</strong>：相当于对一个矩阵依次做一次旋转变换(<span class="math inline">\(\mathbf{U}\)</span>)，一次缩放变换(<span class="math inline">\(\varSigma\)</span>)，一次旋转变换(<span class="math inline">\(V\)</span>)</p><h3 id="奇异值分解的主要性质">奇异值分解的主要性质</h3><ol type="1"><li>若有奇异值分解<span class="math inline">\(\mathbf{A} =\mathbf{U\varSigma V^T}\)</span>，则以下关系成立：</li></ol><p><span class="math display">\[\begin{align*}A^TA &amp;= \mathbf{V}(\varSigma^T\varSigma)\mathbf{V}^T \\AA^T &amp;= \mathbf{U}^(\varSigma\varSigma^T)\mathbf{U}\end{align*}\]</span></p><ol start="2" type="1"><li>在矩阵等奇异值分解中，奇异值、左奇异向量、右奇异向量之间存在对应关系：</li></ol><p><span class="math display">\[\begin{align*}\mathbf{AV} &amp;= \mathbf{U}\varSigma \\\mathbf{A}^T\mathbf{U} &amp;= \mathbf{V}\varSigma^T\end{align*}\]</span></p><ol start="3" type="1"><li>矩阵<span class="math inline">\(\mathbf{A}\)</span>的奇异值分解中，奇异值<span class="math inline">\(\sigma_1,\sigma_2,...,\sigma_n\)</span>是唯一的，而矩阵<span class="math inline">\(\mathbf{U},\mathbf{V}\)</span>不唯一</li><li>矩阵<span class="math inline">\(\mathbf{U}\)</span>和<span class="math inline">\(\varSigma\)</span>等秩，等于正奇异值的个数(包含重复的奇异值)</li><li>矩阵<span class="math inline">\(\mathbf{A}\)</span>的r个右奇异向量<span class="math inline">\(v_1,v_2,...,v_r\)</span>构成<span class="math inline">\(\mathbf{A}^T\)</span>的值域<span class="math inline">\(R(\mathbf{A}^T)\)</span>的一组标准正交基</li></ol>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>决策树</title>
    <link href="/2022/09/07/machine%20learning/decisiontree/decisiontree/"/>
    <url>/2022/09/07/machine%20learning/decisiontree/decisiontree/</url>
    
    <content type="html"><![CDATA[<h2 id="决策树模型和学习">决策树模型和学习</h2><p><strong>定义：</strong>分类决策树模型是一种描述对实例进行分类的树形结构。决策树由节点和有向边组成。结点有两种类型：内部结点和叶结点。内部结点表示一个特征或属性，叶结点表示一个类</p><h3 id="决策树的if-then规则">决策树的if-then规则</h3><p>可以将决策树看成一个if-then规则的集合。将决策树转换成if-then规则的规则如下：由决策树的根结点到叶结点的每一条路径构建一条规则；路径上内部结点的特征对应规则的条件，而叶结点的类对应规则的结论。决策树的路径或其对应的if-then规则集合具有一个重要的性质：<strong>互斥而且完备</strong>。这就是说，每一个实例都被一条路径或一条规则所覆盖，而且只被一条路径或一条规则所覆盖。这里所谓的覆盖指的是实例的特征与路径上的特征一致或实例满足规则的条件。</p><h3 id="决策树与条件概率分布">决策树与条件概率分布</h3><p>决策树表示给定特征条件下类的条件概率分布。其意思是，我们通过设定一些关于条件的约束，这些关于条件的约束将特征空间划分为互不相交的单元或区域，并在每一个单元定义一个类的概率分布就构成了一个条件概率分布。决策树下的一条路径就对应了一个单元。决策树所表示的条件概率分布由各个单元给定条件下类的条件概率分布组成。</p><p>举例说明：假设X为表示特征的随机变量，Y为表示类的随机变量，那么这个条件概率分布可以表示为<span class="math inline">\(P(X|Y)\)</span>。X取值于给定划分下单元的集合，Y取值于类的集合。各叶结点(单元)上的条件概率往往偏向于某一个类。决策树分类时将该结点的实例强行分到条件概率大的那一类</p><h3 id="决策树学习">决策树学习</h3><p>决策树学习的目标是根据给定的训练数据集构建一个决策树模型，使它能够对实例进行正确的分类</p><p>决策树学习的本质是从训练数据集中归纳出一组分类规则。与训练数据集不相矛盾的决策树可能有多个，也可能一个都没有。我们需要的是一个与训练数据矛盾较小的决策树，同时拥有不错的泛化能力。从另一个角度看，决策树学习是由训练数据集估计条件概率模型。基于特征空间划分的类的条件概率模型有无穷多个。我们选择的条件概率模型应该不仅对训练数据有很好的拟合，而且对未知数据有很好的预测</p><p>决策树学习用损失函数表示这一目标；通常用正则化的极大似然函数来作为损失函数，决策树学习的策略是以损失函数为目标函数的最小化</p><p>决策树的学习算法通常是递归地选择最优特征，并根据该特征对训练数据进行划分；这样构造出的决策树对训练数据有着很好的分类能力，但是可能会出现过拟合现象，所以我们也需要对已生成的树进行剪枝，将树变得更简单，从而具有更好的泛化能力。具体来说就是去掉过分细分的叶结点，使其回退到父结点甚至更高的结点，然后将父结点或更高的结点改为新的叶结点</p><h2 id="特征选择">特征选择</h2><h3 id="信息增益">信息增益</h3><p><strong>熵：</strong>熵是表示随机变量不确定性的度量。设X是一个取值有限个值的离散随机变量，其概率分布为：<span class="math display">\[P(X = x_i) = p_i\]</span> 则随机变量X的熵定义为： <span class="math display">\[H(X) = -\sum_{i = 1}^{n}\;p_i\,log\,p_i\]</span>通常上式中的对数以2或e为底，这时熵的单位分别称作比特或纳特。由定义可知，熵只依赖于X的分布，与X的取值无关</p><p>熵的大小和随机变量的不确定性成正比，从定义可以验证： <span class="math display">\[0 \leq H(p) \leq log\,n\]</span> 设有随机变量(X,Y)，其联合概率分布为 <span class="math display">\[P(X = x_i, Y = y_i) = p_{ij}\]</span> 条件熵<span class="math inline">\(H(Y|X)\)</span>表示在已知随机变量X的条件下随机变量Y的不确定性。随机变量X给定的条件下随机变量Y的条件熵<span class="math inline">\(H(Y|X)\)</span>定义为X给定条件下Y的条件概率分布的熵对X的数学期望：<span class="math display">\[H(Y|X) = \sum_{i = 1}^{n}p_iH(Y|X = x_i)\]</span> 这里的<span class="math inline">\(p_i = P(X =x_i)\)</span></p><p>当熵和条件熵中的概率由数据估计(特别是极大似然估计)得到时，所对应的熵与条件熵分别称为经验熵和经验条件熵。此时如果有0概率，令<span class="math inline">\(0log0 = 0\)</span></p><p><strong>定义(信息增益)：</strong>特征A对训练数据集D的信息增益<span class="math inline">\(g(D,A)\)</span>定义为集合D的经验熵<span class="math inline">\(H(D)\)</span>与特征A给定条件下D的经验条件熵<span class="math inline">\(H(D|A)\)</span>之差，即： <span class="math display">\[g(D,A) = H(D) - H(D|A)\]</span> 一般地，熵<span class="math inline">\(H(Y)\)</span>与条件熵<span class="math inline">\(H(Y|X)\)</span>之差称为互信息。决策树学习中的信息增益等价于训练数据集中类与特征的互信息。决策树学习应用信息准则选择特征，这是因为信息增益表示了给定特征条件后相较于原来数据集不确定性减少的程度。根据信息增益准则的特征选择方法是：对训练数据集(或子集)D，计算其每个特征的信息增益，并比较大小，选择信息增益最大的特征。</p><p><strong>算法(信息增益的算法)：</strong></p><p>输入：训练数据集D和特征A</p><p>输出：特征A对训练数据集D的信息增益<span class="math inline">\(g(D,A)\)</span></p><ol type="1"><li>计算数据集D的经验熵<span class="math inline">\(H(D)\)</span>:</li></ol><p><span class="math display">\[H(D) = -\sum_{k = 1}^{K}\frac{|C_k|}{|D|}log_2\;\frac{|C_k|}{|D|}\]</span></p><ol start="2" type="1"><li>计算特征A对数据集D的经验条件熵<span class="math inline">\(H(D|A)\)</span>：</li></ol><p><span class="math display">\[H(D|A) = \sum_{i = 1}^{n}\frac{|D_i|}{D}H(D_i) = -\sum_{i =1}^{n}\frac{|D_i|}{|D|}\sum_{k =1}^{K}\frac{|D_{ik}|}{|D_i|}log_2\;\frac{|D_{ik|}}{|D_i|}\]</span></p><ol start="3" type="1"><li>计算信息增益<span class="math inline">\(g(D,A)\)</span>：</li></ol><p><span class="math display">\[g(D,A) = H(D) - H(D|A)\]</span></p><p><strong>信息增益比：</strong>特征A对训练数据集D的信息增益比<span class="math inline">\(g_R(D,A)\)</span>定义为其信息增益<span class="math inline">\(g(D,A)\)</span>与训练数据集D关于特征A的值的熵<span class="math inline">\(H_A(D)\)</span>之比： <span class="math display">\[g_R(D,A) = \frac{g(D,A)}{H_A(D)}\]</span> 其中，<span class="math inline">\(H_A(D) = -\sum_{i =1}^{n}\frac{|D_i|}{|D|}log_2\,\frac{|D_i|}{|D|}\)</span>，n是特征A取值的个数</p><h2 id="决策树的生成">决策树的生成</h2><h3 id="id3算法">ID3算法</h3><p>ID3算法核心是在决策树各个结点上应用信息增益准则选择特征，递归地构建决策树。具体方法是：从根结点开始，对结点计算所有可能的特征的信息增益，选择信息增益最大的特征作为结点的特征，由该特征的不同取值建立子结点；再对子结点递归地调用以上方法构建决策树；直到所有特征的信息增益均很小或没用特征可以选择为止，最后得到一颗决策树。ID3相当于用极大似然法进行概率模型的选择。</p><p><strong>ID3算法：</strong></p><p>输入：训练数据集D，特征集A和阈值<span class="math inline">\(\epsilon\)</span></p><p>输出：决策树T</p><ol type="1"><li>若D中所有实例属于同一类<span class="math inline">\(C_k\)</span>，则<span class="math inline">\(T\)</span>为单结点树，并将类<span class="math inline">\(C_k\)</span>作为该结点的类标记，返回<span class="math inline">\(T\)</span></li><li>若<span class="math inline">\(A = \emptyset\)</span>，则<span class="math inline">\(T\)</span>为单结点树，并将类<span class="math inline">\(C_k\)</span>作为该结点的类标记，返回<span class="math inline">\(T\)</span></li><li>否则，按信息增益算法计算A中各特征对D的信息增益，选择信息增益最大的特征<span class="math inline">\(A_g\)</span></li><li>如果<span class="math inline">\(A_g\)</span>的信息增益小于阈值<span class="math inline">\(\epsilon\)</span>，则置<span class="math inline">\(T\)</span>为单结点树，并将D中实例最大的类<span class="math inline">\(C_k\)</span>作为该结点的类标记，返回<span class="math inline">\(T\)</span></li><li>否则，对<span class="math inline">\(A_g\)</span>的每一可能值<span class="math inline">\(a_i\)</span>将D分割为若干非空子集<span class="math inline">\(D_i\)</span>，将<span class="math inline">\(D_i\)</span>中实例数最大的类作为标记，构建子结点，由结点及其子结点构成树<span class="math inline">\(T\)</span>，返回<span class="math inline">\(T\)</span></li><li>对第i个子结点，以<span class="math inline">\(D_i\)</span>为训练集，以<span class="math inline">\(A-\{A_g\}\)</span>为特征集，递归地调用前五步，得到子树<span class="math inline">\(T_i\)</span>，返回<span class="math inline">\(T_i\)</span></li></ol><h3 id="c4.5生成算法">C4.5生成算法</h3><p><strong>C4.5 的生成算法</strong>：</p><p>输入：训练数据集D，特征集A和阈值<span class="math inline">\(\epsilon\)</span></p><p>输出：决策树T</p><ol type="1"><li>若D中所有实例属于同一类<span class="math inline">\(C_k\)</span>，则<span class="math inline">\(T\)</span>为单结点树，并将类<span class="math inline">\(C_k\)</span>作为该结点的类标记，返回<span class="math inline">\(T\)</span></li><li>若<span class="math inline">\(A = \emptyset\)</span>，则<span class="math inline">\(T\)</span>为单结点树，并将类<span class="math inline">\(C_k\)</span>作为该结点的类标记，返回<span class="math inline">\(T\)</span></li><li>否则，按信息增益算法计算A中各特征对D的信息增益比，选择信息增益最大的特征<span class="math inline">\(A_g\)</span></li><li>如果<span class="math inline">\(A_g\)</span>的信息增益小于阈值<span class="math inline">\(\epsilon\)</span>，则置<span class="math inline">\(T\)</span>为单结点树，并将D中实例最大的类<span class="math inline">\(C_k\)</span>作为该结点的类标记，返回<span class="math inline">\(T\)</span></li><li>否则，对<span class="math inline">\(A_g\)</span>的每一可能值<span class="math inline">\(a_i\)</span>，依<span class="math inline">\(A_g =a_i\)</span>将D分割为若干非空子集<span class="math inline">\(D_i\)</span>，将<span class="math inline">\(D_i\)</span>中实例数最大的类作为标记，构建子结点，由结点及其子结点构成的树<span class="math inline">\(T\)</span>，返回<span class="math inline">\(T\)</span></li><li>对结点i，以<span class="math inline">\(D_i\)</span>为训练集，以<span class="math inline">\(A-\{A_g\}\)</span>为特征集，递归地调用前五步，得到子树<span class="math inline">\(T_i\)</span>，返回<span class="math inline">\(T_i\)</span></li></ol><h2 id="决策树的剪枝">决策树的剪枝</h2><p>决策树生成算法递归地产生决策树，直到不能继续为止。这样生成的树汪汪队训练数据的分类很准确，但对未知测试数据的分类却没有那么准确，即出现过拟合现象。过拟合的原因是因为在构造决策树时过多的考虑如何提高对训练数据的正确分类，从而构造出过于复杂的决策树。解决方案是考虑决策树的复杂度，对已生成的决策树进行简化。</p><p>在决策树学习中将已生成的树进行简化的过程称为剪枝。这里介绍一种简单但决策树学习的剪枝算法。</p><p>决策树的剪枝往往通过极小化决策树整体的损失函数来实现。设树<span class="math inline">\(T\)</span>的叶结点个数为<span class="math inline">\(|T|\)</span>，t是树T的叶结点，该叶结点有<span class="math inline">\(N_t\)</span>个样本点，其中k类的样本点<span class="math inline">\(N_{tk}\)</span>个，<span class="math inline">\(H_t(T)\)</span>为叶结点t上的经验熵，<span class="math inline">\(\alpha \geq0\)</span>为参数，则决策树学习的损失函数可以定义为： <span class="math display">\[C_{\alpha}(T) = \sum_{t = 1}^{|T|}N_tH_t(T) + \alpha|T|\]</span> 其中经验熵为： <span class="math display">\[H_t(T) = -\sum_{k}\frac{N_{tk}}{N_t}\,log\,\frac{N_{tk}}{N_t}\]</span> 在损失函数中，原式右端第一项可改写为： <span class="math display">\[C(T) = \sum_{t = 1}^{|T|}N_tH_t(T) = -\sum_{t = 1}^{|T|}\sum_{k =1}^{K}N_{tk}\,log\,\frac{N_{tk}}{N_t}\]</span> 这时有： <span class="math display">\[C_{\alpha}(T) = C(T) + \alpha|T|\]</span> 上式中<span class="math inline">\(C(T)\)</span>表示模型对训练数据的预测误差(拟合程度)，<span class="math inline">\(|T|\)</span>表示模型复杂度，参数<span class="math inline">\(\alpha\)</span>控制两者之间的影响，参数大小与模型的复杂度成反比。</p><p>剪枝指当参数<span class="math inline">\(\alpha\)</span>确定时，选择损失函数最好的模型，即损失函数最小的子树。可以看出，决策树生成只考虑了通过提高信息增益对训练数据进行更好的拟合，而决策树剪枝通过优化损失函数还考虑了减小模型复杂度。决策树生成学习局部的模型，决策树剪枝学习整体的模型。</p><p><strong>决策树剪枝算法：</strong></p><p>输入：生成算法产生的整个树T,参数<span class="math inline">\(\alpha\)</span></p><p>输出：修剪后的子树<span class="math inline">\(T_\alpha\)</span></p><ol type="1"><li><p>计算每个结点的经验熵</p></li><li><p>递归地从树的叶结点向上回缩</p><p>假设一组叶结点回缩到其父结点之前与之后的整体树分别为<span class="math inline">\(T_B\)</span>和<span class="math inline">\(T_A\)</span>，其对应的损失函数的值分别为<span class="math inline">\(C_\alpha(T_B)\)</span>和<span class="math inline">\(C_\alpha(T_A)\)</span>，若： <span class="math display">\[C_\alpha(T_A) \leq C_\alpha(T_B)\]</span></p></li></ol><p>则进行剪枝，即将父结点变为新的叶结点</p><ol start="3" type="1"><li>返回步骤2，直到不能继续为止，得到损失函数最小的子树<span class="math inline">\(T_\alpha\)</span></li></ol><p><strong>注意，剪枝时只需要考虑两个树的损失函数的差，其计算可以在局部进行。所以树的剪枝算法可由动态规划实现</strong></p>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>线性模型</title>
    <link href="/2022/09/07/machine%20learning/linearmodel/linearmodel/"/>
    <url>/2022/09/07/machine%20learning/linearmodel/linearmodel/</url>
    
    <content type="html"><![CDATA[<h2 id="基本形式">基本形式</h2><p>给定一个由 <span class="math inline">\(d\)</span> 个属性描述的示例<span class="math inline">\(x =(x_1,x_2,...,x_d)\)</span>，线性模型通过学习一个属性的线性组合来建立一个预测样本的函数，即：<span class="math display">\[f(x) = (\sum_{i = 1}^n w_ix_i) + b\]</span> 将其写为向量形式为： <span class="math display">\[f(x) = w^Tx + b\]</span> 或者我们可以将 <span class="math inline">\(x\)</span>扩展一维，其属性值为<span class="math inline">\(x_{n + 1} =1\)</span>，这个属性的 <span class="math inline">\(w_{n + 1}\)</span>值为1，用来替代 <span class="math inline">\(b\)</span></p><h2 id="线性回归">线性回归</h2><p>给定一个数据集，线性回归尝试学得一个线性模型来尽可能准确地预测输出标记；由上述线性模型的基本形式，我们要做的就是确定<span class="math inline">\(w\)</span> 和 <span class="math inline">\(b\)</span> 的取值来尽可能地使得我们定义的损失函数<span class="math inline">\(\ell\)</span>，我们以均方损失为例讨论整个学习的过程。</p><p>我们要求得一组参数使得均方损失最小： <span class="math display">\[\begin{align*}(w^*,b^*) &amp;= arg_{(w,b)}min \sum_{i = 1}^{m}(f(x_i) - y_i)^2 \\\end{align*}\]</span></p>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Chap3 解析函数的积分表示</title>
    <link href="/2022/08/09/fubianChap3/"/>
    <url>/2022/08/09/fubianChap3/</url>
    
    <content type="html"><![CDATA[<h2 id="复变函数的积分">复变函数的积分</h2><p>我们约定以下提到的曲线(包括简单曲线)都是光滑或逐段光滑的</p><p><strong>定义</strong>：设<span class="math inline">\(C\)</span>是平面上一条有向曲线，其起点是<span class="math inline">\(z_0\)</span>，终点是<span class="math inline">\(Z\)</span>，<span class="math inline">\(f(z)\)</span>是定义在<span class="math inline">\(C\)</span>上的单值函数，任意用一列分点 <span class="math display">\[z_k = x_k + iy_k\]</span> 把曲线分为<span class="math inline">\(n\)</span>个小段，在每个小段上任取点<span class="math inline">\(\zeta_k\)</span>作和 <span class="math display">\[\sum_{k = 1}^{n} f(\zeta_k)\Delta z_k\]</span> 记<span class="math inline">\(\lambda = max_k |\Deltaz_k|\)</span>，如果当<span class="math inline">\(\lambda\rightarrow0\)</span>时，上述和的极限存在，而且其值与弧段的分法和各<span class="math inline">\(\zeta_k\)</span>的取法无关，就称这个极限为<span class="math inline">\(f(z)\)</span>沿曲线<span class="math inline">\(C\)</span>自<span class="math inline">\(z_0\)</span>到<span class="math inline">\(Z\)</span>的积分，记作 <span class="math display">\[\int_{C} f(z)dz\]</span> <strong>定理</strong>：设<span class="math inline">\(f(z) =u(x,y) + iv(x,y)\)</span>在曲线<span class="math inline">\(C\)</span>上连续，则复积分<span class="math inline">\(\int_{C} f(z)dz\)</span>存在，而且 <span class="math display">\[\mathop{\int}_{C}f(z)dz = \mathop{\int}_{C}u(x,y)dx - v(x,y)dy +i\mathop{\int}_{C}v(x,y)dx + u(x,y)dy\]</span> 从前述的C-R方程和现在的积分法则可以看出，<span class="math inline">\(u(x,y)dx\)</span>和<span class="math inline">\(v(x,y)dy\)</span>相关，<span class="math inline">\(v(x,y)dx\)</span>和<span class="math inline">\(u(x,y)dy\)</span>相关。这是因为 <span class="math display">\[\begin{align*}f(z)dz &amp;=(u(x,y) + iv(x,y))(\Delta x + i\Delta y) \\&amp;= (u(x,y)\Delta x - v(x,y)\Delta y) + i(u(x,y)\Delta y +v(x,y)\Delta x)\end{align*}\]</span> 同理求导运算时也应满足C-R方程，这是相关的</p><p>一些曲线积分的基本性质对复积分仍然成立：</p><ul><li>如果<span class="math inline">\(k\)</span>为复常数，则</li></ul><p><span class="math display">\[\mathop{\int}_{C}kf(z)dz = k\mathop{\int}_{C}f(z)dz\]</span></p><ul><li><span class="math inline">\(\int_{C}[f(z) + g(z)]dz = \int_C f(z)dz+ \int_{C}g(z)dz\)</span></li><li><span class="math inline">\(\int_{C}f(z)dz =-\int_{C^-}f(z)dz\)</span></li><li>如果曲线<span class="math inline">\(C\)</span>由<span class="math inline">\(C_1\)</span>和<span class="math inline">\(C_2\)</span>组成，则：</li></ul><p><span class="math display">\[\mathop{\int}_{C}f(z)dz = \mathop{\int}_{C_1} f(z)dz +\mathop{\int}_{C_2}f(z)dz\]</span></p><h3 id="长大不等式">长大不等式</h3><p>在复变函数的许多论证和计算中，常要用到下面不等式的积分估计.设<span class="math inline">\(f(z)\)</span>在曲线<span class="math inline">\(C\)</span>上连续，则： <span class="math display">\[|\mathop{\int}_{C}f(z)dz\;| \leq \mathop{\int}_{C}|\;f(z)\;|\,ds\]</span> 特别地，若在曲线<span class="math inline">\(C\)</span>上有<span class="math inline">\(|f(z)|\leq M\)</span>，曲线<span class="math inline">\(C\)</span>的长为<span class="math inline">\(l\)</span>，则上式有： <span class="math display">\[|\mathop{\int}_{C}f(z)dz\;| \leq Ml\]</span> 该式即为长大不等式</p><h2 id="柯西积分定理">柯西积分定理</h2><p>复变函数中积分与积分的路径有关，那么何时积分与路径无关？柯西积分定理就解决了该问题</p><p>今后把简单闭曲线叫做闭路，如非特别声明，凡沿闭路积分都是按正向(逆时针方向)取的</p><p><strong>定理(柯西积分定理)</strong>：设<span class="math inline">\(D\)</span>是由闭路<span class="math inline">\(C\)</span>所围成的单连通区域，<span class="math inline">\(f(z)\)</span>在闭域<span class="math inline">\(\bar{D} = C + D\)</span>上解析，则 <span class="math display">\[\mathop{\int}_{C}f(z)dz = 0\]</span> 这里，所谓<span class="math inline">\(f(z)\)</span>在闭域<span class="math inline">\(\bar{D}\)</span>上解析，是指存在区域<span class="math inline">\(G\)</span>，使得<span class="math inline">\(\bar{D} \subset G\)</span>，且<span class="math inline">\(f(z)\)</span>在<span class="math inline">\(G\)</span>内解析</p><p><strong>推论1</strong>：设<span class="math inline">\(f(z)\)</span>在单连通域<span class="math inline">\(D\)</span>内解析，<span class="math inline">\(C\)</span>是<span class="math inline">\(D\)</span>内的任意封闭曲线，则 <span class="math display">\[\mathop{\int}_{C}f(z)dz = 0\]</span> <strong>推论2</strong>：设<span class="math inline">\(f(z)\)</span>在单连通域<span class="math inline">\(D\)</span>内解析，<span class="math inline">\(C\)</span>是<span class="math inline">\(D\)</span>内任一条起于点<span class="math inline">\(z_0\)</span>而终于点<span class="math inline">\(z\)</span>的简单曲线，则积分 <span class="math display">\[\mathop{\int}_{C}f(\zeta)d\zeta\]</span> 的值不依赖于积分路径<span class="math inline">\(C\)</span>，而只由<span class="math inline">\(z_0\)</span>和<span class="math inline">\(z\)</span>确定.所以这个积分也可记作 <span class="math display">\[\int_{z_0}^{z}f(\zeta)d\zeta\]</span> <strong>定理</strong>：(多连通区域的柯西积分定理) 设<span class="math inline">\(f(z)\)</span>在复闭路<span class="math inline">\(C=C_0 + C_1^- + C_2^- + ... +C_n^-\)</span>及其所围成的多连通区域内解析，则 <span class="math display">\[\mathop{\int}_{C}f(z)dz = \mathop{\int}_{C_1}f(z)dz +\mathop{\int}_{C_2}f(z)dz + ... +\mathop{\int}_{C_n}f(z)dz\]</span> 或 <span class="math display">\[\mathop{\int}_{C}f(z)dz = 0\]</span></p><h2 id="柯西积分公式">柯西积分公式</h2><p><strong>定理1</strong>：设函数<span class="math inline">\(f(z)\)</span>在闭路(或复闭路)<span class="math inline">\(C\)</span>及其所围区域<span class="math inline">\(D\)</span>内解析，则对<span class="math inline">\(D\)</span>内任意一点<span class="math inline">\(z\)</span>，有 <span class="math display">\[f(z) = \frac{1}{2\pi i}\mathop{\int}_{C}\frac{f(\zeta)}{\zeta - z}d\zeta\]</span> <strong>定理2</strong>：在定理1的条件下，对于区域<span class="math inline">\(D\)</span>内的任一点<span class="math inline">\(z\)</span>，<span class="math inline">\(f(z)\)</span>有任意阶导数，且 <span class="math display">\[f^{(n)}(z) = \frac{n!}{2\pi i}\mathop{\int}_{C}\frac{f(\zeta)}{(\zeta -z)^{n + 1}}d\zeta\]</span> 这个公式也叫柯西积分公式</p><h2 id="原函数">原函数</h2><p><strong>定义</strong>：如果在区域<span class="math inline">\(D\)</span>内有<span class="math inline">\(F&#39;(z) = f(z)\)</span>，则<span class="math inline">\(F(z)\)</span>称为<span class="math inline">\(f(z)\)</span>在区域<span class="math inline">\(D\)</span>内的一个原函数</p><p><strong>定理1</strong>：设<span class="math inline">\(f(z)\)</span>在单连通区域<span class="math inline">\(D\)</span>内连续，且对<span class="math inline">\(D\)</span>内任意闭路<span class="math inline">\(C\)</span>，有<span class="math inline">\(\int_{C}f(z)dz = 0\)</span>.那么，由变上限的积分所确定的函数 <span class="math display">\[F(z) = \int_{z_0}^{z}f(z)dz\]</span> (<span class="math inline">\(z_0\)</span>是<span class="math inline">\(D\)</span>内一定点)是<span class="math inline">\(D\)</span>内的解析函数，而且 <span class="math display">\[F&#39;(z) = f(z)\;\;(z \in D)\]</span> <strong>推论1</strong>：设<span class="math inline">\(f(z)\)</span>在单连通区域<span class="math inline">\(D\)</span>内解析，则定理1的结论成立</p><p><strong>推论2</strong>：在推论1的条件下，对<span class="math inline">\(f(z)\)</span>的任一原函数<span class="math inline">\(H(z)\)</span>，有牛顿-莱布尼茨公式 <span class="math display">\[F(z) = \int_{z_0}^{z}f(z)dz = H(z) - H(z_0)\]</span> <strong>定理2</strong>：(Morera定理)在定理1的条件下，<span class="math inline">\(f(z)\)</span>是<span class="math inline">\(D\)</span>内的解析函数.</p><h2 id="解析函数与调和函数的关系">解析函数与调和函数的关系</h2><p><strong>定义</strong>：如果实二次函数<span class="math inline">\(u(x,y)\)</span>在区域<span class="math inline">\(D\)</span>内有二阶连续偏导数，且在<span class="math inline">\(D\)</span>内满足拉普拉斯(Laplace)方程 <span class="math display">\[\frac{\partial^2 u}{\partial x^2} + \frac{\partial^2 u}{\partial y^2} =0\]</span> 则称<span class="math inline">\(u(x,y)\)</span>是域<span class="math inline">\(D\)</span>内的调和函数.</p><p><strong>定理1</strong>：设<span class="math inline">\(f(z) = u(x,y) +iv(x,y)\)</span>在域<span class="math inline">\(D\)</span>内解析，那么它的实部<span class="math inline">\(u\)</span>及虚部<span class="math inline">\(v\)</span>都是<span class="math inline">\(D\)</span>内的调和函数</p><p><strong>定理2</strong>：设<span class="math inline">\(f(z) = u +iv\)</span>是一解析函数，且<span class="math inline">\(f&#39;(z) \neq0\)</span>，那么等值曲线簇 <span class="math display">\[u(x,y) = K_1\]</span> 与 <span class="math display">\[v(x,y) = K_2\]</span> 在其公共点上永远是互相正交的，这里<span class="math inline">\(K_1\)</span>和<span class="math inline">\(K_2\)</span>为常数</p><p><strong>定理3</strong>：设<span class="math inline">\(u(x,y)\)</span>是单连通区域<span class="math inline">\(D\)</span>内的调和函数，则由曲线积分所确定的函数<span class="math display">\[v(x,y) = \int_{(x_0,y_0)}^{(x,y)} - \frac{\partial u}{\partial y}dx +\frac{\partial u}{\partial x}dy + C\]</span> 使得<span class="math inline">\(f(z) = u(x,y) +iv(x,y)\)</span>在<span class="math inline">\(D\)</span>内解析，其中，<span class="math inline">\((x,y)\)</span>是<span class="math inline">\(D\)</span>内任一点，<span class="math inline">\((x_0,y_0)\)</span>是<span class="math inline">\(D\)</span>内一定点，<span class="math inline">\(C\)</span>是实常数</p>]]></content>
    
    
    <categories>
      
      <category>math</category>
      
      <category>复变函数</category>
      
    </categories>
    
    
    <tags>
      
      <tag>复变函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>EM算法</title>
    <link href="/2022/08/07/machine%20learning/EMAlgorithm/EMAlgorithm/"/>
    <url>/2022/08/07/machine%20learning/EMAlgorithm/EMAlgorithm/</url>
    
    <content type="html"><![CDATA[<h2 id="琴生不等式jensens-inequality">琴生不等式(Jensen'sInequality)</h2><p><strong>凸函数</strong>：对函数<span class="math inline">\(f\)</span>和其定义域内任意的<span class="math inline">\(x\)</span>，均有<span class="math inline">\(f&#39;&#39;(x) \geq0\)</span>，则我们称该函数为凸函数；当函数的输入为一个向量<span class="math inline">\((x_1,x_2,...,x_n)\)</span>时，我们称当该函数的海塞矩阵<span class="math inline">\(H\)</span>为半正定矩阵时，该函数为凸函数</p><p><strong>琴生不等式</strong>：对凸函数<span class="math inline">\(f\)</span>，我们有 <span class="math display">\[E[f(x)] \geq f(E[x])\]</span> 等号当且仅当<span class="math inline">\(x\)</span>取值概率为1时成立；当<span class="math inline">\(f\)</span>为凹函数时，我们有： <span class="math display">\[E[f(x)] \leq f(E[x])\]</span> 同理，等号当且仅当<span class="math inline">\(x\)</span>取值概率为1时成立</p><h2 id="em算法">EM算法</h2><p><strong>输入</strong>：观测变量数据<span class="math inline">\(Y\)</span>，隐变量<span class="math inline">\(Z\)</span>，联合分布<span class="math inline">\(p(y,z|\theta)\)</span>，条件分布<span class="math inline">\(p(z|y,\theta)\)</span></p><p><strong>输出</strong>：模型参数<span class="math inline">\(\theta\)</span></p><p>算法步骤：</p><ul><li>选择参数初值<span class="math inline">\(\theta_0\)</span>，开始迭代</li><li>E-step(Expectation)：记<span class="math inline">\(\theta^{(i)}\)</span>为第i次迭代参数<span class="math inline">\(\theta\)</span>的估计值，在第i +1次迭代的E步，计算</li></ul><p><span class="math display">\[\begin{align*}Q(\theta,\,\theta^{(i)}) &amp;=E_Z[log\,p(y,z|\theta)\,|\,y,\theta^{(i)}] \\&amp;= \sum_{Z}log\,p(y,z|\theta)p(z|y,\theta^{(i)})\end{align*}\]</span></p><ul><li>M-step(Maximization)：求使得<span class="math inline">\(Q(\theta,\,\theta^{(i)})\)</span>极大化的<span class="math inline">\(\theta\)</span>，确定第i +1次迭代的参数的估计值<span class="math inline">\(\theta^{(i +1)}\)</span></li></ul><p><span class="math display">\[\theta^{(i + 1)} = arg\,\mathop{max}_\theta \,Q(\theta,\theta^{(i)})\]</span></p><ul><li>重复第2步和第3步，直到收敛</li></ul><p>几点说明：</p><ul><li>模型参数<span class="math inline">\(\theta\)</span>可任意选取，<strong>但是EM算法对初值是敏感的</strong></li><li>Q函数式中<span class="math inline">\(Z\)</span>式未观测数据，<span class="math inline">\(Y\)</span>是观测数据。注意，<span class="math inline">\(Q(\theta,\theta^{(i)})\)</span>的第一个变元表示要极大化的参数，第二个边缘表示参数当前的估计值。每次迭代实际在求Q函数及其极大值</li><li>停止迭代的条件：</li></ul><p><span class="math display">\[||\theta^{(i + 1)} - \theta^{(i)}|| &lt; \epsilon \;\;或\;\;||Q(\theta^{(i + 1)},\theta^{(i)}) - Q(\theta^{(i )},\theta^{(i)})||&lt; \epsilon\]</span></p><h2 id="em算法的介绍与推导">EM算法的介绍与推导</h2><h3 id="em算法介绍">EM算法介绍</h3><p>在给定样本估计参数且参数为单个参数时，我们知道可用极大似然估计来估计参数；但此时我们存在一个隐变量，这时我们无法通过极大似然估计来求出解析解，于是我们通过EM算法来解决显/隐变量相互依赖的关系，通过赋初值迭代优化直到收敛的方式来解决参数的估计问题</p><p>EM算法的思路是使用启发式的迭代方法，由于我们没办法直接求出模型分布参数，我们可以先猜想隐含参数(E-step)，然后基于观测数据和隐含参数来极大化似然函数，求解参数(M-step)，然后不断循环迭代此过程，直到参数收敛即得到结果</p><h3 id="em算法推导">EM算法推导</h3><p>我们要最大化似然函数，故参数满足： <span class="math display">\[\theta = arg\,\mathop{max}_{\theta}\,\sum_{i =1}^{n}\,log\,p(y^{(i)}|\theta)\]</span> 添加隐变量<span class="math inline">\(z\)</span>后，问题变为：<span class="math display">\[\theta = arg\,\mathop{max}_{\theta,z}\,\sum_{i =1}^{n}log\sum_{z^{(i)}}p(y^{(i)},z^{(i)} |\theta)\]</span> 对朴素的最大似然估计来说，此时的不同在于多了一个隐变量<span class="math inline">\(z\)</span>，那么最朴素的想法是对<span class="math inline">\(\theta\)</span>求偏导来得到极大似然估计的参数结果，但是对上式求导得到的边缘密度形式会非常复杂，很难求解。于是我们想到用琴生不等式将log内部的求和符号提出，于是有：<span class="math display">\[\begin{align*}\sum_{i = 1}^{n}log\sum_{z^{(i)}}p(y^{(i)},z^{(i)} |\theta) &amp;=\sum_{i =1}^{n}log\sum_{z^{(i)}}Q_i(z^{(i)})\frac{p(y^{(i)},z^{(i)}|\theta)}{Q_i(z^{(i)})}\\&amp;\geq \sum_{i =1}^{n}\sum_{z^{(i)}}Q_i(z^{(i)})log\frac{p(y^{(i)},z^{(i)}|\theta)}{Q_{i}(z^{(i)})}\end{align*}\]</span> 上式引入了一个新的分布<span class="math inline">\(Q_i(z^{(i)})\)</span>，满足 <span class="math display">\[\sum_{z}Q_i(z) = 1,\;0\leq Q_i(z) \leq 1\]</span>由于使用了琴生不等式，我们给出了极大似然函数的一个下界，我们对此下界不断进行优化，当这个值收敛时说明取到了区域极值(这也是为什么可能与取的初值有关)</p><p>需要注意的是，我们在应用琴生不等式时需要保证不等式的等号成立，而等号成立条件为取值概率为1，即：<span class="math display">\[\frac{p(y^{(i)},z^{(i)}|\theta)}{Q_i(z^{(i)})} = c\]</span> 其中c是一个常数，我们进行累和可知： <span class="math display">\[\sum_{z}p(y^{(i)},z^{(i)}|\theta) = c\sum_{z}Q_i(z^{(i)})\]</span> 由于右式累和的结果为1，所以有： <span class="math display">\[\sum_{z}p(y^{(i)},z^{(i)}|\theta) = c\\Q_i(z^{(i)}) = \frac{p(y^{(i)},z^{(i)}|\theta)}{c} =\frac{p(y^{(i)},z^{(i)}|\theta)}{\sum_z p(y^{(i)},z^{(i)}|\theta)} =\frac{p(y^{(i)},z^{(i)}|\theta)}{p(y^{(i)}|\theta)} =p(z^{(i)}|y^{(i)},\theta)\]</span> 所以我们要优化的函数为 <span class="math display">\[\sum_{i =1}^{n}\sum_{z^{(i)}}Q_i(z^{(i)})log\frac{p(y^{(i)},z^{(i)}|\theta)}{Q_{i}(z^{(i)})}\]</span> 注意到： <span class="math display">\[\sum_{i = 1}^{n}\sum_{z^{(i)}}Q_i(z^{(i)})log\,{Q_{i}(z^{(i)})}\]</span> 为常数，所以最后参数<span class="math inline">\(\theta\)</span>的优化为： <span class="math display">\[\theta = arg\,\mathop{max}_{\theta}\sum_{i =1}^{n}\sum_{z^{(i)}}p(z^{(i)}|y^{(i)},\theta)log\,{p(y^{(i)},z^{(i)}|\theta)}\]</span></p><h2 id="em算法的收敛性">EM算法的收敛性</h2><h3 id="收敛性证明">收敛性证明</h3><p>我们有： <span class="math display">\[log\,p(y|\theta) = log\,p(y,z|\theta) - log\,p(z|y,\theta)\]</span> 两边同时求期望得： <span class="math display">\[E_{z|y,\theta^{(t)}}[log\,p(y|\theta)] =E_{z|y,\theta^{(t)}}[log\,p(y,z|\theta)] -E_{z|y,\theta^{(t)}}[log\,p(z|x,\theta)]\]</span> 等式左侧与<span class="math inline">\(Z\)</span>无关，故取期望值不变</p><p>等式右侧第一项即为<span class="math inline">\(Q(\theta,\theta^{(t)})\)</span>，由我们对EM算法的推导可知：<span class="math display">\[Q(\theta^{(t + 1)},\theta^{(t)}) \geq Q(\theta^{(t)},\theta^{(t)})\]</span> 然后我们来看第二项，由上所述，我们有<span class="math inline">\(Q(\theta^{(t + 1)},\theta^{(t)}) \geqQ(\theta^{(t)},\theta^{(t)})\)</span>，那么只需要保证： <span class="math display">\[E_{z|y,\theta^{(t)}}[log\,p(z|y,\theta^{(t + 1)})] \leqE_{z|y,\theta^{(t)}}[log\,p(z|y,\theta^{(t)})]\]</span> 注意到上式是<span class="math inline">\(z\)</span>和<span class="math inline">\(y\)</span>的DL散度定义，故显然成立</p><p>所以说明EM算法是收敛的，但收敛值为局部最佳，且与初值的选取有关</p>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Chap2 复变数函数</title>
    <link href="/2022/08/02/%E5%A4%8D%E5%8F%98%E5%87%BD%E6%95%B0/chap2/"/>
    <url>/2022/08/02/%E5%A4%8D%E5%8F%98%E5%87%BD%E6%95%B0/chap2/</url>
    
    <content type="html"><![CDATA[<h2 id="复变数函数">复变数函数</h2><p><strong>定义</strong>：设<span class="math inline">\(E\)</span>是复平面上的一个点集，若对于<span class="math inline">\(E\)</span>中每一个点<span class="math inline">\(z\)</span>，按一定规律有一个复数<span class="math inline">\(w\)</span>与之对应，则称在<span class="math inline">\(E\)</span>上定义了一个复单值函数，记作<span class="math inline">\(w = f(z)\; (z \in E)\)</span>；如果对于自变量<span class="math inline">\(z\)</span>的一个值，按规律对应的<span class="math inline">\(w\)</span>不止一个，则称<span class="math inline">\(w = f(z)\)</span>为多值函数</p><p><strong>定义</strong>：设<span class="math inline">\(w =f(z)\)</span>，是集合<span class="math inline">\(E\)</span>上的单值函数，如果对于<span class="math inline">\(E\)</span>中的任意两个不同点<span class="math inline">\(z_1\)</span>和<span class="math inline">\(z_2\)</span>，它们在(函数值)集合<span class="math inline">\(E&#39;\)</span>中对应的点<span class="math inline">\(w_1 = f(z_1)\)</span>及<span class="math inline">\(w_2 = f(z_2)\)</span>，则称<span class="math inline">\(w = f(z)\)</span>是集<span class="math inline">\(E\)</span>中的一个一一映射.</p><h2 id="函数的极限与连续性">函数的极限与连续性</h2><p><strong>定义</strong>：设函数<span class="math inline">\(w =f(z)\)</span>在点<span class="math inline">\(z_0\)</span>的某个去心邻域<span class="math inline">\(0 &lt; |z - z_0| &lt;\rho\)</span>内有定义，而且实极限： <span class="math display">\[\mathop{lim}_{z\rightarrow z_0}\;|\;f(z) - w_0\;| = 0\]</span> 就称当<span class="math inline">\(z\)</span>趋于<span class="math inline">\(z_0\)</span>时 <span class="math inline">\(f(z)\)</span> 的极限值为 <span class="math inline">\(w_0\)</span> ，记作 <span class="math display">\[\mathop{lim}_{z\rightarrow z_0}\,f(z) = w_0\]</span> 这个定义在几何上意味着：当变点进入<span class="math inline">\(z_0\)</span>的一个充分小的<span class="math inline">\(\delta\)</span>邻域hi时，它们的像点就落入一个<span class="math inline">\(w_0\)</span>的一个给定的<span class="math inline">\(\epsilon\)</span>邻域</p><p><strong>定义</strong>：如果等式 <span class="math display">\[\mathop{lim}_{z\rightarrow z_0}\,f(z) = f(z_0)\]</span> 成立，就称函数<span class="math inline">\(f(z)\)</span>在点<span class="math inline">\(z_0\)</span>连续.如果<span class="math inline">\(f(z)\)</span>在区域<span class="math inline">\(D\)</span>中的每个点都连续，就称<span class="math inline">\(f(z)\)</span>在区域<span class="math inline">\(D\)</span>中连续</p><p><strong>定理</strong>：函数<span class="math inline">\(f(z) = u(x,y)+ iv(x,y)\)</span>在点<span class="math inline">\(z_0 = x_0 +iy_0\)</span>处连续的充要条件时<span class="math inline">\(u(x,y)\)</span>和<span class="math inline">\(v(x,y)\)</span>作为二元函数在<span class="math inline">\((x_0,y_0)\)</span>处连续</p><h2 id="导数和解析函数">导数和解析函数</h2><p>复变函数的导数的概念从形式上看与实变函数的导数概念完全相同</p><p><strong>定义</strong>：设<span class="math inline">\(w =f(z)\)</span>在点<span class="math inline">\(z\)</span>的某个邻域<span class="math inline">\(U\)</span>内有定义，<span class="math inline">\(z\,+\, \Delta z \in U\)</span>.如果极限 <span class="math display">\[\mathop{lim}_{\Delta z \rightarrow 0}\;\frac{f(z + \Delta z) -f(z)}{\Delta z}\]</span> 存在，就称函数<span class="math inline">\(f(z)\)</span>在点<span class="math inline">\(z\)</span>可微，而且这个极限称为<span class="math inline">\(f(z)\)</span>在点<span class="math inline">\(z\)</span>的导数或微商，记为<span class="math inline">\(f&#39;(z)\)</span>，<span class="math inline">\(\frac{df}{dz}\)</span>或<span class="math inline">\(\frac{dw}{dz}\)</span>，即： <span class="math display">\[f&#39;(z) = \mathop{lim}_{\Delta z\rightarrow 0}\frac{f(z + \Delta z) -f(z)}{\Delta z}\]</span> 设<span class="math inline">\(f(z)\)</span>在点<span class="math inline">\(z\)</span>可微： <span class="math display">\[a = \frac{f(z + \Delta z) - f(z)}{\Delta z} - f&#39;(z)\]</span> 则有： <span class="math display">\[\mathop{lim}_{\Delta z\rightarrow 0} a = 0\]</span> <strong>定义</strong>：如果<span class="math inline">\(f(z)\)</span>在区域<span class="math inline">\(D\)</span>内的每一点可微，则称<span class="math inline">\(f(z)\)</span>在<span class="math inline">\(D\)</span>内解析，或者说<span class="math inline">\(f(z)\)</span>是<span class="math inline">\(D\)</span>内的解析函数；如果<span class="math inline">\(f(z)\)</span>在点<span class="math inline">\(z_0\)</span>的某一邻域内可微，则称<span class="math inline">\(f(z)\)</span>在点<span class="math inline">\(z_0\)</span>解析；如果<span class="math inline">\(f(z)\)</span>在点<span class="math inline">\(z_0\)</span>不解析，则<span class="math inline">\(z_0\)</span>称为<span class="math inline">\(f(z)\)</span>的奇点</p><p>由定义可见，函数的解析性概念是和一个区域联系在一起的.即使是说到<span class="math inline">\(f(z)\)</span>在点<span class="math inline">\(z_0\)</span>解析，也是指它在<span class="math inline">\(z_0\)</span>的某个邻域内解析，由于区域是开集，所以函数在区域内解析和函数在区域内每一点解析的说法是等价的.解析函数是复变函数中一类加了很强条件的函数，它有许多完美的性质.</p><p><strong>复变函数的求导法则与实变函数相同</strong></p><h2 id="柯西-黎曼方程">柯西-黎曼方程</h2><p><strong>定理</strong>：函数<span class="math inline">\(f(z) = u(x,y)+ iv(x,y)\)</span>在点<span class="math inline">\(z = x +iy\)</span>可微的充要条件是：</p><ol type="1"><li>二元函数<span class="math inline">\(u(x,y),v(x,y)\)</span>在点<span class="math inline">\((x,y)\)</span>可微</li><li><span class="math inline">\(u(x,y)\)</span>及<span class="math inline">\(v(x,y)\)</span>在点<span class="math inline">\((x,y)\)</span>满足柯西-黎曼方程(简称C-R方程)</li></ol><p><span class="math display">\[\begin{align*}\frac{\partial u}{\partial x} &amp;= \frac{\partial v}{\partial y} \\\frac{\partial u}{\partial y} &amp;= -\frac{\partial v}{\partial x}\end{align*}\]</span></p><p><strong>定理</strong>：函数<span class="math inline">\(f(z) = u(x,y)+ iv(x,y)\)</span>在区域<span class="math inline">\(D\)</span>内可微(即在<span class="math inline">\(D\)</span>内解析)的充要条件：</p><ol type="1"><li>二元函数<span class="math inline">\(u(x,y)\)</span>及<span class="math inline">\(v(x,y)\)</span>在<span class="math inline">\(D\)</span>内可微</li><li><span class="math inline">\(u(x,y)\)</span>及<span class="math inline">\(v(x,y)\)</span>在<span class="math inline">\(D\)</span>内处处满足C-R方程</li></ol><p>求导数的时候可直接用： <span class="math display">\[\begin{align*}f&#39;(z) &amp;= \frac{\partial u}{\partial x} + i\frac{\partialv}{\partial x}\end{align*}\]</span></p>]]></content>
    
    
    <categories>
      
      <category>math</category>
      
      <category>复变函数</category>
      
    </categories>
    
    
    <tags>
      
      <tag>复变函数</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>马尔可夫决策过程</title>
    <link href="/2022/08/01/machine%20learning/mdp/mdp/"/>
    <url>/2022/08/01/machine%20learning/mdp/mdp/</url>
    
    <content type="html"><![CDATA[<p>马尔可夫过程需要一些随机过程前置知识，即马尔可夫性，马尔可夫链，状态转移矩阵等，较为简略在此不过多详述，百度即可</p><h2 id="马尔可夫奖励过程">马尔可夫奖励过程</h2><p><strong>马尔可夫奖励过程</strong>是马尔可夫链+奖励函数。状态及状态转移无变化；奖励函数是一个期望，表示当我i们到达某一个状态时可以获得多少的奖励</p><h3 id="回报和价值函数">回报和价值函数</h3><p>这里定义：<strong>范围</strong>是指一个回合的长度(每个回合最大的时间步数)，它是由有限个步数决定的；<strong>回报</strong>是指把奖励进行折扣后所获得的奖励。</p><p>汇报可以定义为奖励的逐步叠加，即： <span class="math display">\[G_t = r_{t + 1} + \gamma r_{t + 2} +\gamma^2 r_{t + 3} + ...+\gamma^{T -t - 1}r_T\]</span> 这里有一个折扣因子<span class="math inline">\(\gamma\)</span>，越往后得到的奖励，折扣越多；说明我们更希望得到现有的奖励，对未来的奖励要打折扣。</p><p>当我们定义了回报，就可以定义状态的价值了，即<strong>状态价值函数</strong>。对马尔可夫奖励过程，状态价值函数被定义成回报的期望：<span class="math display">\[\begin{align*}V^t(s) &amp;= E[G_t\;|\;s_t = s] \\&amp;= E[r_{t + 1} + \gamma r_{t + 2} +\gamma^2 r_{t + 3} +...+\gamma^{T - t - 1}r_T \; | \; s_t = s]\end{align*}\]</span> 这个期望的意义是：从当前这个状态开始，可能获得多大的价值。</p><p><strong>设置折扣因子的原因</strong>：</p><ul><li>有些马尔可夫过程是存在环的，它会带来无穷奖励，而这正是我们想避免的</li><li>我们并不能保证模型是完美模拟环境的，所以对未来评估要打折扣(类似于防止过拟合)</li><li>如果奖励是有实际价值的，我们可能希望立刻获得奖励，而不是后面再得到奖励(对未来奖励的折扣因子可以按需求进行调整)</li></ul><p>在计算一个状态的价值函数时，我们可以通过计算所有轨迹的期望来算出当前状态的价值(蒙特卡洛方法)，而还有一种方法是通过下文介绍的贝尔曼方程进行计算</p><h3 id="贝尔曼方程">贝尔曼方程</h3><p><strong>贝尔曼方程</strong>： <span class="math display">\[V(s) = R(s) \;+\;\gamma\sum_{s&#39; \in S}p(s&#39;|\,s)V(s&#39;)\]</span> 等式右侧第一项为即时奖励，第二项为未来奖励的折扣总和</p><p>这里我们详细解释第二项：</p><ul><li><span class="math inline">\(p(s&#39;|\,s)\)</span>是指从当前状态转移到未来状态的概率</li><li><span class="math inline">\(V(s&#39;)\)</span>代表的是未来某一个价值的状态</li></ul><p>这样通过求和相当于求出了在这个状态跳往其他状态的价值期望，再乘折扣因子即可</p><p>我们可以把贝尔曼方程写为矩阵形式并直接求解： <span class="math display">\[\begin{align*}V &amp;= R \, + \,\gamma PV \\(I - \gamma P)V &amp;= R \\V &amp;= (I - \gamma P)^{-1}R\end{align*}\]</span> 这样我们直接得到了<span class="math inline">\(V\)</span>的解析解，我们可以直接进行计算，但当状态过多时不便于求解(计算开销过大)，所以只适用于少量状态的马尔可夫奖励过程</p><p>贝尔曼方程的推导： <span class="math display">\[\begin{align*}V^t(s) &amp;= E[G_t\;|\;s_t = s] \\&amp;= E[r_{t + 1} + \gamma r_{t + 2} +\gamma^2 r_{t + 3} + ...\; | \;s_t = s] \\&amp;= R(s) + \gamma E[r_{t + 1} + \gamma r_{t + 2} +\gamma^2 r_{t + 3}+ ...\; | \; s_t = s] \\&amp;= R(s) + \gamma E[G_{t + 1} | s_t = s]\end{align*}\]</span></p><h2 id="马尔可夫决策过程">马尔可夫决策过程</h2><p>相对于马尔可夫奖励过程，马尔可夫决策过程多了决策，其他定义类似。此外状态转移也多一个条件：<span class="math inline">\(p(s_{t +1}=s&#39;\,|\,s_t=s\,,\,a_t)\)</span>；未来的状态不仅依赖于当前点状态，也依赖于在当前状态智能体采取的动作，马尔可夫决策过程满足条件：<span class="math display">\[p(s_{t + 1}\,|\,s_t,a_t) = p(s_{t + 1}\,|\,h_t,a_t)\]</span> 对于奖励函数，它也多了一个当前动作，变成了<span class="math inline">\(R(s_t = s,a_t = a) = E[r_t\,|\,s_t = s,a_t =a]\)</span>。当前状态以及采取的动作会决定智能体在当前可能得到的奖励的多少</p><h3 id="马尔可夫决策过程中的策略">马尔可夫决策过程中的策略</h3><p>策略定义了在某一个状态应该采取什么样的动作。知道当前状态后，我们可以把当前状态带入策略函数来得到一个概率：<span class="math display">\[\pi(a\;|\;s) = p(a_t = a\,|\,s_t = s)\]</span>概率代表在所有可能的动作中怎样采取行动。另外策略也可能时确定的，它有可能直接输出一个值，或者直接告诉我们当前应该采取怎么样的动作，而不是一个动作的概率</p><p>已知马尔可夫决策过程和策略<span class="math inline">\(\pi\)</span>，我们可以把马尔可夫决策过程转换成马尔可夫奖励过程。在马尔可夫决策过程中，状态转移函数<span class="math inline">\(p(s&#39;|s,a)\)</span>基于它当前的状态以及它当前的动作。因为我们现在已知策略函数，也就是已知在每一个状态下可能采取的动作的概率，所以我们就可以直接把动作进行加和，去掉<span class="math inline">\(a\)</span>，这样我们就可u得到对于马尔可夫奖励过程的转移，这里就没有动作，即<span class="math display">\[p_{\pi}(s&#39;\,|\,s) = \sum_{a \in A}\pi(a\,|\,s)p(s&#39;|s,a)\]</span>对于奖励函数，我们也可以把动作去掉，这样就会得到类似于马尔可夫奖励过程的奖励函数：<span class="math display">\[R_{\pi}(s) = \sum_{a \in A}\pi(a\,|\,s)R(s,a)\]</span></p><h3 id="马尔可夫决策过程与马尔可夫奖励过程的区别">马尔可夫决策过程与马尔可夫奖励过程的区别</h3><ul><li>马尔可夫奖励过程：从一个状态跳转到另一个状态时，只需要考虑转移概率即可</li><li>马尔可夫决策过程：从一个状态跳转到另一个状态时，需要先考虑策略得到决策a，再通过决策a转移到新状态s</li></ul><h3 id="马尔可夫决策过程的状态函数">马尔可夫决策过程的状态函数</h3><p>马尔可夫决策过程中的价值函数可类似于马尔可夫奖励过程来定义： <span class="math display">\[V_{\pi} = E_{\pi}[G_t\,|\,s_t = s]\]</span> 其中的期望基于我们采取的策略<span class="math inline">\(\pi\)</span>，当策略决定后，我们通过对策略进行采样来得到一个期望，计算出它的价值函数</p><p>这里我们引入一个<strong>Q函数</strong>，Q函数也被称为<strong>动作价值函数</strong>。Q函数定义的时在某一个状态采取某一个动作，有可能得到的回报的一个期望，即：<span class="math display">\[Q_\pi(s,a) = E_\pi[G_t\,|\,s_t = s,a_t = a]\]</span>这里的期望也是基于策略函数的。所以我们就需要对策略函数进行一个加和并得到它的价值，对Q函数的中的动作进行加和就得到价值函数：<span class="math display">\[V_\pi(s) = \sum_{a \in A}\pi(a\,|\,s)Q_\pi(s,a)\]</span></p><h3 id="贝尔曼期望方程">贝尔曼期望方程</h3><p>我们可以将状态价值函数和Q函数拆解成两个部分：即时奖励和后续状态的折扣价值。通过对状态价值函数进行分解，我们就可以得到一个类似于之前马尔可夫奖励过程的贝尔曼方程——<strong>贝尔曼期望方程</strong><span class="math display">\[V_{\pi}(s) = E_{\pi}[r_{t + 1} + \gamma V_{\pi}(s_{t + 1})\,|\,s_t=s]\]</span> 对于Q函数，我们也可以做类似的分解，得到Q函数的贝尔曼期望方程：<span class="math display">\[Q_{\pi}(s,a) = E_{\pi}[r_{t + 1} + \gamma Q_{\pi}(s_{t + 1},a_{t +1})\,|\,s_t = s,a_t = a]\]</span> 贝尔曼方程定义了当前状态和未来状态之间的关联</p><p>我们进一步分解期望方程，有： <span class="math display">\[V_{\pi}(s) = \sum_{a \in A} \pi(a\,|\,s)(R(s,a) + \gamma \sum_{s&#39;\in S}p(s&#39;\,|\,s,a)V_{\pi}(s&#39;))\]</span> 上式代表当前状态价值和未来状态价值之间的关联</p><p>于是我们可以得到Q函数的表达： <span class="math display">\[Q_{\pi}(s,a) = R(s,a) + \gamma\sum_{s&#39;\in S}p(s&#39;\,|\,s,a)\sum_{a\in A}\pi(a&#39;\,|\,s&#39;)Q_{\pi}(s&#39;,a&#39;)\]</span> 同样的，上式代表当前时刻的Q函数和未来时刻的Q函数之间的关联</p><p>上两式也是贝尔曼期望方程的另一种表示形式</p><h3 id="策略评估">策略评估</h3><p>已知马尔可夫决策过程以及要采取的策略<span class="math inline">\(\pi\)</span>，计算价值函数<span class="math inline">\(V_\pi(s)\)</span>的过程就是<strong>策略评估</strong>，策略评估有时也被称为<strong>(价值)预测</strong>，也就是预测我们当前采取的策略最终会产生多少价值。</p><h3 id="预测和控制">预测和控制</h3><p>预测和控制是马尔可夫决策过程的核心问题</p><ul><li>预测(评估一个给定的策略)的输入是马尔可夫决策过程&lt;<span class="math inline">\(S,A,P,R,\gamma\)</span>&gt;和策略<span class="math inline">\(\pi\)</span>，输出是价值函数<span class="math inline">\(V_{\pi}\)</span>。预测是指给定一个马尔科夫决策过程和一个策略，计算它的价值函数，也就是每个状态的价值</li><li>控制(搜索最佳策略))的输入是马尔可夫决策过程&lt;<span class="math inline">\(S,A,P,R,\gamma\)</span>&gt;，输出是最佳价值函数<span class="math inline">\(V^*\)</span>和最佳策略<span class="math inline">\(\pi^*\)</span>，控制就是我们去寻找一个最佳的策略，然后同时输出它的最佳价值函数以及最佳策略</li></ul><p>这两个问题都可以通过动态规划的方法来解决，需要强调的是，这两者的区别在于，预测问题是给定一个策略，我们要确定它的价值函数。而控制问题是在没有策略的前提下，我们要确定最佳的价值函数以及对应的决策方案。实际上，这两者是递进的关系，我们通过解决预测问题，进而解决控制问题</p><h3 id="动态规划">动态规划</h3><p>动态规划适合解决具有最优子结构和重叠子问题两个性质的问题。最优子结构意味着问题可以拆分成一个个小问题，通过解决这些小问题来得到原问题的答案，即最优解。重叠子问题意味着，子问题出现多次，并且子问题的解决方案能够被重复使用，我们可以保存子问题的首次计算结果，在再次需要时直接使用</p><p>马尔可夫决策过程满足动态规划的要求，在贝尔曼方程中我们可以把它分解成递归的结构。当我们把它分解成递归的结构的时候，如果子问题的子状态能够得到一个值，那么它的未来状态因为与子状态是直接相关的，我们也可以将其推算出来。价值函数可以存储并重用子问题的最佳的解。动态规划应用于马尔可夫决策过程的规划问题而不是学习问题，我们必须对环境是完全已知的，才能做动态规划，也就是要知道状态转移概率和对应的奖励。是用动态规划完成预测问题和控制问题的求解，是解决马尔可夫决策过程预测问题和控制问题的非常有效的方式</p><h3 id="使用动态规划进行策略评估">使用动态规划进行策略评估</h3><p>策略评估就是给定马尔可夫决策过程和策略，评估我们可以获得多少价值，即对于当前策略，我们可以得到多大的价值。我们可以直接把<strong>贝尔曼期望备份</strong>变成迭代的过程，反复迭代直到收敛。这个过程可以看作<strong>同步备份</strong>的过程</p><p>同步备份和异步备份：</p><ul><li>同步备份是指每一次的迭代都会完全更新所有的状态，这对于程序资源的需求特别大</li><li>异步备份就是通过某种方式，使得每一次迭代不需要更新所有的状态，因为事实上也不是所有状态都需要更新</li></ul><p><span class="math display">\[V_{t + 1}(s) = \sum_{a \in A}\pi(a\,|\,s)(R(s,a) + \gamma \sum_{s&#39;\in S}p(s&#39;|s,a)V_t(s&#39;))\]</span></p><p>上式说明求解<span class="math inline">\(V_\pi(s)\)</span>的过程可以进行动态规划，可以对每个<span class="math inline">\(V_t(s)\)</span>进行求解，反复迭代直到价值函数的值收敛。由于给定了策略函数，我们可以将它简化为马尔科夫奖励过程的形式，即把策略去掉：<span class="math display">\[V_{t + 1}(s) = R_{\pi}(s) + \gamma p_{\pi}(s&#39;\,|\,s)V_{t}(s&#39;)\]</span>这样迭代的式子中就只有价值函数和状态转移函数了。通过该式我们也可以得到每个状态的价值，因为在马尔可夫奖励/决策过程中，价值函数包含的变量都只与状态有关。它表示智能体进入某一个状态，未来可能得到多大的价值</p><h3 id="马尔可夫决策过程控制">马尔可夫决策过程控制</h3><p>策略评估是指给定马尔可夫决策过程和策略，估算价值函数的值。如果我们只有马尔可夫决策过程，那么如何寻找最佳策略从而得到<strong>最佳价值函数</strong>呢？</p><p>最佳函数的数学定义为： <span class="math display">\[V^*(s) = \mathop{max}_\pi\; V_{\pi}(s)\]</span>最佳函数是指，我们搜索一种策略让每个状态的价值最大，在这种情况下我们得到的策略就是最佳策略：<span class="math display">\[\pi^*(s) = arg \,\mathop{max}_{\pi}\,V_\pi(s)\]</span>最佳策略使得每个状态的价值都得到最大值。所以我们如果可以得到一个最佳价值函数，就可以认为某一个马尔可夫决策过程环境可解。在这种情况下，最佳函数是一致的，环境中可达到的上限的值是一致的，但这里可能有多个最佳策略，多个最佳策略能够取得相同的最佳价值。</p><p>当取得最佳价值函数后，我们可以通过对Q函数最大化的方式来得到最佳策略：当Q函数取得最大值时，令<span class="math inline">\(\pi^*(a \,|\, s) = 1\)</span>，否则为0</p><p>当Q函数收敛后，因为Q函数时关于状态与动作的函数，所以如果在某个状态采取某个动作可以使Q函数最大化，那么这个动作就是最佳动作。如果我们能优化出一个Q函数，就可以直接在Q函数中取一个让Q函数值最大化的动作的值，就可以提取出最佳策略。</p><p>对于一个事先定好的马尔可夫决策过程，当智能体采取最佳策略的时候，最佳策略一般都是确定的，而且是稳定的(它不会随着时间的变化而变化)。但最佳策略不一定是唯一的，多种动作可能会取得相同的价值</p><p>我们可以通过策略迭代和价值迭代来解决马尔可夫决策过程的控制问题</p><h3 id="策略迭代">策略迭代</h3><p>策略迭代由两部分构成：策略评估和策略改进。第一步为策略评估，当前我们在优化策略<span class="math inline">\(\pi\)</span>，在优化过程中得到一个最新的策略。我们先保证这个策略不变，然后估计它的价值，即给定当前的策略函数来估计状态价值函数。第二步为策略改进，得到状态价值函数后，我们可以进一步推算出它的Q函数，得到Q函数后，直接对Q函数最大化，通过对Q函数做一个贪心的搜索来进一步改进策略。这两个步骤一直在迭代进行。</p><p>我们看策略改进的方法：得到状态价值函数后，我们就可以通过奖励函数以及状态转移函数来计算Q函数：<span class="math display">\[Q_{\pi_i}(s,a) = R(s,a) + \gamma \sum_{s&#39; \in S}p(s&#39;\;|\;s,a)V_{\pi_i}(s&#39;)\]</span>对每个状态，策略改进会得到它的新一轮的策略，我们取使它得到Q函数最大值的动作：<span class="math display">\[\pi_{i + 1}(s) = arg\,\mathop{max}_a\;Q_{\pi_i}(s,a)\]</span></p><h4 id="贝尔曼最优方程">贝尔曼最优方程</h4><p>当我们一直采取argmax的时候，会得到一个单调的递增。通过采取贪心操作，我们就会得到更好或不变的策略，而不会使价值函数变差，所以当改进停止后，我们就会得到一个最佳策略。当改进停止后，我们取让Q函数值最大化的动作，Q函数就会直接变成价值函数，即<span class="math display">\[Q_{\pi}(s,\pi&#39;(s)) = \mathop{max}_{a \in A}\,Q_{\pi}(s,a) =Q_{\pi}(s,\pi(s)) = V_{\pi}(s)\]</span> 我们得到<strong>贝尔曼最优方程</strong>： <span class="math display">\[V_{\pi}(s) = \mathop{max}_{a \in A}\,Q_{\pi}(s,a)\]</span>贝尔曼最优方程表明：最佳策略下的一个状态的价值必须等于在这个状态下采取最好动作得到的回报的期望</p><p>当马尔可夫决策过程满足贝尔曼最优方程时，整个马尔可夫决策过程已经达到最佳状态。只有当整个状态已经收敛后，我们得到最佳价值函数后，贝尔曼最优方程才会被满足。满足贝尔曼最优方程后，我们可以采用最大化操作：<span class="math display">\[V^*(s) = \mathop{max}_a \,Q^*(s,a)\]</span>当我们取让Q函数值最大化的动作时，对应的值就是当前状态的最佳的价值函数的值</p><h3 id="价值迭代">价值迭代</h3><h4 id="最优性原理">最优性原理</h4><p><strong>最优性原理定理</strong>：一个策略<span class="math inline">\(\pi(s|a)\)</span>在状态s达到了最优价值，当且仅当对于任何能够从s到达的s'都已达到了最优价值</p><h4 id="确认性价值迭代">确认性价值迭代</h4><p>如果我们知道子问题<span class="math inline">\(V^*(s&#39;)\)</span>的最优解，就可以通过价值迭代来得到最优的<span class="math inline">\(V^*(s)\)</span>的解，价值迭代就是把贝尔曼最优方程当成一个更新规则来进行：<span class="math display">\[V(s) \leftarrow \mathop{max}_{a \in A}(R(s,a) + \gamma \sum_{s&#39; \inS}p(s&#39;\,|\,s,a)V(s&#39;))\]</span> 为了得到最佳的<span class="math inline">\(V^*\)</span>，对于每个状态的<span class="math inline">\(V\)</span>，我们直接通过贝尔曼最优方程进行迭代，迭代多次后价值函数就会收敛。这种价值迭代算法也被称为确认性价值迭代</p><h4 id="价值迭代算法">价值迭代算法</h4><p>价值迭代的算法过程如下：</p><ol type="1"><li><p>初始化：令<span class="math inline">\(k =1\)</span>，对于所有的状态<span class="math inline">\(s\)</span>，<span class="math inline">\(V_0(s) = 0\)</span></p></li><li><p>对于<span class="math inline">\(k = 1\)</span>，<span class="math inline">\(H\)</span>(迭代次数)</p><div class="code-wrapper"><pre><code class="hljs">     对所有的状态$s$</code></pre></div><p><span class="math display">\[\begin{align*}Q_{k + 1}(s,a) &amp;= R(s,a) + \gamma \sum_{s&#39; \inS}\,p(s&#39;\,|\,s,a)V_k(s&#39;) \\V_{k + 1}(s) &amp;= \mathop{max}_a \,Q_{k + 1}(s,a)\\k &amp;\leftarrow k + 1\end{align*}\]</span></p></li><li><p>在迭代后提取最优策略</p></li></ol><p><span class="math display">\[\pi(s) = arg\,\mathop{max}_{a}\,R(s,a) + \gamma \sum_{s&#39; \inS}\,p(s&#39;\,|\,s&#39;,a)V_{k + 1}(s&#39;)\]</span></p>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>notes</category>
      
    </categories>
    
    
    <tags>
      
      <tag>machine learning</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>汇编语言笔记</title>
    <link href="/2022/07/19/assembly/"/>
    <url>/2022/07/19/assembly/</url>
    
    <content type="html"><![CDATA[<h1 id="寄存器">寄存器</h1><h2 id="通用寄存器">通用寄存器</h2><p>以16位寄存器为例，我们记为AX[15:0]</p><p>AX、BX、CX、DX、均可分为高八位[15:8]（AH，BH，CH，DH）和低八位[7:0]（AL、BL、CL、DL）</p><h2 id="字在寄存器中的存储">字在寄存器中的存储</h2><p>字节：记为byte，一个字节由8bit组成，可以存在8位寄存器中。</p><p>字：记为word，一个字由2字节组成，这两个字节记为高位字节和低位字节。</p><h2 id="几条汇编指令">几条汇编指令</h2><ol type="1"><li>mov ax,18：将18送入ax寄存器</li><li>mov ah,78：将78送入ah</li><li>add ax,8：将ax的值加8</li><li>mox ax,bx：将bx的值送入ax</li><li>add ax,bx：将ax与bx相加放入ax</li></ol><p><strong>注意：在执行加法运算时，视al与ah为独立的寄存器，也就是说如果单独对al进行加法运算时，在最高位产生进位则不会对ah产生影响。</strong></p><p>在进行数据传输或运算时，应注意指令的两个操作对象位数应该统一，否则视为错误指令，示例如下：</p><p><strong>注意：如下指令均为错误指令！！！</strong></p><ol type="1"><li>mov ax,bl ;八位向十六位传输</li><li>mov bh,ax ;十六位向八位传输</li><li>mov al,20000 ;超过寄存器储存限制</li><li>add al,100H ;将高于八位的数传入八位寄存器</li></ol><h2 id="cpu给出物理地址的方法">8086CPU给出物理地址的方法</h2><figure><img src="/.com//Users\Zya1412\Desktop\Assembly\A1.png" alt="A1"><figcaption aria-hidden="true">A1</figcaption></figure><p>当8086CPU读写内存时：</p><ol type="1"><li>CPU中的相关部件提供两个十六位地址，一个称为段地址，另一个称为偏移地址；</li><li>段地址和偏移地址通过内部总线送入地址加法器；</li><li>地址加法器将两个16位地址合为20位物理地址；</li><li>地址加法器通过内部总线将物理地址送入控制电路；</li><li>输入输出控制电路将物理地址送入地址总线；</li><li>物理地址被地址总线送入存储器</li></ol><p>地址加法器的合成方法：<strong>物理地址=段地址&lt;&lt;4+偏移地址</strong></p><p>偏移地址为16位，16位的寻址能力位64KB，所以一个段的长度最大为64KB。</p><h2 id="段寄存器">段寄存器</h2><p>我们介绍关于段地址的一些寄存器，段地址在8086CPU的段寄存器中存放，这四个寄存器为：CS，DS，SS，ES</p><h3 id="csip">CS&amp;IP</h3><p>CS和Ip是8086CPU中最关键的两个寄存器：CS是代码段寄存器；IP是指令指针寄存器。指令地址即CS&lt;&lt;4+IP。</p><p>8086CPU的工作过程可简要描述如下：</p><ol type="1"><li>从CS:IP指向的内存单元读取指令，读取的指令进入指令缓存器；</li><li>IP=IP+所读取的指令长度，从而指向下一条指令；</li><li>执行指令。转到步骤(1),重复这个过程。</li></ol><h3 id="修改csip的指令">修改CS、IP的指令</h3><p>mov指令未提供修改CS、IP指令的功能(大概是因为这会引起混乱)</p><p>但我们可以通过“jmp段地址:偏移地址”修改CS，IP。若想仅修改IP的内容，可用“jmp某寄存器”的形式完成，如：jmp ax这个指令形式上等价于mov IP,ax</p><h2 id="内存中字的存储">内存中字的存储</h2><p>CPU中，用16位寄存器来存储一个字。高8位存放高位字节，低8位存放低位字节。由于内存单元是字节单元，所以一个字需要两个地址连续的内存单元来存放。</p><p>由此我们引出字单元的概念：字单元即存放一个字形数据(16位)的内存单元，由两个地址连续的内存单元组成。</p><h2 id="ds和address">DS和[address]</h2><p>CPU读取一个内存单元时，必须先给出这个内存单元的地址，在8086PC中，内存地址由段地址和偏移地址组成。DS寄存器通常存放要访问数据的段地址。比如要读取/写入10000H单元的内容过程可如下所示：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></div></td><td class="code"><pre><code class="hljs assembly">;read<br>mov bx,1000H<br>mov ds,bx<br>mov al,[0]<br>;write<br>mov bx,1000H<br>mov ds,bx<br>mov [0],cx<br></code></pre></td></tr></table></figure><p><strong>注意：8086CPU不支持将立即数传入ds寄存器的操作，故我们需要先将地址装入另一个无关寄存器，再通过这个寄存器放入ds。</strong></p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs assembly">;一些基础指令<br>mov ax,bx ;将bx移入ax<br>add ax,bx ;将ax与bx求和放入ax<br>sub ax,bx ;将ax-bx放入ax<br>;这三个指令支持的类型有三个：寄存器，存储单元，立即数<br></code></pre></td></tr></table></figure><h2 id="cpu的栈机制">CPU的栈机制</h2><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs assembly">push ax;将ax的数据入栈<br>pop ax;将栈顶的数据弹出并存入ax<br>;栈的操作支持数据存储类型：存储单元，寄存器<br></code></pre></td></tr></table></figure><p>关于栈，8086CPU存在两个寄存器：段寄存器SS和寄存器SP。</p><p>栈顶段地址存放在SS中，偏移地址存放在SP中。任意时刻SS:SP指向栈顶元素。push/pop指令执行时，CPU从SS和SP中得到栈顶的地址。</p><p>注意到：SS:SP的机制与CS:IP的机制相同，故一个栈段的大小也为64KB。</p><p>[bx]表示一个内存单元，它的偏移地址在bx中</p><p>我们定义(reg)表示寄存器中的数据</p><h1 id="loop指令">Loop指令</h1><p>loop指令的格式：loop标号，CPU执行loop指令时，要进行两部操作：</p><ol type="1"><li>(cx)=(cx)-1</li><li>判断cx的值，不为0则转至标号处执行程序，如果为0则向下执行</li></ol><p>eg：计算2^12</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs assembly">assume cs:code<br>code segment<br>mov ax,2<br><br>mov cx,11<br>s:add ax,ax<br>loop s<br>mov ax,4c00h<br>int 21h<br>code ends<br>end<br></code></pre></td></tr></table></figure><h2 id="段前缀">段前缀</h2><p>在普通的movax,[bx]指令中，内存单元的偏移地址由bx给出，而段地址默认在ds中。我们可以在访问内存单元的指令中显式地给出内存单元的段地址所在的段寄存器：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs assembly">mov ax,ds:[bx]<br>mov ax,cs:[bx]<br>mov ax,ss:[bx]<br>mov ax,es:[bx]<br></code></pre></td></tr></table></figure><p>以上的ds,cs,es,ss均为<strong>段前缀</strong></p><h1 id="更灵活的定位内存地址的方法">更灵活的定位内存地址的方法</h1><h2 id="and-or指令">and &amp; or指令</h2><p>and指令：做按位与</p><p>or指令：做按位或</p><h2 id="bx-idata">[bx + idata]</h2><p><strong>寄存器相对寻址</strong></p><p>[bx +idata]表示一个内存单元，它的偏移地址为(bx)+idata(bx中的数值加idata)</p><p>eg：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs assembly">mov ax,[200+bx]<br></code></pre></td></tr></table></figure><p>这个命令是将((ds)*16+(bx)+200)送入ax中</p><p>有了这种记录方式，就可以利用loops循环操作数组(不断改变bx来改变偏移量)</p><h2 id="si和di">SI和DI</h2><p><strong>基址变址寻址</strong></p><p>SI和DI是x86中和bx功能相似的寄存器，它们不能被分为两个8位寄存器。</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs assembly">mov ax,[200+si]<br>mov ax,[s00+di]<br></code></pre></td></tr></table></figure><p><strong>相对基址变址寻址</strong></p><p>可以用bx，si，di，idata互相组合构成偏移量：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs assembly">mov ax,[bx+idata]<br>mov ax,[bx+si]<br>mov ax,[bx+di]<br>mov ax,[bx+si+idata]<br>mov ax,[bx+di+idata]<br>mov ax,[bx+si+di+idata]<br></code></pre></td></tr></table></figure><p>可以操作二，三维数组。bp寄存器与si，di作用相同。</p><h2 id="指令要处理的数据长度">指令要处理的数据长度</h2><h3 id="通过寄存器名指明要处理的数据尺寸">通过寄存器名指明要处理的数据尺寸</h3><h4 id="字操作">字操作</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs assembly">mov ax,1<br>mov bx,ds:[0]<br>inc ax<br>add ax,1000<br></code></pre></td></tr></table></figure><h4 id="字节操作">字节操作</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs assembly">mov al,1<br>mov al,bl<br>mov al,ds:[0]<br>inc al<br>add al,100<br></code></pre></td></tr></table></figure><h3 id="用操作符-x-ptr-指明内存单元的长度">用操作符 X ptr指明内存单元的长度</h3><p>X可以为word或byte</p><h4 id="word-ptr指明内存单元为字单元">word ptr指明内存单元为字单元</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs assembly">mov word ptr ds:[0],1<br>inc word ptr [bx]<br>add word ptr [bx],2<br></code></pre></td></tr></table></figure><h4 id="byte-ptr指明内存单元为字节单元">byteptr指明内存单元为字节单元</h4><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs assembly">mov byte ptr ds:[0],1<br>inc byte ptr [bx]<br>add byte ptr [bx],2<br></code></pre></td></tr></table></figure><h2 id="div指令">div指令</h2><p>div为除法指令：</p><ol type="1"><li><p>除数：有8位或16位两种，在一个reg或内存单元中。</p></li><li><p>被除数：默认放在ax/dx&amp;ax中，若除数8位，被除数则为16位，默认在ax中存放；若除数为16位，被除数则为32位，在dx和ax中存放，dx放高16位，ax放低16位。</p></li><li><p>结果：如果除数为8位，则al存储除法操作的商，ah放余数；若除数为16位，则ax存储商，dx存储余数。</p></li></ol><p>格式如下：</p><p>div reg</p><p>div 内存单元</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs assembly">div byte ptr ds:[0]<br>div word ptr es:[0]<br>div word ptr [bx+si+8]<br>div byte ptr [bx+si+8]<br></code></pre></td></tr></table></figure><h2 id="伪指令dd">伪指令dd</h2><p>db为字节型数据，dw为字型数据，dd为double型数据(32位)</p><h2 id="dup操作符">dup操作符</h2><p>dup用来与dw，db，dd等数据定义伪指令配合使用的，用来进行数据的重复：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs assembly">db 3 dup (0);等价于db 0,0,0<br>db 3 dup (0,1,2);等价于db 0,1,2,0,1,2,0,1,2<br>db 3 dup (&#x27;abc&#x27;,&#x27;ABC&#x27;);等价于db‘abcABCabcABCabcABC&#x27;<br></code></pre></td></tr></table></figure><h1 id="转移指令">转移指令</h1><p>可以修改IP，或同时修改CS和IP的指令称为转移指令；概括的说，转移指令就是可以控制CPU执行内存中某处代码的指令。</p><p>x86中转移有以下几类：</p><ol type="1"><li>只修改IP时，称为段内转移，比如jmp ax</li><li>同时修改CS和IP时，称为段间转移，比如jmp 1000：0</li></ol><p>由于转移指令对IP的修改范围不同，段内转移又分为：短转移和近转移。</p><ol type="1"><li>短转移的IP修改范围为-128~127</li><li>近转移的IP修改范围为-32768~32767</li></ol><p>x86的转移指令分为以下几类：</p><ol type="1"><li>无条件转移指令</li><li>条件转移指令</li><li>循环指令</li><li>过程</li><li>中断</li></ol><h2 id="操作符offset">操作符offset</h2><p>offset的功能是取得标号的偏移地址，比如：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs assembly">assume cs:codesg<br>codesg segment<br>  start:mov ax,offset start;相当于mov ax,0<br>    s:mov ax,offset s;相当于mov ax,3<br>    <br>codesg ends<br>end start<br></code></pre></td></tr></table></figure><h2 id="jmp指令">jmp指令</h2><p>jmp指令要给出两种信息：</p><ol type="1"><li>转移的目的地址</li><li>转移的距离(段间转移、段内短转移、段内近转移)</li></ol><h3 id="依据位移进行转移的jmp指令">依据位移进行转移的jmp指令</h3><p>eg：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs assembly">;示例：jmp short 标号;转到标号处执行指令<br>start: mov ax,0<br>   jmp short s<br>   add ax,1<br>s: inc ax<br></code></pre></td></tr></table></figure><p>add ax 1这个指令由于jmp被跳过未执行，故ax中的数据为1。</p><p><strong>注意：s标号在机器语言中也是立即数，表示为偏移地址(类似于c语言中的函数指针)</strong></p><p>在jmp指令转换为机器语言后，机器语言只会保留jmp指令的指令号(EB)和跳转地址相对当前地址的偏移量作为标号</p><p>jmp short 标号的功能为：(IP)=(IP)+8位位移</p><p>8位位移=标号处地址-jmp指令后第一个字节的地址</p><p>8位位移的范围是-128~127，用补码表示</p><p>类似于jmp short 标号，我们还有jmp near ptr标号，其功能为IP=(IP)+16位位移。这个指令实现了段内近转移。</p><h3 id="转移的目的地址在指令中的jmp指令">转移的目的地址在指令中的jmp指令</h3><p>上述jmp指令，其对应的机器指令是相对于当前IP的转移位移</p><p>“jmp far ptr 标号“实现的是段间转移，又称为远转移：</p><p>far ptr指明了指令用标号的段地址和偏移地址修改CS和IP</p><p>eg:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs assembly">start:mov ax,0<br>  mov bx,0<br>  jmp far ptr s<br>  db 256 dup (0)<br>s:add ax,1<br>  inc ax<br></code></pre></td></tr></table></figure><h3 id="转移地址在寄存器中的jmp指令">转移地址在寄存器中的jmp指令</h3><p>指令格式：jmp 16位register</p><h3 id="转移地址在内存中的jmp指令">转移地址在内存中的jmp指令</h3><ol type="1"><li>jmp word ptr 内存单元地址(段内转移)</li><li>jmp dword ptr 内存单元地址(段间转移)</li></ol><p>第一个指令的功能是在指定内存中读一个数据作为IP的偏移地址，并执行jmp指令</p><p>第二个指令的功能是在指定内存中的读取连续存放的两个字，高地址处存目的段地址，低地址存目的偏移地址，</p><p>(CS) = (内存单元地址+2)</p><p>(Ip) = (内存单元地址)</p><h2 id="jcxz指令">jcxz指令</h2><p>jcxz指令为有条件转移指令，所有条件转移指令都是短转移，在对应的机器码中包含转移的位移，而不是目的地址。对IP的修改范围：-128~127</p><p>指令格式：jcxz 标号</p><p>当(cx)=0时，(IP)=(IP)+8位位移；当(cx)$$0时，什么都不做(程序向下执行)。</p><p>用c代码来翻译即是：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">if</span>((cx) == <span class="hljs-number">0</span>)jmp <span class="hljs-type">short</span> 标号<br></code></pre></td></tr></table></figure><h2 id="loop指令-1">loop指令</h2><p>loop指令为循环指令，所有循环指令都是<strong>短转移</strong>，对应的机器码包含转移地址，对IP的修改范围都是：-128~127</p><p>指令格式: loop 标号（(cx)=(cx)-1，如果(cx)$$0，则转到标号处执行）</p><h2 id="根据位移进行转移的意义">根据位移进行转移的意义</h2><p>保存位移地址的原因是：使得程序存储在内存任何位置都可以得到正确执行，否则若用绝对地址存储的话，改变指令位置则会出错。</p><h2 id="call和ret指令">CALL和RET指令</h2><h3 id="ret和retf">ret和retf</h3><p>ret指令用栈中的数据，修改IP的内容，从而实现近转移；</p><p>retf指令用栈中的数据，修改CS和IP的内容，从而实现远转移。</p><p>执行ret指令进行如下操作：</p><ol type="1"><li>(IP)=((ss)*16+(sp))</li><li>(sp)=(sp)+2</li></ol><p>执行retf指令进行如下操作：</p><ol type="1"><li>(IP)=((ss)*16+(sp))</li><li>(sp)=(sp)+2</li><li>(cs)=((ss)*16+(sp))</li><li>(sp)=(sp)+2</li></ol><h3 id="call指令">call指令</h3><p>执行call指令时进行两步操作：</p><ol type="1"><li>将当前的IP或CS和IP压入栈中</li><li>转移</li></ol><p><strong>call指令不能实现短转移，除此之外，call指令实现转移的方法和jmp指令的原理相同</strong></p><h4 id="依据位移进行转移的call指令">依据位移进行转移的call指令</h4><p>call指令的格式： call 标号(将当前的IP压栈后，转到标号处执行指令)</p><p>执行call指令时，具体操作为：</p><ol type="1"><li><p>(sp)=(sp)-2</p><p>((ss)*16+(sp))=(IP)</p></li><li><p>(IP)=(IP)+16位位移</p></li></ol><p>call 标号指令等价于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs assembly">push IP<br>jmp near ptr 标号<br></code></pre></td></tr></table></figure><h4 id="转移的目的地址在指令中的call指令">转移的目的地址在指令中的call指令</h4><p>前面讲的call指令，其对应的机器指令中并没有转移的目的地址，而是相对于当前IP的转移位移。</p><p>“call far ptr 标号"实现的是段间转移。</p><p>执行此种格式的call指令时，进行如下操作：</p><ol type="1"><li><p>(sp)=(sp)-2</p><p>(cs)=((ss)*16+(sp))</p><p>(sp)=(sp)-2</p><p>(ip)=((ss)*16+(sp))</p></li><li><p>(cs)=标号所在段的段地址</p><p>(IP)=标号在段中的偏移地址</p></li></ol><p>call far ptr 标号等价于:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs assembly">push CS<br>push IP<br>jmp far ptr 标号<br></code></pre></td></tr></table></figure><h4 id="转移地址在寄存器中的call指令">转移地址在寄存器中的call指令</h4><p>指令格式：call 16bits register</p><p>功能：</p><p>(sp)=(sp)-2</p><p>(IP)=((ss)*16+(sp))</p><p>(IP)=(16位register)</p><p>此种指令等价于：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs assembly">push IP<br>jmp 16位reg<br></code></pre></td></tr></table></figure><h4 id="转移地址在内存中的call指令">转移地址在内存中的call指令</h4><p>转移地址在内存中的call指令有两种格式。</p><ol type="1"><li>call word ptr 内存单元地址</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs assembly">push IP<br>jmp word ptr 内存单元地址<br></code></pre></td></tr></table></figure><ol start="2" type="1"><li>call dword ptr 内存单元地址</li></ol><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs assembly">push CS<br>push IP<br>jmp dword ptr 内存单元地址<br></code></pre></td></tr></table></figure><h3 id="mul指令">mul指令</h3><ol type="1"><li>两个相乘的数：两个相乘的数，要么都是8位，要么都是16位。如果是8位，一个默认放在AL中，另一个放在8位reg或内存单元字节单元中；如果是16位，一个默认在ax中，；ing一个放在16位reg或内存单元字节中。</li><li>结果：如果是八位，结果默认放在ax中；如果是16位，高位默认在dx中存放，低位在ax中存放。</li></ol><h1 id="标志寄存器">标志寄存器</h1><p>CPU内部寄存器中，有一种特殊的寄存器，具有以下三种作用：</p><ol type="1"><li>用来存储相关指令的某些执行结果</li><li>用来为CPU执行相关指令提供行为依据</li><li>用来控制CPU的相关工作方式</li></ol><p>这种特殊的寄存器在8086CPU中被称为标志寄存器。标志寄存器有16位，其中储存的信息通常被称为程序状态字，之前使用的ax,bx,cx,dx,si,di,bp,sp,IP,cs,ds,es皆是标志寄存器，本章的标志寄存器(以下简称flag)是最后一个。</p><p>flag与其它寄存器不一样，其它寄存器用来放数据，都是整个寄存器具有一个意义，而flag寄存器是按位起作用的，其每一位都有专门的含义:</p><p>flag[11]=OF</p><p>flag[10]=DF</p><p>flag[9]=IF</p><p>flag[8]=TF</p><p>flag[7]=SF</p><p>flag[6]=ZF</p><p>flag[4]=AF</p><p>flag[2]=PF</p><p>flag[0]=CF</p><h2 id="zf标志">ZF标志</h2><p>flag第六位是0标志位，它记录相关指令操作后其结果是否为0：是0则ZF为1；非0则ZF为0</p><p>eg:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs assembly">mov ax,1<br>sub ax,1<br>;ax为0，所以ZF为1<br>mov ax,2<br>sub ax,1<br>;ax为1，所以ZF为0<br></code></pre></td></tr></table></figure><p><strong>注意：运算指令是有可能影响标志寄存器的，要注意是否对标志寄存器的某些标志位产生了影响</strong></p><h2 id="pf标志">PF标志</h2><p>flag的第二位为PF，它记录了相关指令执行后，其结果的所有bit位中1的个数是否为偶数：是偶数则PF为1；反之为0</p><h2 id="sf标志">SF标志</h2><p>flag的第七位为SF，符号标志位，它记录了相关指令执行后其结果是否为负：是负数则SF为1；反之为0</p><p>注：无符号数的SF位无意义，只有有符号数的SF位才会影响结果</p><h2 id="cf标志">CF标志</h2><p>flag的第0位为SF，进位标志位。一般情况下，在进行<strong>无符号数</strong>的运算时，它记录了运算结果的最高有效位向更高位的进位值，或从更高位的借位值。</p><h2 id="of标志">OF标志</h2><p>flag的第11位为OF，溢出标志位。一般情况下，OF记录了有符号数运算的结果是否发生了溢出：若发生溢出，OF=1；反之OF=0</p><p>注：OF是对<strong>有符号数</strong>运算有意义的标志位；CF是对<strong>无符号数</strong>运算有意义的标志位。</p><h2 id="adc指令">adc指令</h2><p>adc是带进位加法指令，它利用了CF位上记录的进位值。</p><p>eg:</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs assembly">adc ax,bx;ax = (ax) + (bx) + CF<br></code></pre></td></tr></table></figure><p>adc指令的意义：执行加法运算中高位-低位分离的大数加法(与add指令一同完成)</p><p>eg:计算1EF0001000H+2010001EF0H，结果放在ax(最高16位)，bx(次高16位)，cx(低16位)中。</p><p>计算分三步：</p><ol type="1"><li>先将低16位相加，完成后CF记录本次相加的进位值</li><li>再将次高16位和CF(低16位)相加，完成后CF记录本次相加的进位值</li><li>最后高16位和CF(次高16位)相加，完成后CF记录本次相加的进位值</li></ol><h2 id="sbb指令">sbb指令</h2><p>sbb是带借位减法指令，它利用了CF位上记录的借位值。</p><p>指令格式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs assembly">sbb ax,bx;(ax) = (ax) - (bx) - CF<br></code></pre></td></tr></table></figure><h2 id="cmp指令">cmp指令</h2><p>cmp是比较指令，功能相当于减法指令，只是不保存结果。cmp指令执行后，将对标志寄存器产生影响。其他相关指令通过识别这些被影响的标志寄存器位来得知比较结果。</p><p>指令格式：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs assembly">cmp ax,bx;若ax-bx=0,ZF=1,否则ZF=0,其余对标志位影响与减法指令相同<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>计算机基础</category>
      
      <category>汇编语言</category>
      
    </categories>
    
    
    <tags>
      
      <tag>汇编语言</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Vim笔记</title>
    <link href="/2022/07/19/linux/vim/"/>
    <url>/2022/07/19/linux/vim/</url>
    
    <content type="html"><![CDATA[<p>（肯定会忘所以先总结一下）</p><h2 id="几种模式">几种模式</h2><p>插入模式(Insert):用i,a,o,I,A,O即可插入</p><p>命令模式:用esc后输入加命令即可</p><p>可视化模式(Visionary):Ctrl+v即可进入</p><h2 id="常用编辑命令">常用编辑命令</h2><h3 id="移动一个字符">移动一个字符</h3><p>h、i、j、k分别对应左、下、上、右的操作</p><h3 id="删除一个字符">删除一个字符</h3><p>移动到需要删除的地方按x/dl即可，几下x即是几个字符</p><p>X/dh删除光标前一个位置的字符</p><h3 id="undo和redo">Undo和Redo</h3><p>u可直接回到上一个状态；Ctrl+r可回到最新状态</p><h3 id="删除和添加行">删除和添加行</h3><p>向正在编辑的文本输入“dd"就能删除一行，保存在缓冲中，可使用p进行粘贴</p><p>在正常模式下输入o即可在当前光标下添加一行；O则在上一行添加一行</p><p>dw删除一个单词</p><p>d0从光标起删除至行首</p><p>D/d$从光标起删除至行尾</p><p>dd删除整个光标所在行</p><p>dj/dk删除整个光标所在行及上/下一行</p><h3 id="复制和粘贴">复制和粘贴</h3><p>yy将光标行复制到缓冲</p><p>yw从光标位置到词末尾复制</p><p>ykw从光标位置复制k个词</p><p>y0从光标到行首复制</p><p>y$从光标到行尾复制</p><p>kyy复制光标所在行下k行</p><p>yj复制光标行及下一行</p><p>yk复制光标行和上一行</p><p>yG从光标当前位置府治奥文件末尾</p><p>p添加至当前光标/下一个位置</p><p>Ctrl+v选择块进行复制粘贴删除操作</p><h3 id="重复执行">重复执行</h3><p>多次执行相同命令：数字+命令</p><p>eg：3l为向右移动三格；4dd为删除四行；”5iShell<esc>“即输入五遍shell</esc></p><h3 id="保存和终止">保存和终止</h3><p>:w 保存</p><p>:w text.txt 保存为text.txt</p><p>:w &gt;&gt; text.txt 添加到text.txt并保存</p><p>:q 终止编辑器</p><p>ZZ 保存后终止</p><p>:wq! 保存后强制终止</p><p>:e test.txt 调用test.txt文件</p><p>:e 调用当前文件</p><h2 id="高级编辑命令">高级编辑命令</h2><h3 id="移动命令">移动命令</h3><p>使用w命令向右移动一个单词，b向左移动一个单词；此时除字母或数字外的所有字符可视为一个单词</p><p>与此不同的是，W和B命令只能以Space分隔单词</p><p>与其他命令一样，在命令前添加数字就能将命令重复指定次数。</p><p>正常模式中，使用0或^命令移动到行的开始，$移动到行尾</p><p>:set nu或者:set number可用显示行号</p><p>正常模式下输入数字+G移动到指定数字行</p><p>:set nonumber或:set nonu可隐藏行号</p><p>+移动到下一行的第一个字</p><p>-移动到上一行的第一个字</p><p>(移动到上一个语句的第一个字</p><p>)移动到下一个语句的第一个字</p><p>{移动到上一段</p><p>}移动到下一段</p><p>]]移动到下一个节区的开始</p><p>[[移动到上一个节区的开始] 标签文件关键字</p><p>Ctrl-x + Ctrl-k 字典查找</p><p>Ctrl-x + Ctrl-l 整行补全</p><p>Ctrl-x + Ctrl-f 文件名补全</p><p>Ctrl-x + Ctrl-o 全能补全</p><h2 id="环境设置参数">环境设置参数</h2><p>:set nu/nonu 设置/取消行号</p><p>:set hlsearch/nohlsearch 是否将查找的字符串高亮</p><p>:set autoindent/noautoindent 是否自动缩进</p><p>:set backup 是否自动保存备份文件</p><p>:set ruler 显示/不显示状态栏说明</p><p>:set showmode 是否要显示--INSERT--这样的左下角状态栏</p><p>:set backspace==(012)当设为2时，可删除任意值；设为1时，仅可删除刚刚输入的字符，而无法删除原本就存在的字符；设为0时无法用backspace</p><p>:set all 显示目前所有对环境参数设置值</p><p>:set显示与系统默认值不同的设置参数，一般来说就是你有自动变动过的设置参数</p><p>:syntax on/off 是否依据程序相关语法显示不同颜色</p><p>:set bg=dark/light 可用以显示不同的颜色色调</p>]]></content>
    
    
    <categories>
      
      <category>Linux</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CSAPP shelllab总结</title>
    <link href="/2022/07/19/CSAPP/shelllab/"/>
    <url>/2022/07/19/CSAPP/shelllab/</url>
    
    <content type="html"><![CDATA[<h2 id="书中一些函数的功能">书中一些函数的功能</h2><figure class="highlight c"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></div></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;unistd.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;signal.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span><span class="hljs-string">&lt;sys/types.h&gt;</span></span><br><span class="hljs-type">pid_t</span> <span class="hljs-title function_">getpgrp</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span>;<span class="hljs-comment">// 返回当前进程的进程组id</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">setpgid</span><span class="hljs-params">(<span class="hljs-type">pid_t</span> pid,<span class="hljs-type">pid_t</span> pgid)</span><span class="hljs-comment">// 改变自己或其他进程的进程组，成功返回0失败返回1</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">kill</span><span class="hljs-params">(<span class="hljs-type">pid_t</span> pid,<span class="hljs-type">int</span> sig)</span><span class="hljs-comment">// 进程通过调用kill函数发送信号给其他进程(包括自己)，成// 功返回0失败返回1</span><br><span class="hljs-keyword">typedef</span> <span class="hljs-title function_">void</span> <span class="hljs-params">(*<span class="hljs-type">sighandler_t</span>)</span> <span class="hljs-params">(<span class="hljs-type">int</span>)</span>;<br><span class="hljs-type">sighandler_t</span> <span class="hljs-title function_">signal</span><span class="hljs-params">(<span class="hljs-type">int</span> signum, <span class="hljs-type">sighandler_t</span> handler)</span>;<span class="hljs-comment">// 若成功则返回指向前次处理程序的指针，否则返回SIG_ERR</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">sigprocmask</span><span class="hljs-params">(<span class="hljs-type">int</span> how,<span class="hljs-type">const</span> <span class="hljs-type">sigset_t</span> *<span class="hljs-built_in">set</span>, <span class="hljs-type">sigset_t</span> *oldset)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">sigemptyset</span><span class="hljs-params">(<span class="hljs-type">sigset_t</span> *<span class="hljs-built_in">set</span>)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">sigfillset</span><span class="hljs-params">(<span class="hljs-type">sigset_t</span> *<span class="hljs-built_in">set</span>)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">sigaddset</span><span class="hljs-params">(<span class="hljs-type">sigset_t</span> *<span class="hljs-built_in">set</span>,<span class="hljs-type">int</span> signum)</span>;<br><span class="hljs-type">int</span> <span class="hljs-title function_">sigdelset</span><span class="hljs-params">(<span class="hljs-type">sigset_t</span> *<span class="hljs-built_in">set</span>,<span class="hljs-type">int</span> signum)</span>;<br><span class="hljs-comment">/* sigprocmask 函数改变当前阻塞的信号集合，具体行为依赖how的值</span><br><span class="hljs-comment">   SIG_BLOCK   把set中的信号添加到blocked向量</span><br><span class="hljs-comment">   SIG_UNBLOCK 从blocked中删除set的信号</span><br><span class="hljs-comment">   SIG_SETMASK block=set</span><br><span class="hljs-comment">   如果oldset非空，那么blocked位向量的值保存在oldset中</span><br><span class="hljs-comment">   sigemptyset 初始化set为空集合</span><br><span class="hljs-comment">   sigfillset  把每个信号都添加到set中</span><br><span class="hljs-comment">   sigaddset   把signum添加到set</span><br><span class="hljs-comment">   sigdelset   从set中删除signum</span><br><span class="hljs-comment">   如果signum是set的成员，那么sigismember返回1，否则返回0 */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">sigismember</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">sigset_t</span> *<span class="hljs-built_in">set</span>,<span class="hljs-type">int</span> signum)</span>;<br></code></pre></td></tr></table></figure><h2 id="eval函数">eval函数</h2><p>实现代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * eval - Evaluate the command line that the user has just typed in</span><br><span class="hljs-comment"> * </span><br><span class="hljs-comment"> * If the user has requested a built-in command (quit, jobs, bg or fg)</span><br><span class="hljs-comment"> * then execute it immediately. Otherwise, fork a child process and</span><br><span class="hljs-comment"> * run the job in the context of the child. If the job is running in</span><br><span class="hljs-comment"> * the foreground, wait for it to terminate and then return.  Note:</span><br><span class="hljs-comment"> * each child process must have a unique process group ID so that our</span><br><span class="hljs-comment"> * background children don&#x27;t receive SIGINT (SIGTSTP) from the kernel</span><br><span class="hljs-comment"> * when we type ctrl-c (ctrl-z) at the keyboard.  </span><br><span class="hljs-comment">*/</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">eval</span><span class="hljs-params">(<span class="hljs-type">char</span> *cmdline)</span> <br>&#123;<br>    <span class="hljs-type">char</span> *argv[MAXARGS];       <span class="hljs-comment">// Argument list</span><br>    <span class="hljs-type">char</span> buf[MAXLINE];          <span class="hljs-comment">// Holds modified command line</span><br>    <span class="hljs-type">int</span> bg;                     <span class="hljs-comment">// Should the job run in background or foreground                        </span><br>    <span class="hljs-type">pid_t</span> pid;                  <span class="hljs-comment">// Process id</span><br>    <span class="hljs-type">sigset_t</span> mask;<br>    <span class="hljs-built_in">strcpy</span>(buf,cmdline);<br>    bg = parseline(buf,argv);<br>    <span class="hljs-keyword">if</span>(argv[<span class="hljs-number">0</span>] == <span class="hljs-literal">NULL</span>)&#123;<br>        <span class="hljs-keyword">return</span>;                 <span class="hljs-comment">// Ignore empty line</span><br>    &#125;<br><br>    <span class="hljs-keyword">if</span>(!builtin_cmd(argv))&#123;<br>        sigemptyset(&amp;mask);<br>        sigaddset(&amp;mask,SIGCHLD);<br>        sigprocmask(SIG_BLOCK,&amp;mask,<span class="hljs-literal">NULL</span>);<br>        <span class="hljs-keyword">if</span>((pid = fork()) == <span class="hljs-number">0</span>)&#123;    <span class="hljs-comment">// Child process runs user job</span><br>            sigprocmask(SIG_UNBLOCK,&amp;mask,<span class="hljs-literal">NULL</span>);<br>            setpgid(<span class="hljs-number">0</span>,<span class="hljs-number">0</span>);<br>            <span class="hljs-keyword">if</span>(execve(argv[<span class="hljs-number">0</span>], argv, environ) &lt; <span class="hljs-number">0</span>)&#123;<br>                <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%s: Command not found.\n&quot;</span>,argv[<span class="hljs-number">0</span>]);<br>                <span class="hljs-built_in">exit</span>(<span class="hljs-number">0</span>);<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">else</span>&#123;<br>            <span class="hljs-keyword">if</span>(!bg)&#123;<br>                addjob(jobs,pid,FG,cmdline);<br>            &#125;<br>            <span class="hljs-keyword">else</span>&#123;<br>                addjob(jobs,pid,BG,cmdline);<br>            &#125;<br>            sigprocmask(SIG_UNBLOCK,&amp;mask,<span class="hljs-literal">NULL</span>);<br>        &#125;<br>        <span class="hljs-comment">// Parent waits for foreground job to terminate</span><br>        <span class="hljs-keyword">if</span>(!bg)&#123;<br>            <span class="hljs-type">int</span> status;<br>            <span class="hljs-keyword">if</span>(waitpid(pid,&amp;status,<span class="hljs-number">0</span>) &lt; <span class="hljs-number">0</span>)&#123;<br>                unix_error(<span class="hljs-string">&quot;waitfg: waitpid error&quot;</span>);<br>            &#125;<br>            waitfg(pid);<br>        &#125;<br>        <span class="hljs-keyword">else</span>&#123;<br>            <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;[%d] (%d) %s&quot;</span>,pid2jid(pid),pid,cmdline);<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>eval函数不能直接按照书中代码进行实现，因为书中代码没有考虑信号处理，故我们需要在书中代码的基础上加入对各类中断信号的处理</p><p>eval函数的作用是读取用户输入的命令行并对该命令行求值</p><p><strong>原理解释</strong>：</p><ul><li>首先读入并解析指令，若指令为空则直接返回</li><li>如果指令不是一个内置指令(用builtin_cmd判断，若是内置命令直接执行返回)，先清空中断向量mask，然后传入SIGCHLD并用sigprocmask传入SIG_BLOCK对mask进行阻塞，这样做的目的是阻塞SIGCHLD防止addjob和deletejob出现竞争；接下来fork子进程执行输入的命令，将该子进程用setpgid添加到新的进程组，防止与shell程序冲突，最后UNBLOCK掉SIGCHLD并用execve执行即可</li><li>父进程直接根据bg/fg信号调用addjob，并解除阻塞</li><li>如果是前台进程，则需要等待前台进程完成；如果是后台进程则直接打印出进程信息即可(和结果保持一致)</li></ul><h2 id="builtin_cmd函数">builtin_cmd函数</h2><p>依照书中方法实现即可：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> <span class="hljs-title function_">builtin_cmd</span><span class="hljs-params">(<span class="hljs-type">char</span> **argv)</span> <br>&#123;<br>    <span class="hljs-keyword">if</span>(!<span class="hljs-built_in">strcmp</span>(argv[<span class="hljs-number">0</span>], <span class="hljs-string">&quot;quit&quot;</span>))<br>        <span class="hljs-built_in">exit</span>(<span class="hljs-number">0</span>);<br>    <span class="hljs-keyword">if</span>(!<span class="hljs-built_in">strcmp</span>(argv[<span class="hljs-number">0</span>], <span class="hljs-string">&quot;bg&quot;</span>) || !<span class="hljs-built_in">strcmp</span>(argv[<span class="hljs-number">0</span>], <span class="hljs-string">&quot;fg&quot;</span>) )&#123;<br>        do_bgfg(argv);<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>    &#125;<br>    <span class="hljs-keyword">if</span>(!<span class="hljs-built_in">strcmp</span>(argv[<span class="hljs-number">0</span>], <span class="hljs-string">&quot;jobs&quot;</span>))&#123;<br>        listjobs(jobs);<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>    &#125;<br>    <span class="hljs-keyword">if</span>(!<span class="hljs-built_in">strcmp</span>(argv[<span class="hljs-number">0</span>], <span class="hljs-string">&quot;&amp;&quot;</span>))&#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;     <span class="hljs-comment">/* not a builtin command */</span><br>&#125;<br></code></pre></td></tr></table></figure><p>内置命令函数builtin_cmd实现较为简单，由writeup可知除了书中实现的quit和&amp;以外还要实现bg、fg、jobs的判断与执行，按照定义添加即可</p><h2 id="do_bgfg函数">do_bgfg函数</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * do_bgfg - Execute the builtin bg and fg commands</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">do_bgfg</span><span class="hljs-params">(<span class="hljs-type">char</span> **argv)</span> <br>&#123;<br>    <span class="hljs-keyword">if</span>(argv[<span class="hljs-number">1</span>] == <span class="hljs-literal">NULL</span>)&#123;<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%s command requires an argument\n&quot;</span>,argv[<span class="hljs-number">0</span>]);<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">job_t</span> *<span class="hljs-title">job</span>;</span><br>    <span class="hljs-type">int</span> id;<br>    <span class="hljs-type">sigset_t</span> mask,prev;<br>    <span class="hljs-type">char</span> *shell_para = argv[<span class="hljs-number">1</span>];<br>    sigfillset(&amp;mask);<br>    <span class="hljs-keyword">if</span>(shell_para[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;%&#x27;</span>)&#123;<br>        id = atoi(shell_para + <span class="hljs-number">1</span>);<br>        <span class="hljs-keyword">if</span>(id == <span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%s: argument must be a legal pid or jid\n&quot;</span>,param);<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">else</span>&#123;<br>        id = atoi(shell_para);<br>        <span class="hljs-keyword">if</span>(id == <span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;%s: argument must be a legal pid or jid\n&quot;</span>,param);<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        sigprocmask(SIG_BLOCK,&amp;mask,&amp;prev);<br>        id = pid2jid(id);<br>    &#125;<br>    <span class="hljs-keyword">if</span>(!<span class="hljs-built_in">strcmp</span>(argv[<span class="hljs-number">0</span>],<span class="hljs-string">&quot;bg&quot;</span>))&#123;<br>        kill(-(job-&gt;pid),SIGCONT);<br>        job-&gt;state = BG;<br>        <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;[%d] (%d) %s&quot;</span>,job-&gt;jid,job-&gt;pid,job-&gt;cmdline);<br>    &#125;<br>    <span class="hljs-keyword">else</span>&#123;<br>        kill(-(job-&gt;pid),SIGCONT);<br>        job-&gt;state = FG;<br>        waitfg(job-&gt;pid);<br>    &#125;<br>    <span class="hljs-keyword">return</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>do_bgfg函数就是正常的执行内置的bg/fg命令</p><ul><li>如果后面无参数，直接按标准的输出printf即可<code>printf("%s command requires an argument\n",argv[0]);</code></li><li>如果有参数则按定义处理该参数即可，用atoi处理参数(注意分别pid/jid)，如果是pid的话要先BLOCK信号然后将pid转化为jid，最后按照fg/bg定义执行即可(<strong>注意</strong>：要发送SIGCONT信号)</li></ul><h2 id="waitfg函数">waitfg函数</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * waitfg - Block until process pid is no longer the foreground process</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">waitfg</span><span class="hljs-params">(<span class="hljs-type">pid_t</span> pid)</span><br>&#123;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">job_t</span>* <span class="hljs-title">job</span>;</span><br>    job = getjobpid(jobs,pid);<br>    <span class="hljs-keyword">while</span>(job-&gt;state == FG)&#123;<br>        sleep(<span class="hljs-number">1</span>);<br>    &#125;<br>    <span class="hljs-keyword">return</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p>waitfg函数阻塞进程直到没有前台进程执行</p><p>该函数实现简单，直接按照官网writeup的方式实现，用一个sleep不断等待即可</p><h2 id="三个signal_handler实现">三个signal_handler实现</h2><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/*****************</span><br><span class="hljs-comment"> * Signal handlers</span><br><span class="hljs-comment"> *****************/</span><br><br><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * sigchld_handler - The kernel sends a SIGCHLD to the shell whenever</span><br><span class="hljs-comment"> *     a child job terminates (becomes a zombie), or stops because it</span><br><span class="hljs-comment"> *     received a SIGSTOP or SIGTSTP signal. The handler reaps all</span><br><span class="hljs-comment"> *     available zombie children, but doesn&#x27;t wait for any other</span><br><span class="hljs-comment"> *     currently running children to terminate.  </span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">sigchld_handler</span><span class="hljs-params">(<span class="hljs-type">int</span> sig)</span> <br>&#123;<br>    <span class="hljs-type">int</span> status;  <br>    <span class="hljs-type">pid_t</span> pid;  <br>    <br>    <span class="hljs-keyword">while</span> ((pid = waitpid(fgpid(jobs), &amp;status, WNOHANG | WUNTRACED)) &gt; <span class="hljs-number">0</span>) &#123;  <br>        <span class="hljs-keyword">if</span> (WIFSTOPPED(status))&#123; <br>            <span class="hljs-comment">//change state if stopped</span><br>            getjobpid(jobs, pid)-&gt;state = ST;<br>            <span class="hljs-type">int</span> jid = pid2jid(pid);<br>            <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Job [%d] (%d) Stopped by signal %d\n&quot;</span>, jid, pid, WSTOPSIG(status));<br>        &#125;  <br>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (WIFSIGNALED(status))&#123;<br>            <span class="hljs-comment">//delete is signaled</span><br>            <span class="hljs-type">int</span> jid = pid2jid(pid);  <br>            <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;Job [%d] (%d) terminated by signal %d\n&quot;</span>, jid, pid, WTERMSIG(status));<br>            deletejob(jobs, pid);<br>        &#125;  <br>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (WIFEXITED(status))&#123;  <br>            <span class="hljs-comment">//exited</span><br>            deletejob(jobs, pid);  <br>        &#125;  <br>    &#125;  <br>    <span class="hljs-keyword">return</span>; <br>&#125;<br><br><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * sigint_handler - The kernel sends a SIGINT to the shell whenver the</span><br><span class="hljs-comment"> *    user types ctrl-c at the keyboard.  Catch it and send it along</span><br><span class="hljs-comment"> *    to the foreground job.  </span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">sigint_handler</span><span class="hljs-params">(<span class="hljs-type">int</span> sig)</span> <br>&#123;<br>    <span class="hljs-type">int</span> pid = fgpid(jobs);<br>    <span class="hljs-keyword">if</span>(pid == <span class="hljs-number">0</span>)&#123;<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    kill(-pid,sig);<br>    <span class="hljs-keyword">return</span>;<br>&#125;<br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * sigtstp_handler - The kernel sends a SIGTSTP to the shell whenever</span><br><span class="hljs-comment"> *     the user types ctrl-z at the keyboard. Catch it and suspend the</span><br><span class="hljs-comment"> *     foreground job by sending it a SIGTSTP.  </span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">sigtstp_handler</span><span class="hljs-params">(<span class="hljs-type">int</span> sig)</span> <br>&#123;<br>    <span class="hljs-type">int</span> pid = fgpid(jobs);<br>    <span class="hljs-keyword">if</span>(pid == <span class="hljs-number">0</span>)&#123;<br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    kill(-pid,sig);<br>    <span class="hljs-keyword">return</span>;<br>&#125;<br></code></pre></td></tr></table></figure><h3 id="sigchld_handler">sigchld_handler</h3><p>sigchld的处理应该是三个要实现的信号处理中最复杂的一个：</p><p>首先我们需要等待该进程所有的子进程都结束就立即返回，按照书中的信号实现即wait中的参数为<code>WNOHANG | WUNTRACED</code></p><p>如果退出的子进程为被终止的清空，那么改变该进程的state并直接打印标准输出即可；如果是被signal中断退出，那么打terminatedbysignal并调用deletejob删除即可；如果退出的子进程为正常退出的清空，那么直接调用delete删除即可</p><h3 id="sigint_handler">sigint_handler</h3><p>sigint信号的处理比较简单，直接获取进程号，如果是子进程直接返回即可；如果是父进程直接kill掉该进程的<strong>所有进程组内的进程</strong>并返回即可</p><h3 id="sigtstp_handler">sigtstp_handler</h3><p>与sigint的处理方式相同(效果一样)</p><h2 id="总结">总结</h2><p>本次实验我对shell内部工作原理有了一定的理解，尤其是处理前后台进程，以及对各种信号产生的中断进行处理，最重要的是本次实验以及书中的章节对《操作系统概念》一书中没有仔细讲解的信号做了大量讲解，对我来说极大地补充了操作系统原理的知识面，是一次非常有收获的实验体验</p>]]></content>
    
    
    <categories>
      
      <category>计算机基础</category>
      
      <category>CSAPP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CSAPP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CSAPP Cachelab总结</title>
    <link href="/2022/07/19/CSAPP/cachelab/"/>
    <url>/2022/07/19/CSAPP/cachelab/</url>
    
    <content type="html"><![CDATA[<h2 id="part-a">Part A</h2><p>第一部分是用C语言实现一个Cache模拟器，实现代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br></pre></div></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;cachelab.h&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdlib.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;string.h&gt;</span></span><br><span class="hljs-type">int</span> s,S,E,b;<br>FILE *fp;<br><span class="hljs-type">int</span> hit_count,miss_count,eviction_count;<br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> _<span class="hljs-title">Cache</span>&#123;</span><br>    <span class="hljs-type">int</span> valid,tag,last_visited;<br>&#125;Cache;<br>Cache ** cache= <span class="hljs-literal">NULL</span>; <br><span class="hljs-type">char</span> input[<span class="hljs-number">100</span>];<br><span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> <span class="hljs-title function_">char2hex</span><span class="hljs-params">(<span class="hljs-type">char</span> c)</span>&#123;<br><span class="hljs-comment">//printf(&quot;arg=%c\n&quot;,c);</span><br><span class="hljs-keyword">if</span>(c &gt;= <span class="hljs-string">&#x27;0&#x27;</span>&amp;&amp; c &lt;= <span class="hljs-string">&#x27;9&#x27;</span>)&#123;<br> <span class="hljs-comment">//printf(&quot;value = %d\n&quot;,c - &#x27;0&#x27;);</span><br>         <span class="hljs-keyword">return</span> c - <span class="hljs-string">&#x27;0&#x27;</span>;<br>    &#125;<br><span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(c &gt;= <span class="hljs-string">&#x27;a&#x27;</span> &amp;&amp; c &lt;= <span class="hljs-string">&#x27;f&#x27;</span>)&#123;<br>        <span class="hljs-keyword">return</span> c - <span class="hljs-string">&#x27;a&#x27;</span> + <span class="hljs-number">10</span>;<br>    &#125;<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(c &gt;= <span class="hljs-string">&#x27;A&#x27;</span> &amp;&amp; c &lt;= <span class="hljs-string">&#x27;F&#x27;</span>)&#123;<br>        <span class="hljs-keyword">return</span> c - <span class="hljs-string">&#x27;A&#x27;</span> + <span class="hljs-number">10</span>;<br>    &#125;<br><span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">parse</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> **argv)</span><br>&#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; argc; i++)&#123;<br>        <span class="hljs-keyword">if</span>(argv[i][<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;-&#x27;</span>)&#123;<br>            <span class="hljs-keyword">if</span>(argv[i][<span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;s&#x27;</span>)<br>            &#123;<br>                s = atoi(argv[++i]);<br>                S = <span class="hljs-number">1</span> &lt;&lt; s;<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(argv[i][<span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;E&#x27;</span>)&#123;<br>                E = atoi(argv[++i]);<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(argv[i][<span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;b&#x27;</span>)&#123;<br>                b = atoi(argv[++i]);<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(argv[i][<span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;t&#x27;</span>)&#123;<br>            i++;<br>                fp = fopen((argv[i]),<span class="hljs-string">&quot;r&quot;</span>);<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br><span class="hljs-type">void</span> <span class="hljs-title function_">cache_option</span><span class="hljs-params">(<span class="hljs-type">int</span> op,<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> addr,<span class="hljs-type">int</span> size,<span class="hljs-type">int</span> time)</span><br>&#123;<br>    <span class="hljs-type">int</span> tag,index;<br>    index = (addr &gt;&gt; b) &amp; ((<span class="hljs-number">-1U</span>) &gt;&gt; (<span class="hljs-number">32</span> - s));<br>    tag = addr &gt;&gt; (s + b);<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;op=%d addr=%x tag:%x index=%x\n&quot;</span>,op,addr,tag,index);<br>    <span class="hljs-keyword">if</span>(op == <span class="hljs-number">1</span>)&#123;    <span class="hljs-comment">// I_type</span><br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    <span class="hljs-keyword">if</span>(op == <span class="hljs-number">2</span> || op == <span class="hljs-number">4</span>)&#123;   <span class="hljs-comment">// S_type or M_type need to write to the cache</span><br>        <span class="hljs-type">int</span> hit = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; E;i++)&#123;<br>            <span class="hljs-keyword">if</span>(cache[index][i].tag == tag)&#123;   <span class="hljs-comment">//hit</span><br>                cache[index][i].last_visited = <span class="hljs-number">0</span>;<br>                hit_count++;<br>                hit = <span class="hljs-number">1</span>;<br>                <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;hit\n&quot;</span>);<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">if</span>(hit == <span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-type">int</span> sign = <span class="hljs-number">0</span>;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; E;i++)&#123;<br>                <span class="hljs-keyword">if</span>(cache[index][i].valid == <span class="hljs-number">0</span>)&#123;<br>                    cache[index][i].valid = <span class="hljs-number">1</span>;<br>                    cache[index][i].last_visited = <span class="hljs-number">0</span>;<br>                    cache[index][i].tag = tag; <br>                    sign = <span class="hljs-number">1</span>;<br>                    miss_count++;<br>                    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;miss\n&quot;</span>);<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">if</span>(sign == <span class="hljs-number">0</span>)&#123;<br>                eviction_count++;<br>                miss_count++;<br>                <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;eviction\nmiss\n&quot;</span>);<br>                <span class="hljs-type">int</span> flag = <span class="hljs-number">0</span>,max_last_visited = <span class="hljs-number">0</span>;<br>                <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; E;i++)&#123;<br>                    <span class="hljs-keyword">if</span>(cache[index][i].last_visited &gt; max_last_visited)&#123;<br>                        max_last_visited = cache[index][i].last_visited;<br>                        flag = i;<br>                    &#125;<br>                &#125;<br>                cache[index][flag].last_visited = <span class="hljs-number">0</span>;<br>                cache[index][flag].tag = tag;<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">if</span>(op == <span class="hljs-number">3</span> || op == <span class="hljs-number">4</span>)&#123; <span class="hljs-comment">// L_type or M_type need to write the cache</span><br>        <span class="hljs-type">int</span> hit = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; E;i++)&#123;<br>            <span class="hljs-keyword">if</span>(cache[index][i].tag == tag)&#123;   <span class="hljs-comment">//hit</span><br>                cache[index][i].last_visited = <span class="hljs-number">0</span>;<br>                hit_count++;<br>                <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;hit\n&quot;</span>);<br>                hit = <span class="hljs-number">1</span>;<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">if</span>(hit == <span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-type">int</span> sign = <span class="hljs-number">0</span>;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; E;i++)&#123;<br>                <span class="hljs-keyword">if</span>(cache[index][i].valid == <span class="hljs-number">0</span>)&#123;<br>                    cache[index][i].valid = <span class="hljs-number">1</span>;<br>                    cache[index][i].last_visited = <span class="hljs-number">0</span>;<br>                    cache[index][i].tag = tag; <br>                    sign = <span class="hljs-number">1</span>;<br>                    miss_count++;<br>                    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;miss\n&quot;</span>);<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">if</span>(sign == <span class="hljs-number">0</span>)&#123;<br>                eviction_count++;<br>                miss_count++;<br>                <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;eviction\nmiss\n&quot;</span>);<br>                <span class="hljs-type">int</span> flag = <span class="hljs-number">0</span>,max_last_visited = <span class="hljs-number">0</span>;<br>                <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; E;i++)&#123;<br>                    <span class="hljs-keyword">if</span>(cache[index][i].last_visited &gt; max_last_visited)&#123;<br>                        max_last_visited = cache[index][i].last_visited;<br>                        flag = i;<br>                    &#125;<br>                &#125;<br>                cache[index][flag].last_visited = <span class="hljs-number">0</span>;<br>                cache[index][flag].tag = tag;<br>            &#125;<br>        &#125;      <br>    &#125;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; S;i++)&#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; E;j++)&#123;<br>            <span class="hljs-keyword">if</span>(cache[i][j].valid == <span class="hljs-number">1</span>)&#123;<br>                cache[i][j].last_visited++;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br><span class="hljs-type">int</span> <span class="hljs-title function_">main</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span>* argv[])</span><br>&#123;<br>    parse(argc,argv);<br>    <span class="hljs-comment">//printf(&quot;s:%d S:%d E:%d b:%d&quot;,s,S,E,b);</span><br>    hit_count = <span class="hljs-number">0</span>;<br>    miss_count = <span class="hljs-number">0</span>;<br>    eviction_count = <span class="hljs-number">0</span>;<br>    cache = (Cache **)<span class="hljs-built_in">malloc</span>(<span class="hljs-keyword">sizeof</span>(Cache *) * S);<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; S;i++)&#123;<br>        cache[i] = (Cache *)<span class="hljs-built_in">malloc</span>(<span class="hljs-keyword">sizeof</span>(Cache) * E);<br>    &#125;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; S;i++)&#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; E;j++)&#123;<br>            cache[i][j].last_visited = <span class="hljs-number">-1</span>;<br>            cache[i][j].valid = <span class="hljs-number">0</span>;<br>            cache[i][j].tag = <span class="hljs-number">-1</span>;<br>        &#125;<br>    &#125;<br>    <span class="hljs-type">int</span> time = <span class="hljs-number">0</span>;<br>    <span class="hljs-keyword">while</span>(fgets(input,<span class="hljs-number">200</span>,fp))&#123;<br>        <span class="hljs-comment">//printf(&quot;%s\n&quot;,input);</span><br>        <span class="hljs-type">int</span> flag = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> size = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> addr = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> len = <span class="hljs-built_in">strlen</span>(input) - <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span> op = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; len;i++)&#123;<br>            <span class="hljs-keyword">if</span>(input[i] == <span class="hljs-string">&#x27;I&#x27;</span>)&#123;<br>                op = <span class="hljs-number">1</span>;<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(input[i] == <span class="hljs-string">&#x27;S&#x27;</span>)&#123;<br>                op = <span class="hljs-number">2</span>;<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(input[i] == <span class="hljs-string">&#x27;L&#x27;</span>)&#123;<br>                op = <span class="hljs-number">3</span>;<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(input[i] == <span class="hljs-string">&#x27;M&#x27;</span>)&#123;<br>                op = <span class="hljs-number">4</span>;<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(input[i] == <span class="hljs-string">&#x27; &#x27;</span>)&#123;<br>                <span class="hljs-keyword">continue</span>;<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(input[i] == <span class="hljs-string">&#x27;,&#x27;</span>)&#123;<br>                flag = <span class="hljs-number">1</span>;<br>                <span class="hljs-comment">//op = 0;</span><br>            &#125;<br>            <span class="hljs-keyword">else</span>&#123;<br>                <span class="hljs-keyword">if</span>(flag == <span class="hljs-number">0</span>)&#123;<br>                    <span class="hljs-comment">//printf(&quot;%c\n&quot;,input[i]);</span><br>                    addr = addr * <span class="hljs-number">16</span> + char2hex(input[i]);<br>                    <span class="hljs-comment">//printf(&quot;ADDR=%x\n&quot;,addr);</span><br>                &#125;<br>                <span class="hljs-keyword">else</span>&#123;<br>                    size = size * <span class="hljs-number">10</span> + (input[i] - <span class="hljs-string">&#x27;0&#x27;</span>);<br>                &#125;<br>            &#125;<br>            <span class="hljs-comment">//cache_option(op,addr,size,time);</span><br>        &#125;<br>        <span class="hljs-comment">//printf(&quot;addr=%x size=%x\n&quot;,addr,size);</span><br>        cache_option(op,addr,size,time);<br>    &#125;<br>    printSummary(hit_count,miss_count,eviction_count);<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; S;i++)&#123;<br>        <span class="hljs-built_in">free</span>(cache[i]);<br>    &#125;<br>    <span class="hljs-built_in">free</span>(cache);<br>    fclose(fp);<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>s,S用来记录组索引位数和组数(<code>S = 2^s</code>)</p><p>E记录每组行数</p><p>b记录块索引位数</p><p>(上述参数与书中描述相同)</p><p>然后定义一个Cache结构体来模拟</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> _<span class="hljs-title">Cache</span>&#123;</span><br>    <span class="hljs-type">int</span> valid,tag,last_visited;<br>&#125;Cache;<br></code></pre></td></tr></table></figure><p>char2hex函数将字符转为十六进制下的数值，该函数原理简单不过多赘述</p><p>parse函数处理命令行输入的命令，为Cache的各个参数进行赋值，直接按定义实现：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">parse</span><span class="hljs-params">(<span class="hljs-type">int</span> argc, <span class="hljs-type">char</span> **argv)</span><br>&#123;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; argc; i++)&#123;<br>        <span class="hljs-keyword">if</span>(argv[i][<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;-&#x27;</span>)&#123;<br>            <span class="hljs-keyword">if</span>(argv[i][<span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;s&#x27;</span>)<br>            &#123;<br>                s = atoi(argv[++i]);<br>                S = <span class="hljs-number">1</span> &lt;&lt; s;<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(argv[i][<span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;E&#x27;</span>)&#123;<br>                E = atoi(argv[++i]);<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(argv[i][<span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;b&#x27;</span>)&#123;<br>                b = atoi(argv[++i]);<br>            &#125;<br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(argv[i][<span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;t&#x27;</span>)&#123;<br>            i++;<br>                fp = fopen((argv[i]),<span class="hljs-string">&quot;r&quot;</span>);<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>接下来是最重要的Cache模拟函数</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">cache_option</span><span class="hljs-params">(<span class="hljs-type">int</span> op,<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> addr,<span class="hljs-type">int</span> size,<span class="hljs-type">int</span> time)</span><br>&#123;<br>    <span class="hljs-type">int</span> tag,index;<br>    index = (addr &gt;&gt; b) &amp; ((<span class="hljs-number">-1U</span>) &gt;&gt; (<span class="hljs-number">32</span> - s));<br>    tag = addr &gt;&gt; (s + b);<br>    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;op=%d addr=%x tag:%x index=%x\n&quot;</span>,op,addr,tag,index);<br>    <span class="hljs-keyword">if</span>(op == <span class="hljs-number">1</span>)&#123;    <span class="hljs-comment">// I_type</span><br>        <span class="hljs-keyword">return</span>;<br>    &#125;<br>    <span class="hljs-keyword">if</span>(op == <span class="hljs-number">2</span> || op == <span class="hljs-number">4</span>)&#123;   <span class="hljs-comment">// S_type or M_type need to write to the cache</span><br>        <span class="hljs-type">int</span> hit = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; E;i++)&#123;<br>            <span class="hljs-keyword">if</span>(cache[index][i].tag == tag)&#123;   <span class="hljs-comment">//hit</span><br>                cache[index][i].last_visited = <span class="hljs-number">0</span>;<br>                hit_count++;<br>                hit = <span class="hljs-number">1</span>;<br>                <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;hit\n&quot;</span>);<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">if</span>(hit == <span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-type">int</span> sign = <span class="hljs-number">0</span>;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; E;i++)&#123;<br>                <span class="hljs-keyword">if</span>(cache[index][i].valid == <span class="hljs-number">0</span>)&#123;<br>                    cache[index][i].valid = <span class="hljs-number">1</span>;<br>                    cache[index][i].last_visited = <span class="hljs-number">0</span>;<br>                    cache[index][i].tag = tag; <br>                    sign = <span class="hljs-number">1</span>;<br>                    miss_count++;<br>                    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;miss\n&quot;</span>);<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">if</span>(sign == <span class="hljs-number">0</span>)&#123;<br>                eviction_count++;<br>                miss_count++;<br>                <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;eviction\nmiss\n&quot;</span>);<br>                <span class="hljs-type">int</span> flag = <span class="hljs-number">0</span>,max_last_visited = <span class="hljs-number">0</span>;<br>                <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; E;i++)&#123;<br>                    <span class="hljs-keyword">if</span>(cache[index][i].last_visited &gt; max_last_visited)&#123;<br>                        max_last_visited = cache[index][i].last_visited;<br>                        flag = i;<br>                    &#125;<br>                &#125;<br>                cache[index][flag].last_visited = <span class="hljs-number">0</span>;<br>                cache[index][flag].tag = tag;<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">if</span>(op == <span class="hljs-number">3</span> || op == <span class="hljs-number">4</span>)&#123; <span class="hljs-comment">// L_type or M_type need to write the cache</span><br>        <span class="hljs-type">int</span> hit = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; E;i++)&#123;<br>            <span class="hljs-keyword">if</span>(cache[index][i].tag == tag)&#123;   <span class="hljs-comment">//hit</span><br>                cache[index][i].last_visited = <span class="hljs-number">0</span>;<br>                hit_count++;<br>                <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;hit\n&quot;</span>);<br>                hit = <span class="hljs-number">1</span>;<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">if</span>(hit == <span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-type">int</span> sign = <span class="hljs-number">0</span>;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; E;i++)&#123;<br>                <span class="hljs-keyword">if</span>(cache[index][i].valid == <span class="hljs-number">0</span>)&#123;<br>                    cache[index][i].valid = <span class="hljs-number">1</span>;<br>                    cache[index][i].last_visited = <span class="hljs-number">0</span>;<br>                    cache[index][i].tag = tag; <br>                    sign = <span class="hljs-number">1</span>;<br>                    miss_count++;<br>                    <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;miss\n&quot;</span>);<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">if</span>(sign == <span class="hljs-number">0</span>)&#123;<br>                eviction_count++;<br>                miss_count++;<br>                <span class="hljs-built_in">printf</span>(<span class="hljs-string">&quot;eviction\nmiss\n&quot;</span>);<br>                <span class="hljs-type">int</span> flag = <span class="hljs-number">0</span>,max_last_visited = <span class="hljs-number">0</span>;<br>                <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; E;i++)&#123;<br>                    <span class="hljs-keyword">if</span>(cache[index][i].last_visited &gt; max_last_visited)&#123;<br>                        max_last_visited = cache[index][i].last_visited;<br>                        flag = i;<br>                    &#125;<br>                &#125;<br>                cache[index][flag].last_visited = <span class="hljs-number">0</span>;<br>                cache[index][flag].tag = tag;<br>            &#125;<br>        &#125;      <br>    &#125;<br>    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; S;i++)&#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; E;j++)&#123;<br>            <span class="hljs-keyword">if</span>(cache[i][j].valid == <span class="hljs-number">1</span>)&#123;<br>                cache[i][j].last_visited++;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><p>访问地址的index和tag位按定义设置即可，通过op值来区分I/S/L/M四种type的指令，需要注意的一点是，Mtype指令既需要读也需要写，所以在读写的if中均加入Mtype的情况将其在读写两种情况中均执行一遍即可</p><ul><li>如果是Itype指令，那么对Cache无读写操作，直接返回即可</li><li>如果是Stype或Mtype，那么会对Cache执行一次写操作，对Cache的每一行搜索tag值，如果命中则更新hit_count(总命中数)和上次访问时间last_count，标志本次访问标记hit为1(代表命中)；若未命中则按照定义向Cache中执行写入，如果有valid的行则写入valid行并给miss_count计数，修改Cache该行的参数即可；若没有valid行则通过LRU策略选最久未访问的行进行替换，给eviction_count和miss_count计数并更新Cache的参数</li><li>如果是Ltype或Mtype，那么会对Cache执行一次读操作，由于我们的模拟器对Cache只执行模拟不执行实际的读写，故读操作和写操作在模拟中的行为是一样的，在此不重复赘述，参考上面写操作过程即可</li></ul><p>这样就完成了Cache的模拟</p><p>在主函数中按顺序处理参数-按参数对Cache初始化(由于s，E，B参数不固定故采取堆分配初始化Cache)-读入模拟指令-调用cache_option进行模拟cache-打印hit/miss/eviction三种行为的数量-freecache即可</p><h2 id="part-b">Part B</h2><p>第二部分要完成一个矩阵转置，但要求Cachemiss数量尽可能少，测试情况有三种：32x32，64x64，61x67</p><p>由于<code>b = 5</code>，故块大小为<code>2^5=32</code>，又由于<code>sizeof(int) = 4</code>，所以每个块内可放<code>32 / sizeof(int) = 8</code>个数据</p><p>，并且有2^5组(<code>s = 5</code>)，每组1行</p><h3 id="x32">32x32</h3><p>由于Cache的一行能存储八个数据，所以很自然的会考虑8x8的矩阵分块形式</p><p>注意到writeup中写到我们只能使用12个变量(也就是寄存器)，那么为什么会提到这一点呢：这是因为变量是寄存器，如果我们把数据存到变量再存储到另一个矩阵中，这样就比正常的<code>B[j][i] = A[i][j]</code>少了当<code>i=j</code>时，<code>B[j]</code>这一行会替换<code>A[i]</code>那一行导致的miss，可以在一定程度上减少miss数量</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; <span class="hljs-number">4</span>;i++)&#123;<br>          <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">4</span>;j++)&#123;<br>              <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> k = (i &lt;&lt; <span class="hljs-number">3</span>); k &lt; ((i + <span class="hljs-number">1</span>) &lt;&lt; <span class="hljs-number">3</span>);k++)&#123;<br>                  <span class="hljs-type">int</span> h = j &lt;&lt; <span class="hljs-number">3</span>;<br>                  r1 = A[k][h];<br>                  r2 = A[k][h + <span class="hljs-number">1</span>];<br>                  r3 = A[k][h + <span class="hljs-number">2</span>];<br>                  r4 = A[k][h + <span class="hljs-number">3</span>];<br>                  r5 = A[k][h + <span class="hljs-number">4</span>];<br>                  r6 = A[k][h + <span class="hljs-number">5</span>];<br>                  r7 = A[k][h + <span class="hljs-number">6</span>];<br>                  r8 = A[k][h + <span class="hljs-number">7</span>];<br>                  <br>                  B[h][k] = r1;<br>                  B[h + <span class="hljs-number">1</span>][k] = r2;<br>                  B[h + <span class="hljs-number">2</span>][k] = r3;<br>                  B[h + <span class="hljs-number">3</span>][k] = r4;<br>                  B[h + <span class="hljs-number">4</span>][k] = r5;<br>                  B[h + <span class="hljs-number">5</span>][k] = r6;<br>                  B[h + <span class="hljs-number">6</span>][k] = r7;<br>                  B[h + <span class="hljs-number">7</span>][k] = r8;<br>              &#125;<br>          &#125;<br>      &#125;<br></code></pre></td></tr></table></figure><p>这样我们使用8个变量(不超过限制)，就可以将miss数缩小到满分的300以内()</p><h3 id="x64">64x64</h3><p>由于这次矩阵变为64x64的int矩阵，所以一个Cache只能存储四行，很自然的会想到将矩阵进行4x4分块，但是这样分块又会导致Cache一行八块不能充分利用(不能全中)，所以为了更好的利用题目中给定参数的Cache，我们将矩阵先分成8x8的块，再将8x8的块分成4x4的块</p><p>注意到采用这种方式的分块会导致每隔四行Cache就会被覆盖，所以我们采取先对8x8中的上半部的两个4x4先转置后复制的策略(这样可以避免4x4带来的浪费)，然后将下半部每隔分隔4列的两列中的8个元素依次放到寄存器中，然后不断对这八个元素找到对应位置然后换位赋值(就是原来先复制后赋值过程中一开始错放的位置)，这样不断重复完成赋值：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; <span class="hljs-number">64</span>;i += <span class="hljs-number">8</span>)&#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">64</span>;j += <span class="hljs-number">8</span>)&#123;<br>                <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> k = i;k &lt; i + <span class="hljs-number">4</span>;k++)&#123;<br>                    r1 = A[k][j];<br>                    r2 = A[k][j + <span class="hljs-number">1</span>];<br>                    r3 = A[k][j + <span class="hljs-number">2</span>];<br>                    r4 = A[k][j + <span class="hljs-number">3</span>];<br>                    r5 = A[k][j + <span class="hljs-number">4</span>];<br>                    r6 = A[k][j + <span class="hljs-number">5</span>];<br>                    r7 = A[k][j + <span class="hljs-number">6</span>];<br>                    r8 = A[k][j + <span class="hljs-number">7</span>];<br><br>                    B[j][k] = r1;<br>                    B[j + <span class="hljs-number">1</span>][k] = r2;<br>                    B[j + <span class="hljs-number">2</span>][k] = r3;<br>                    B[j + <span class="hljs-number">3</span>][k] = r4;<br>                    B[j][k + <span class="hljs-number">4</span>] = r5;<br>                    B[j + <span class="hljs-number">1</span>][k + <span class="hljs-number">4</span>] = r6;<br>                    B[j + <span class="hljs-number">2</span>][k + <span class="hljs-number">4</span>] = r7;<br>                    B[j + <span class="hljs-number">3</span>][k + <span class="hljs-number">4</span>] = r8;<br>                &#125;<br>                <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> k = j;k &lt; j + <span class="hljs-number">4</span>;k++)&#123;<br>                    r1 = A[i + <span class="hljs-number">4</span>][k];<br>                    r5 = A[i + <span class="hljs-number">4</span>][k + <span class="hljs-number">4</span>];<br>                    r2 = A[i + <span class="hljs-number">5</span>][k];<br>                    r6 = A[i + <span class="hljs-number">5</span>][k + <span class="hljs-number">4</span>];<br>                    r3 = A[i + <span class="hljs-number">6</span>][k];<br>                    r7 = A[i + <span class="hljs-number">6</span>][k + <span class="hljs-number">4</span>];<br>                    r4 = A[i + <span class="hljs-number">7</span>][k];<br>                    r8 = A[i + <span class="hljs-number">7</span>][k + <span class="hljs-number">4</span>];<br><br>                    tran = B[k][i + <span class="hljs-number">4</span>];<br>                    B[k][i + <span class="hljs-number">4</span>] = r1;<br>                    r1 = tran;<br>                    tran = B[k][i + <span class="hljs-number">5</span>];<br>                    B[k][i + <span class="hljs-number">5</span>] = r2;<br>                    r2 = tran;<br>                    tran = B[k][i + <span class="hljs-number">6</span>];<br>                    B[k][i + <span class="hljs-number">6</span>] = r3;<br>                    r3 = tran;<br>                    tran = B[k][i + <span class="hljs-number">7</span>];<br>                    B[k][i + <span class="hljs-number">7</span>] = r4;<br>                    r4 = tran;<br><br>                    B[k + <span class="hljs-number">4</span>][i] = r1;<br>                    B[k + <span class="hljs-number">4</span>][i + <span class="hljs-number">4</span>] = r5;<br>                    B[k + <span class="hljs-number">4</span>][i + <span class="hljs-number">1</span>] = r2;<br>                    B[k + <span class="hljs-number">4</span>][i + <span class="hljs-number">5</span>] = r6;<br>                    B[k + <span class="hljs-number">4</span>][i + <span class="hljs-number">2</span>] = r3;<br>                    B[k + <span class="hljs-number">4</span>][i + <span class="hljs-number">6</span>] = r7;<br>                    B[k + <span class="hljs-number">4</span>][i + <span class="hljs-number">3</span>] = r4;<br>                    B[k + <span class="hljs-number">4</span>][i + <span class="hljs-number">7</span>] = r8;<br>                &#125;<br>            &#125;<br>        &#125;<br></code></pre></td></tr></table></figure><h3 id="x67">61x67</h3><p>最后一种情况比64x64简单一些，我们直接矩阵进行8x8进行分块然后对其他块直接转置即可，测试可知这样即可满足要求：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; N;i += <span class="hljs-number">8</span>)&#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; M;j++)&#123;<br>                <span class="hljs-keyword">if</span>(i + <span class="hljs-number">8</span> &lt;= N &amp;&amp; j &lt; M)&#123;<br>                    r1 = A[i][j];<br>                    r2 = A[i + <span class="hljs-number">1</span>][j];<br>                    r3 = A[i + <span class="hljs-number">2</span>][j];<br>                    r4 = A[i + <span class="hljs-number">3</span>][j];<br>                    r5 = A[i + <span class="hljs-number">4</span>][j];<br>                    r6 = A[i + <span class="hljs-number">5</span>][j];<br>                    r7 = A[i + <span class="hljs-number">6</span>][j];<br>                    r8 = A[i + <span class="hljs-number">7</span>][j];<br>                    <br>                    B[j][i] = r1;<br>                    B[j][i + <span class="hljs-number">1</span>] = r2;<br>                    B[j][i + <span class="hljs-number">2</span>] = r3;<br>                    B[j][i + <span class="hljs-number">3</span>] = r4;<br>                    B[j][i + <span class="hljs-number">4</span>] = r5;<br>                    B[j][i + <span class="hljs-number">5</span>] = r6;<br>                    B[j][i + <span class="hljs-number">6</span>] = r7;<br>                    B[j][i + <span class="hljs-number">7</span>] = r8;<br>                &#125;<br>                <span class="hljs-keyword">else</span>&#123;<br>                    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> k = i; k &lt; i + <span class="hljs-number">8</span> &amp;&amp; k &lt; N; k++)&#123;<br>                        B[j][k] = A[k][j];<br>                    &#125;<br>                &#125;<br>            &#125;<br>        &#125;<br></code></pre></td></tr></table></figure><p>trans.c的源代码如下：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * trans.c - Matrix transpose B = A^T</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Each transpose function must have a prototype of the form:</span><br><span class="hljs-comment"> * void trans(int M, int N, int A[N][M], int B[M][N]);</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * A transpose function is evaluated by counting the number of misses</span><br><span class="hljs-comment"> * on a 1KB direct mapped cache with a block size of 32 bytes.</span><br><span class="hljs-comment"> */</span> <br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&lt;stdio.h&gt;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">include</span> <span class="hljs-string">&quot;cachelab.h&quot;</span></span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">is_transpose</span><span class="hljs-params">(<span class="hljs-type">int</span> M, <span class="hljs-type">int</span> N, <span class="hljs-type">int</span> A[N][M], <span class="hljs-type">int</span> B[M][N])</span>;<br><br><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * transpose_submit - This is the solution transpose function that you</span><br><span class="hljs-comment"> *     will be graded on for Part B of the assignment. Do not change</span><br><span class="hljs-comment"> *     the description string &quot;Transpose submission&quot;, as the driver</span><br><span class="hljs-comment"> *     searches for that string to identify the transpose function to</span><br><span class="hljs-comment"> *     be graded. </span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">char</span> transpose_submit_desc[] = <span class="hljs-string">&quot;Transpose submission&quot;</span>;<br><span class="hljs-type">void</span> <span class="hljs-title function_">transpose_submit</span><span class="hljs-params">(<span class="hljs-type">int</span> M, <span class="hljs-type">int</span> N, <span class="hljs-type">int</span> A[N][M], <span class="hljs-type">int</span> B[M][N])</span><br>&#123;<br>    <span class="hljs-type">int</span> r1,r2,r3,r4,r5,r6,r7,r8;<br>    <span class="hljs-keyword">if</span>(N == <span class="hljs-number">32</span>)&#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; <span class="hljs-number">4</span>;i++)&#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">4</span>;j++)&#123;<br>                <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> k = (i &lt;&lt; <span class="hljs-number">3</span>); k &lt; ((i + <span class="hljs-number">1</span>) &lt;&lt; <span class="hljs-number">3</span>);k++)&#123;<br>                    <span class="hljs-type">int</span> h = j &lt;&lt; <span class="hljs-number">3</span>;<br>                    r1 = A[k][h];<br>                    r2 = A[k][h + <span class="hljs-number">1</span>];<br>                    r3 = A[k][h + <span class="hljs-number">2</span>];<br>                    r4 = A[k][h + <span class="hljs-number">3</span>];<br>                    r5 = A[k][h + <span class="hljs-number">4</span>];<br>                    r6 = A[k][h + <span class="hljs-number">5</span>];<br>                    r7 = A[k][h + <span class="hljs-number">6</span>];<br>                    r8 = A[k][h + <span class="hljs-number">7</span>];<br>                    <br>                    B[h][k] = r1;<br>                    B[h + <span class="hljs-number">1</span>][k] = r2;<br>                    B[h + <span class="hljs-number">2</span>][k] = r3;<br>                    B[h + <span class="hljs-number">3</span>][k] = r4;<br>                    B[h + <span class="hljs-number">4</span>][k] = r5;<br>                    B[h + <span class="hljs-number">5</span>][k] = r6;<br>                    B[h + <span class="hljs-number">6</span>][k] = r7;<br>                    B[h + <span class="hljs-number">7</span>][k] = r8;<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(N == <span class="hljs-number">64</span>)&#123;<br>        <span class="hljs-type">int</span> tran;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; <span class="hljs-number">64</span>;i += <span class="hljs-number">8</span>)&#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; <span class="hljs-number">64</span>;j += <span class="hljs-number">8</span>)&#123;<br>                <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> k = i;k &lt; i + <span class="hljs-number">4</span>;k++)&#123;<br>                    r1 = A[k][j];<br>                    r2 = A[k][j + <span class="hljs-number">1</span>];<br>                    r3 = A[k][j + <span class="hljs-number">2</span>];<br>                    r4 = A[k][j + <span class="hljs-number">3</span>];<br>                    r5 = A[k][j + <span class="hljs-number">4</span>];<br>                    r6 = A[k][j + <span class="hljs-number">5</span>];<br>                    r7 = A[k][j + <span class="hljs-number">6</span>];<br>                    r8 = A[k][j + <span class="hljs-number">7</span>];<br><br>                    B[j][k] = r1;<br>                    B[j + <span class="hljs-number">1</span>][k] = r2;<br>                    B[j + <span class="hljs-number">2</span>][k] = r3;<br>                    B[j + <span class="hljs-number">3</span>][k] = r4;<br>                    B[j][k + <span class="hljs-number">4</span>] = r5;<br>                    B[j + <span class="hljs-number">1</span>][k + <span class="hljs-number">4</span>] = r6;<br>                    B[j + <span class="hljs-number">2</span>][k + <span class="hljs-number">4</span>] = r7;<br>                    B[j + <span class="hljs-number">3</span>][k + <span class="hljs-number">4</span>] = r8;<br>                &#125;<br>                <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> k = j;k &lt; j + <span class="hljs-number">4</span>;k++)&#123;<br>                    r1 = A[i + <span class="hljs-number">4</span>][k];<br>                    r5 = A[i + <span class="hljs-number">4</span>][k + <span class="hljs-number">4</span>];<br>                    r2 = A[i + <span class="hljs-number">5</span>][k];<br>                    r6 = A[i + <span class="hljs-number">5</span>][k + <span class="hljs-number">4</span>];<br>                    r3 = A[i + <span class="hljs-number">6</span>][k];<br>                    r7 = A[i + <span class="hljs-number">6</span>][k + <span class="hljs-number">4</span>];<br>                    r4 = A[i + <span class="hljs-number">7</span>][k];<br>                    r8 = A[i + <span class="hljs-number">7</span>][k + <span class="hljs-number">4</span>];<br><br>                    tran = B[k][i + <span class="hljs-number">4</span>];<br>                    B[k][i + <span class="hljs-number">4</span>] = r1;<br>                    r1 = tran;<br>                    tran = B[k][i + <span class="hljs-number">5</span>];<br>                    B[k][i + <span class="hljs-number">5</span>] = r2;<br>                    r2 = tran;<br>                    tran = B[k][i + <span class="hljs-number">6</span>];<br>                    B[k][i + <span class="hljs-number">6</span>] = r3;<br>                    r3 = tran;<br>                    tran = B[k][i + <span class="hljs-number">7</span>];<br>                    B[k][i + <span class="hljs-number">7</span>] = r4;<br>                    r4 = tran;<br><br>                    B[k + <span class="hljs-number">4</span>][i] = r1;<br>                    B[k + <span class="hljs-number">4</span>][i + <span class="hljs-number">4</span>] = r5;<br>                    B[k + <span class="hljs-number">4</span>][i + <span class="hljs-number">1</span>] = r2;<br>                    B[k + <span class="hljs-number">4</span>][i + <span class="hljs-number">5</span>] = r6;<br>                    B[k + <span class="hljs-number">4</span>][i + <span class="hljs-number">2</span>] = r3;<br>                    B[k + <span class="hljs-number">4</span>][i + <span class="hljs-number">6</span>] = r7;<br>                    B[k + <span class="hljs-number">4</span>][i + <span class="hljs-number">3</span>] = r4;<br>                    B[k + <span class="hljs-number">4</span>][i + <span class="hljs-number">7</span>] = r8;<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">else</span>&#123;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>;i &lt; N;i += <span class="hljs-number">8</span>)&#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>;j &lt; M;j++)&#123;<br>                <span class="hljs-keyword">if</span>(i + <span class="hljs-number">8</span> &lt;= N &amp;&amp; j &lt; M)&#123;<br>                    r1 = A[i][j];<br>                    r2 = A[i + <span class="hljs-number">1</span>][j];<br>                    r3 = A[i + <span class="hljs-number">2</span>][j];<br>                    r4 = A[i + <span class="hljs-number">3</span>][j];<br>                    r5 = A[i + <span class="hljs-number">4</span>][j];<br>                    r6 = A[i + <span class="hljs-number">5</span>][j];<br>                    r7 = A[i + <span class="hljs-number">6</span>][j];<br>                    r8 = A[i + <span class="hljs-number">7</span>][j];<br>                    <br>                    B[j][i] = r1;<br>                    B[j][i + <span class="hljs-number">1</span>] = r2;<br>                    B[j][i + <span class="hljs-number">2</span>] = r3;<br>                    B[j][i + <span class="hljs-number">3</span>] = r4;<br>                    B[j][i + <span class="hljs-number">4</span>] = r5;<br>                    B[j][i + <span class="hljs-number">5</span>] = r6;<br>                    B[j][i + <span class="hljs-number">6</span>] = r7;<br>                    B[j][i + <span class="hljs-number">7</span>] = r8;<br>                &#125;<br>                <span class="hljs-keyword">else</span>&#123;<br>                    <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> k = i; k &lt; i + <span class="hljs-number">8</span> &amp;&amp; k &lt; N; k++)&#123;<br>                        B[j][k] = A[k][j];<br>                    &#125;<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * You can define additional transpose functions below. We&#x27;ve defined</span><br><span class="hljs-comment"> * a simple one below to help you get started. </span><br><span class="hljs-comment"> */</span> <br><br><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * trans - A simple baseline transpose function, not optimized for the cache.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">char</span> trans_desc[] = <span class="hljs-string">&quot;Simple row-wise scan transpose&quot;</span>;<br><span class="hljs-type">void</span> <span class="hljs-title function_">trans</span><span class="hljs-params">(<span class="hljs-type">int</span> M, <span class="hljs-type">int</span> N, <span class="hljs-type">int</span> A[N][M], <span class="hljs-type">int</span> B[M][N])</span><br>&#123;<br>    <span class="hljs-type">int</span> i, j, tmp;<br><br>    <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; N; i++) &#123;<br>        <span class="hljs-keyword">for</span> (j = <span class="hljs-number">0</span>; j &lt; M; j++) &#123;<br>            tmp = A[i][j];<br>            B[j][i] = tmp;<br>        &#125;<br>    &#125;    <br><br>&#125;<br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * registerFunctions - This function registers your transpose</span><br><span class="hljs-comment"> *     functions with the driver.  At runtime, the driver will</span><br><span class="hljs-comment"> *     evaluate each of the registered functions and summarize their</span><br><span class="hljs-comment"> *     performance. This is a handy way to experiment with different</span><br><span class="hljs-comment"> *     transpose strategies.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">registerFunctions</span><span class="hljs-params">()</span><br>&#123;<br>    <span class="hljs-comment">/* Register your solution function */</span><br>    registerTransFunction(transpose_submit, transpose_submit_desc); <br><br>    <span class="hljs-comment">/* Register any additional transpose functions */</span><br>    registerTransFunction(trans, trans_desc); <br><br>&#125;<br><br><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * is_transpose - This helper function checks if B is the transpose of</span><br><span class="hljs-comment"> *     A. You can check the correctness of your transpose by calling</span><br><span class="hljs-comment"> *     it before returning from the transpose function.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">is_transpose</span><span class="hljs-params">(<span class="hljs-type">int</span> M, <span class="hljs-type">int</span> N, <span class="hljs-type">int</span> A[N][M], <span class="hljs-type">int</span> B[M][N])</span><br>&#123;<br>    <span class="hljs-type">int</span> i, j;<br><br>    <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; N; i++) &#123;<br>        <span class="hljs-keyword">for</span> (j = <span class="hljs-number">0</span>; j &lt; M; ++j) &#123;<br>            <span class="hljs-keyword">if</span> (A[i][j] != B[j][i]) &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>            &#125;<br>        &#125;<br>    &#125;<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>&#125;<br><br><br><br></code></pre></td></tr></table></figure><h2 id="总结">总结</h2><p>本次实验通过对Cache的模拟以及针对Cache命中率进行优化的编程让我对Cache的原理有了更深层次的理解，也让我发现了在第一次学习Cache概念时有一定的误解(例如在何时进行替换以及怎样替换)，而矩阵转置的部分也十分考验思维，也花费了许久的时间，总体来说本次实验在概念上和思维上都得到了极大的收获与锻炼</p>]]></content>
    
    
    <categories>
      
      <category>计算机基础</category>
      
      <category>CSAPP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CSAPP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CS229 ps2-solution</title>
    <link href="/2022/07/18/machine%20learning/CS229/cs229%20ps2/"/>
    <url>/2022/07/18/machine%20learning/CS229/cs229%20ps2/</url>
    
    <content type="html"><![CDATA[<h2 id="problem-1">Problem 1</h2><h3 id="sub-problem-a">Sub Problem (a)</h3><p>Converges in dataset A , NOT converge in dataset B.</p><h3 id="sub-problem-b">Sub Problem (b)</h3><p>Dataset A is NOT linear separable, but dataset B is linear separable.It's shown by the output graph by the program.</p><p><strong>Why does NOT linear regression converge on a linear separabledataset?</strong></p><p>As the dataset is linear separable, we can assume that the separateline is <span class="math inline">\(x=0\)</span> , otherwise we canrotate the space to make the separate line to be <span class="math inline">\(x = 0\)</span></p><p>Our loss function is : <span class="math display">\[\ell(\theta) = \sum_{i = 1}^{m}y^{(i)}log(g(\theta^Tx)) + (1 -y^{(i)})log(1 - g(\theta^Tx))\]</span> In this specific separable case, we can divide the data intoonly two kinds of types:</p><ul><li><span class="math inline">\(y^{(i)} = 1\)</span> and <span class="math inline">\(x^{(i)} &gt; 0\)</span></li><li><span class="math inline">\(y^{(i)} = 0\)</span> and <span class="math inline">\(x^{(i)} &lt; 0\)</span></li></ul><p>For the first type, it leads <span class="math inline">\(log(g(\theta^Tx))\)</span> to zero (because thederivative is larger than zero);</p><p>For the second type, it leads <span class="math inline">\(log(1 -g(\theta^Tx))\)</span> to zero(because the derivative is less thanzero).</p><p>So in both cases, the loss function is NOT converging.</p><p>Conversely, when the dataset is not linear separable, we got fourdifferent types:</p><ul><li><span class="math inline">\(y^{(i)} = 1\)</span> and <span class="math inline">\(x^{(i)} &gt; 0\)</span></li><li><span class="math inline">\(y^{(i)} = 1\)</span> and <span class="math inline">\(x^{(i)} &lt; 0\)</span></li><li><span class="math inline">\(y^{(i)} = 0\)</span> and <span class="math inline">\(x^{(i)} &gt; 0\)</span></li><li><span class="math inline">\(y^{(i)} = 0\)</span> and <span class="math inline">\(x^{(i)} &lt; 0\)</span></li></ul><p>So its derivative will keep changing and the loss function must get aminimum point.</p><h3 id="sub-problem-c">Sub Problem (c)</h3><h4 id="i">i</h4><p><strong>Do NOT work.</strong> Because changing the learning ratedoesn't change the fact that the the logistic regression doesn'tconverges on a linear separable dataset.</p><h4 id="ii">ii</h4><p>Yes, because as the time goes, the error of <span class="math inline">\(\theta\)</span> will be limited as we cantolerance.</p><h4 id="iii">iii</h4><p><strong>Do NOT work.</strong> Linear scaling is the same way withmultiple a real number to <span class="math inline">\(\theta\)</span>,doesn't change the properties of the model and the dataset.</p><h4 id="iv">iv</h4><p>When adding a <span class="math inline">\(L_2\)</span>regularization, the derivative of loss function becomes: (Set the constof <span class="math inline">\(L_2\)</span> regularization is 1/2) <span class="math display">\[\frac{\partial J}{\partial \theta} = x_j^{(i)}(y^{(i)} - g(\theta^Tx)) +\theta_j\]</span> So the update of <span class="math inline">\(\theta_j\)</span>is: <span class="math display">\[\theta_j = (1 - \alpha)\theta_j - \alpha x_j^{(i)}(y^{(i)} -g(\theta^Tx))\]</span> It can prevent the arbitrary scaling. So it does work.</p><p><strong>We can adjust the weight of the regularization term topromise the scaling is not arbitrary.</strong></p><h4 id="v">v</h4><p>Yes, adding noise term could make the model converges. Just have tomake sure to keep the <span class="math inline">\(\theta\)</span> notarbitrary scaling.</p><h3 id="sub-problem-d">Sub Problem (d)</h3><h2 id="problem-2">Problem 2</h2><p>This problem tends to make us understand more that the output oflogistic regression is the empirical probability of the training set(<strong>NOT only because the sigmoid function output a value between 0and 1</strong>)</p><h3 id="sub-problem-a-1">Sub Problem (a)</h3><p>As the problem says, the parameter <span class="math inline">\(\theta\)</span> is maximum likelihood parameter,so we calculate <span class="math inline">\(\theta\)</span> ： <span class="math display">\[\begin{align*}\ell(\theta) &amp;= \sum_{i = 1}^{m}y^{(i)}log(h(x^{(i)})) + (1 -y^{(i)})log(1 - h(x^{(i)})) \\&amp;= \sum_{i = 1}^{m}-y^{(i)}log(1 + e^{-\theta^Tx}) + (1 -y^{(i)})log(\frac{e^{-\theta^Tx}}{1 + e^{-\theta^Tx}}) \\&amp;= \sum_{i = 1}^{m}-y^{(i)}log(1 + e^{-\theta^Tx}) + (1 -y^{(i)})(-\theta^Tx) - (1 - y^{(i)})log(1 + e^{-\theta^Tx})\\&amp;= \sum_{i = 1}^{m}(1 - y^{(i)})(-\theta^Tx) + log(1 +e^{-\theta^Tx}) \\\frac{\partial \ell}{\partial \theta_j} &amp;= \sum_{i = 1}^{m}(1 -y^{(i)})(-x_{j}^{(i)}) + (1 - g(\theta^Tx))x_{j}^{(i)}\\&amp;= \sum_{i = 1}^{m}x_{j}^{(i)}(y^{(i)} - g(\theta^Tx))\end{align*}\]</span> Let j = 0 (because the problem sets <span class="math inline">\(x_{0}^{(i)}=1\)</span>), then we got: <span class="math display">\[\sum_{i = 1}^{m}(y^{(i)} - g(\theta^Tx)) = 0\]</span> So we proof the problem.</p><h3 id="sub-problem-b-1">Sub Problem (b)</h3><p>The conclusion is <strong>NOT TRUE</strong>.</p><p>We set (a,b) equals to (0.5,1) , so we got : <span class="math display">\[\sum_{i \in I_{a,b}}I(y^{(i)} = 1) = |\{i \in I_{a,b}\}|\]</span> But <span class="math display">\[\sum_{i \in I_{a,b}}P(y = 1|x;\theta) &lt; |\{i \in I_{a,b}\}|\]</span> So the formula can't set up.</p><h3 id="sub-problem-c-1">Sub Problem (c)</h3><p>After adding <span class="math inline">\(L_2\)</span> regularization,calculating the maximum likelihood,we got: <span class="math display">\[\sum_{i = 1}^{m}(g(\theta^Tx) - y^{(i)})x_{j}^{(i)} + \lambda\theta = 0\]</span> that means: <span class="math display">\[\sum_{i = 1}^{m}P(y = 1|x;\theta) + \lambda\theta = \sum_{i =1}^{m}I\{y^{(i)} = 1\}\]</span> So the formula can't set up.</p><h2 id="problem-3">Problem 3</h2><p>This problem lets us explore the connection between MAP(maximum aposteriori estimation) and MLE(maximum likelihood estimation), and howto choose prior distribution over <span class="math inline">\(\theta\)</span>.</p><h3 id="sub-problem-a-2">Sub Problem (a)</h3><p><span class="math display">\[\begin{align*}\theta_{MAP} &amp;= arg\,max_\theta\; p(\theta|x,y)\\p(\theta|x,y) &amp;= \frac{p(\theta,x,y)}{p(x,y)} =\frac{p(y|x,\theta)p(\theta,x)}{p(x,y)} =\frac{p(y|x,\theta)p(\theta|x)p(x)}{p(x,y)} \\&amp;= p(y|x,\theta)p(\theta|x) = p(y|x,\theta)p(\theta)\end{align*}\]</span></p><p>So we finish the prove.</p><h3 id="sub-problem-b-2">Sub Problem (b)</h3><p>From sub problem (a), we know: <span class="math display">\[\theta_{MAP} = arg\,max_{\theta}p(y|x,\theta)p(\theta)\]</span> So,it is the same with: <span class="math display">\[\theta_{MAP} = arg\,max_{\theta}\;(log\;p(y|x,\theta) + log\;p(\theta))\]</span> Because <span class="math inline">\(\theta\)</span> ~ <span class="math inline">\(\mathcal{N}(0,\eta^2I)\)</span>, so we have: <span class="math display">\[\begin{align*}p(\theta) &amp;=\frac{1}{(2\pi)^\frac{n}{2}\eta^n}exp\{-\frac{||\theta||^2}{2\eta^2}\}\\log\,p(\theta) &amp;= -\frac{n}{2}log\,(2\pi) - nlog(\eta) -\frac{||\theta||^2}{2\eta^2}\end{align*}\]</span> So, we have: <span class="math display">\[\begin{align*}\theta_{MAP}  &amp;= arg\,max_{\theta}\;(\,log\,p(y|x,\theta)\,-\frac{1}{2\eta^2}||\theta||^2) \\&amp;= arg\,min_{\theta}\;(-log\,p(y|x,\theta) +\frac{1}{2\eta^2}||\theta||^2)\end{align*}\]</span> We finish the prove.</p><p>And <span class="math inline">\(\lambda =\frac{1}{2\eta^2}\)</span></p><h3 id="sub-problem-c-2">Sub Problem (c)</h3><p><span class="math display">\[p(y|X;\theta) =\frac{1}{(2\pi)^{\frac{m}{2}}\sigma^m}exp\{-\frac{1}{2\sigma^2}||X\theta- y ||^2\}\]</span></p><p>The same with sub problem (b), we have: <span class="math display">\[\begin{align*}log\,p(y|X,\theta) &amp;= -\frac{m}{2}log(2\pi) - mlog\sigma -\frac{1}{2\sigma^2}||X\theta - y||^2\\\theta_{MAP} &amp;= arg\,min_{\theta}(-log\,p(y|x,\theta) +\frac{1}{2\eta^2}||\theta||^2) \\&amp;= arg\,min_{\theta}(\frac{1}{2\sigma^2}||X\theta - y||^2 +\frac{1}{2\eta^2}||\theta||^2)\\J &amp;= arg\,min_{\theta}(\frac{1}{2\sigma^2}||X\theta - y||^2 +\frac{1}{2\eta^2}||\theta||^2)\end{align*}\]</span> Let derivative be zero: <span class="math display">\[\frac{\partial J}{\partial \theta} = \frac{1}{\sigma^2}(X^TX\theta -X^Ty) + \frac{1}{\eta^2}\theta = 0\]</span> So: <span class="math display">\[\theta_{MAP} = arg\,min_{\theta}J = (X^TX +\frac{\sigma^2}{\eta^2}I)^{-1}X^Ty\]</span></p><h3 id="sub-problem-d-1">Sub Problem (d)</h3><p>The derivation is similar with the question before, just change thedistribution of <span class="math inline">\(\theta\)</span> : <span class="math display">\[\begin{align*}p(\theta) &amp;= \frac{1}{(2b)^n}exp\{-\frac{1}{b}||\theta||_1\} \\\theta_{MAP} &amp;= arg\,min\,\frac{1}{2\sigma^2}||X\theta - y||^2 +\frac{1}{b}||\theta||_1 \\J(\theta) &amp;= ||X\theta-y||^2 + \gamma||\theta||_1\end{align*}\]</span> So, we got: <span class="math display">\[\gamma = \frac{2\sigma^2}{b}\]</span></p><h2 id="problem-4">Problem 4</h2><h3 id="sub-problem-a-3">Sub Problem (a)</h3><p><span class="math inline">\(K(x,z) = K_1(x,z) + K_2(x,z)\)</span><strong>is a kernel.</strong></p><p>Because the sum of two positive semi-define matrices is still apositive semi-define matrix. It can be shown by the definition of thepositive semi-define matrix</p><h3 id="sub-problem-b-3">Sub Problem (b)</h3><p><span class="math inline">\(K(x,z) = K_1(x,z) - K_2(x,z)\)</span><strong>is NOT a kernel.</strong></p><p>Consider this example: <span class="math display">\[\begin{bmatrix}I_r &amp; O \\O &amp; O\end{bmatrix}-\begin{bmatrix}I_{r + 1} &amp; O \\O &amp; O\end{bmatrix}=\begin{bmatrix}-I_1 &amp; O \\O &amp; O\end{bmatrix}\]</span> the difference of these two positive semi-define matrices is anegative semi-define matrices, from the Mercer's theory we know, itcan't be a kernel.</p><h3 id="sub-problem-c-3">Sub Problem (c)</h3><p><span class="math inline">\(K(x,z) = aK_1(x,z)\)</span> <strong>is akernel.</strong></p><p>Obviously, a positive semi-define matrix multiply a positivenumber(it's the same with multiply a identify matrix times a constant)is still a positive semi-define matrix. Because it has the same standardmatrix with the original matrix.</p><h3 id="sub-problem-d-2">Sub Problem (d)</h3><p><span class="math inline">\(K(x,z) = -aK_1(x,z)\)</span> <strong>isNOT a kernel.</strong></p><p>Its standard matrix is the opposite with the original matrix'sstandard matrix.</p><h3 id="sub-problem-e">Sub Problem (e)</h3><p><span class="math inline">\(K(x,z) = K_1(x,z)K_2(x,z)\)</span><strong>is a kernel.</strong></p><p>the <span class="math inline">\(K_1(x,z)\)</span> and <span class="math inline">\(K_2(x,z)\)</span> return none negative values, sothe <span class="math inline">\(K(x,z)\)</span> returns a none negativevalue.</p><h3 id="sub-problem-f">Sub Problem (f)</h3><p>Calculate the new kernel can prove: <span class="math display">\[\begin{align*}z^TKz &amp;= \sum_i\sum_jz_iK_{ij}z_j \\&amp;= \sum_i\sum_jz_if(x^{(i)})f(x^{(j)})z_j  \\  &amp;= \sum_i(z_if(x^{(i)}))^2\\  &amp;\geq 0\end{align*}\]</span></p><h3 id="sub-problem-g">Sub Problem (g)</h3><p><span class="math inline">\(K(x,z) = K_3(\phi(x),\phi(z))\)</span><strong>is a kernel.</strong></p><p>No matter the vector mapped by <span class="math inline">\(\phi\)</span> is, the Gram Matrix of <span class="math inline">\(K_3\)</span> is a positive semi-define matrix. Soit is a kernel.</p><h3 id="sub-problem-h">Sub Problem (h)</h3><p><span class="math inline">\(K(x,z) = p(K_1(x,z))\)</span> <strong>isa kernel.</strong></p><p>Because <span class="math inline">\(K_1\)</span> is a kernel and themapping function <span class="math inline">\(p\)</span> is a positivecoefficient, so the value of <span class="math inline">\(K_1(x,z)\)</span> is none negative, so the valueof <span class="math inline">\(K(x,z)\)</span> is none negative.</p><h2 id="problem-5">Problem 5</h2><h3 id="sub-problem-a-4">Sub Problem (a)</h3><h4 id="i-1">i</h4><p>Observing the <span class="math inline">\(h_{\theta}\)</span> , weknow that every update of <span class="math inline">\(\theta\)</span> isa linear combination of <span class="math inline">\(\phi(x^{(i)})\)</span>, so we have bunch of realparameters <span class="math inline">\(\beta\)</span> to represent:<span class="math inline">\(\theta = \sum_{i =1}^{n}\beta_i\phi(x^{(i)})\)</span></p><h4 id="ii-1">ii</h4><p>From the question above, we know that every update makes <span class="math inline">\(\theta\)</span> a combination of <span class="math inline">\(\phi(x^{(i)})\)</span>, so when predicting thenext data point, the computation becomes <span class="math display">\[\begin{align*}g({\theta^{(i)}}^T\phi(x^{(i + 1)})) &amp;= g((\sum_{k =1}^i\beta_k\phi(x^{(k)}))^T\phi(x^{(i + 1)})) \\&amp;= \sum_{k = 1}^i\beta_k(\phi(x^{(k)})\phi(x^{(i + 1)})) \\&amp;= \sum_{k = 1}^i\beta_kK(x^{(k)},x^{(i +1)})\end{align*}\]</span> So, we can use the kernel function to predict the unknownpoint in the data set.</p><h4 id="iii-1">iii</h4><p>We can update <span class="math inline">\(\beta\)</span> by using thesame way as updating <span class="math inline">\(\theta\)</span>,: <span class="math display">\[\beta_i = \alpha(y^{(i)} - g({\theta^{(i)}}^T\phi(x^{(i)})))\]</span> As i loops.</p><h3 id="sub-problem-b-4">Sub Problem (b)</h3><figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> math<br><br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><br><span class="hljs-keyword">import</span> util<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">initial_state</span>():<br>    <span class="hljs-string">&quot;&quot;&quot;Return the initial state for the perceptron.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    This function computes and then returns the initial state of the perceptron.</span><br><span class="hljs-string">    Feel free to use any data type (dicts, lists, tuples, or custom classes) to</span><br><span class="hljs-string">    contain the state of the perceptron.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-comment"># *** START CODE HERE ***</span><br>    <span class="hljs-keyword">return</span> []<br>    <span class="hljs-comment"># *** END CODE HERE ***</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">state, kernel, x_i</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Peform a prediction on a given instance x_i given the current state</span><br><span class="hljs-string">    and the kernel.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        state: The state returned from initial_state()</span><br><span class="hljs-string">        kernel: A binary function that takes two vectors as input and returns</span><br><span class="hljs-string">            the result of a kernel</span><br><span class="hljs-string">        x_i: A vector containing the features for a single instance</span><br><span class="hljs-string">    </span><br><span class="hljs-string">    Returns:</span><br><span class="hljs-string">        Returns the prediction (i.e 0 or 1)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># *** START CODE HERE ***</span><br>    <span class="hljs-keyword">if</span> <span class="hljs-built_in">sum</span>(beta * kernel(x,x_i) <span class="hljs-keyword">for</span> beta,x <span class="hljs-keyword">in</span> state) &lt; <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <span class="hljs-comment"># *** END CODE HERE ***</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">update_state</span>(<span class="hljs-params">state, kernel, learning_rate, x_i, y_i</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Updates the state of the perceptron.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        state: The state returned from initial_state()</span><br><span class="hljs-string">        kernel: A binary function that takes two vectors as input and returns the result of a kernel</span><br><span class="hljs-string">        learning_rate: The learning rate for the update</span><br><span class="hljs-string">        x_i: A vector containing the features for a single instance</span><br><span class="hljs-string">        y_i: A 0 or 1 indicating the label for a single instance</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># *** START CODE HERE ***</span><br>    beta_i = learning_rate * (y_i - sign(<span class="hljs-built_in">sum</span>(beta * kernel(x,x_i) <span class="hljs-keyword">for</span> beta,x <span class="hljs-keyword">in</span> state)))<br>    state.append((beta_i,x_i))<br>    <span class="hljs-comment"># *** END CODE HERE ***</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">sign</span>(<span class="hljs-params">a</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Gets the sign of a scalar input.&quot;&quot;&quot;</span><br>    <span class="hljs-keyword">if</span> a &gt;= <span class="hljs-number">0</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span><br>    <span class="hljs-keyword">else</span>:<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">0</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">dot_kernel</span>(<span class="hljs-params">a, b</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;An implementation of a dot product kernel.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        a: A vector</span><br><span class="hljs-string">        b: A vector</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-keyword">return</span> np.dot(a, b)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">rbf_kernel</span>(<span class="hljs-params">a, b, sigma=<span class="hljs-number">1</span></span>):<br>    <span class="hljs-string">&quot;&quot;&quot;An implementation of the radial basis function kernel.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        a: A vector</span><br><span class="hljs-string">        b: A vector</span><br><span class="hljs-string">        sigma: The radius of the kernel</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    distance = (a - b).dot(a - b)<br>    scaled_distance = -distance / (<span class="hljs-number">2</span> * (sigma) ** <span class="hljs-number">2</span>)<br>    <span class="hljs-keyword">return</span> math.exp(scaled_distance)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">train_perceptron</span>(<span class="hljs-params">kernel_name, kernel, learning_rate</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Train a perceptron with the given kernel.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    This function trains a perceptron with a given kernel and then</span><br><span class="hljs-string">    uses that perceptron to make predictions.</span><br><span class="hljs-string">    The output predictions are saved to src/output/p05_&#123;kernel_name&#125;_predictions.txt.</span><br><span class="hljs-string">    The output plots are saved to src/output_&#123;kernel_name&#125;_output.pdf.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        kernel_name: The name of the kernel.</span><br><span class="hljs-string">        kernel: The kernel function.</span><br><span class="hljs-string">        learning_rate: The learning rate for training.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    train_x, train_y = util.load_csv(<span class="hljs-string">&#x27;../data/ds5_train.csv&#x27;</span>)<br><br>    state = initial_state()<br><br>    <span class="hljs-keyword">for</span> x_i, y_i <span class="hljs-keyword">in</span> <span class="hljs-built_in">zip</span>(train_x, train_y):<br>        update_state(state, kernel, learning_rate, x_i, y_i)<br><br>    test_x, test_y = util.load_csv(<span class="hljs-string">&#x27;../data/ds5_train.csv&#x27;</span>)<br><br>    plt.figure(figsize=(<span class="hljs-number">12</span>, <span class="hljs-number">8</span>))<br>    util.plot_contour(<span class="hljs-keyword">lambda</span> a: predict(state, kernel, a))<br>    util.plot_points(test_x, test_y)<br>    plt.savefig(<span class="hljs-string">&#x27;./output/p05_&#123;&#125;_output.pdf&#x27;</span>.<span class="hljs-built_in">format</span>(kernel_name))<br><br>    predict_y = [predict(state, kernel, test_x[i, :]) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(test_y.shape[<span class="hljs-number">0</span>])]<br><br>    np.savetxt(<span class="hljs-string">&#x27;./output/p05_&#123;&#125;_predictions&#x27;</span>.<span class="hljs-built_in">format</span>(kernel_name), predict_y)<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>():<br>    train_perceptron(<span class="hljs-string">&#x27;dot&#x27;</span>, dot_kernel, <span class="hljs-number">0.5</span>)<br>    train_perceptron(<span class="hljs-string">&#x27;rbf&#x27;</span>, rbf_kernel, <span class="hljs-number">0.5</span>)<br><br><br><span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&quot;__main__&quot;</span>:<br>    main()<br><br></code></pre></td></tr></table></figure><h3 id="sub-problem-c-4">Sub Problem (c)</h3><p>Dot kernel performance badly, because it's mapping <span class="math inline">\(\phi(x) = x\)</span>, doesn't change the fact thatthe dataset is linear separable.</p>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>CS229</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS229</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>CS229 ps1-solution</title>
    <link href="/2022/07/16/machine%20learning/CS229/cs229%20ps1/"/>
    <url>/2022/07/16/machine%20learning/CS229/cs229%20ps1/</url>
    
    <content type="html"><![CDATA[<h2 id="problem-1">Problem 1</h2><h3 id="sub-problem-a">Sub Problem (a)</h3><p>For the loss function <span class="math inline">\(J(\theta)\)</span>，the element of the hessianmatrix is： <span class="math display">\[H_{ij} = \frac{ \partial^{2} J(\theta)}{\partial \theta_i\partial\theta_j}\]</span> So for the specific loss function <span class="math inline">\(J(\theta)\)</span> <span class="math display">\[J(\theta) = -\frac{1}{m}\sum_{i =1}^{m}y^{(i)}log(h_{\theta}(x^{(i)}))\, + \,  (1 - y^{(i)})log(1 -h_{\theta}(x^{(i)}))\]</span> We got: <span class="math display">\[\frac{\partial {J(\theta)}}{\partial \theta_i} = -\frac{1}{m}\sum_{k =1}^{m}(x_{i}^{(k)}y^{(k)} - x_{i}^{(k)}g(\theta^{T}x))\]</span> So the second derivative is: <span class="math display">\[\frac{\partial ^{2}J(\theta)}{\partial {\theta_i}{\theta_j}} = \sum_{k =1}^{m}\frac{x_{i}^{(k)}x_{j}^{(k)}}{m}g(\theta^{T}x)(1 - g(\theta^{T}x))\]</span> We want to prove <span class="math inline">\(z^{T}Hz \geq0\)</span>： <span class="math display">\[z^THz = \sum_{k = 1}^{m}\sum_{i = 1}^{m}\sum_{j =1}^{m}\frac{z_{i}x_{i}^{(k)}x_{j}^{(k)}z_{j}}{m}g(\theta^{T}x)(1 -g(\theta^{T}x))\]</span> Consider the sum, we got: <span class="math display">\[\sum_{i = 1}^{m}\sum_{j = 1}^{m}z_{i}x_{i}x_{j}z_{j} = (xz)^{T}(xz) \geq0\]</span> the resident part <span class="math inline">\(0 &lt;g(\theta^Tx) &lt; 1\)</span>，so we finish the proof.</p><h3 id="sub-problem-b">Sub Problem (b)</h3><figure class="highlight python"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></div></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> util<br><br><span class="hljs-keyword">from</span> linear_model <span class="hljs-keyword">import</span> LinearModel<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">train_path, eval_path, pred_path</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Problem 1(b): Logistic regression with Newton&#x27;s Method.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        train_path: Path to CSV file containing dataset for training.</span><br><span class="hljs-string">        eval_path: Path to CSV file containing dataset for evaluation.</span><br><span class="hljs-string">        pred_path: Path to save predictions.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    x_train, y_train = util.load_dataset(train_path, add_intercept=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># *** START CODE HERE ***</span><br>    model = LogisticRegression(eps=<span class="hljs-number">1e-5</span>)<br>    model.fit(x_train, y_train)<br>    util.plot(x_train, y_train,model.theta,<span class="hljs-string">&#x27;output/p01b.png&#x27;</span>)<br>    x_out,y_out = util.load_dataset(eval_path, add_intercept=<span class="hljs-literal">True</span>)<br>    prediction = model.predict(x_eval)<br>    np.savetxt(pred_path,prediction &gt; <span class="hljs-number">0.5</span>, fmt=<span class="hljs-string">&#x27;%d&#x27;</span>)<br>    <span class="hljs-comment"># *** END CODE HERE ***</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LogisticRegression</span>(<span class="hljs-title class_ inherited__">LinearModel</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Logistic regression with Newton&#x27;s Method as the solver.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Example usage:</span><br><span class="hljs-string">        &gt; clf = LogisticRegression()</span><br><span class="hljs-string">        &gt; clf.fit(x_train, y_train)</span><br><span class="hljs-string">        &gt; clf.predict(x_eval)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, x, y</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Run Newton&#x27;s Method to minimize J(theta) for logistic regression.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x: Training example inputs. Shape (m, n).</span><br><span class="hljs-string">            y: Training example labels. Shape (m,).</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># *** START CODE HERE ***</span><br>        m,n = x.shape<br>        self.theta = np.zeros(n)<br>        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>            old_theta = np.copy(self.theta)<br>            hx = <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-x.dot(self.theta)))<br>            hessian = (x.T * hx * (<span class="hljs-number">1</span> - hx)).dot(x) / m<br>            gradient_J_theta = x.T.dot(hx - y) / m<br>            self.theta = self.theta - np.linalg.inv(hessian).dot(gradient_J_theta)<br>            <span class="hljs-keyword">if</span> np.linalg.norm(self.theta - old_theta,<span class="hljs-built_in">ord</span>=<span class="hljs-number">1</span>) &lt; self.eps:<br>                <span class="hljs-keyword">break</span><br>        <span class="hljs-comment"># *** END CODE HERE ***</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Make a prediction given new inputs x.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x: Inputs of shape (m, n).</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            Outputs of shape (m,).</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># *** START CODE HERE ***</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / <span class="hljs-number">1</span> + np.exp(-x.dot(self.theta))<br>        <span class="hljs-comment"># *** END CODE HERE ***</span><br><br></code></pre></td></tr></table></figure><p>Use Newton's method to solve the problem.</p><h3 id="sub-problem-c">Sub Problem (c)</h3><p>First，by bayes formula： <span class="math display">\[p(y = 1 | x) = \frac{p(x|y = 1)p(y = 1)}{p(x|y = 1)p(y = 1) + p(x|y =0)p(y = 0)}\]</span> Bring in the possibility of the defination，we got： <span class="math display">\[p(y = 1|x) = \frac{1}{1 + \frac{1 - \phi}{\phi}exp\{\frac{1}{2}((x -\mu_0)^{T}\sum^{-1}(x - \mu_0) - (x - \mu_1)^{T}\sum^{-1}(x - \mu_1))\}}\]</span> Simplify the formula： <span class="math display">\[p(y = 1|x) = \frac{1}{1 + exp\{\sum^{-1}(\mu_0 - \mu_1)^Tx +\frac{1}{2}((\mu_0 + \mu_1)^T\sum^{-1}(\mu_1 - \mu_0)) - log(\frac{1 -\phi}{\phi})\}}\]</span> So，define the parameter like this： <span class="math display">\[\theta = (\mu_0 - \mu_1)(\sum)^{-1}\]</span> <strong>note that</strong> <span class="math inline">\(\sum^{-1}\)</span> <strong>is a symmetricmatrix</strong> <span class="math display">\[\theta_0 = \frac{1}{2}((\mu_0 + \mu_1)^T\sum^{-1}(\mu_1 - \mu_0)) -log(\frac{1 - \phi}{\phi})\]</span> So <span class="math inline">\(p(y = 1|x)\)</span> can berepresented by the formula as the question displays.</p><h3 id="sub-problem-d">Sub Problem (d)</h3><p><span class="math display">\[\ell(\phi,\mu_0,\mu_1,\sum) = log\prod_{i =1}^{m}p(x^{(i)},y^{(i)};\phi,\mu_0,\mu_1,\sum)\\= log\prod_{i =1}^{m}p(x^{(i)}|y^{(i)};\mu_0,\mu_1,\sum)p(y^{(i)};\phi) \\= \sum_{i = 1}^{m}(log(p(x^{(i)}|y^{(i)};\mu_0,\mu_1,\sum)) +log(p(y^{(i)};\phi)))\]</span></p><p>We calculate the <span class="math inline">\(\phi\)</span> first：<span class="math display">\[\frac{\partial  \ell}{\partial  \phi} = \sum_{i =1}^{m}y^{(i)}\frac{\partial  log\phi}{\partial \phi} + (1 -y^{(i)})\frac{\partial  log(1 - \phi)}{\partial  \phi} \\= \sum_{i = 1}^{m}\frac{y^{(i)}}{\phi} - \frac{y - \phi}{1 - \phi}\\= \frac{(\sum_{i = 1}^{m}y^{(i)}) - m\phi}{\phi(1 - \phi)} = 0\]</span> So make the derivative maximum，we have to let： <span class="math display">\[\phi = \frac{\sum_{i = 1}^{m}I(y^{(i)} = 1)}{m}\]</span> Then we calculate <span class="math inline">\(\mu_0,\mu_1,\sum\)</span>： <span class="math display">\[\frac{\partial  \ell}{\partial  \mu_0} =\frac{\partial  \ell}{\partial  \mu}\frac{\partial  \mu}{\partial  \mu_0}\\= -\frac{1}{2\sqrt{2\pi}}\sum_{i = 1}^{m}\frac{\partial  (x^{(i)} -\mu)^T\sum^{-1}(x^{(i)} -\mu)}{\partial  \mu}\frac{\partial  \mu}{\partial  \mu_0}\\= -\frac{\sum^{-1}}{\sqrt{2\pi}}\sum_{i = 1}^{m} I(y^{(i)} = 0)(x^{(i)}- \mu_0) \\= -\frac{1}{\sqrt{2\pi}}\sum_{i = 1}^{m}I(y^{(i)} = 0)(x^{(i)} - \mu_0)= 0\]</span> So，we can calculate <span class="math inline">\(\mu_0\)</span>： <span class="math display">\[\mu_0 = \frac{\sum_{i = 1}^{m}I(y^{(i)} = 0)x^{(i)}}{\sum_{i =1}^{m}I(y^{(i)} = 0)}\]</span> For the same derivation，we know that <span class="math inline">\(\mu_1\)</span> is： <span class="math display">\[\mu_1 = \frac{\sum_{i = 1}^{m}I(y^{(i)} = 1)x^{(i)}}{\sum_{i =1}^{m}I(y^{(i)} = 1)}\]</span> At last，we calculate the covariance matrix <span class="math inline">\(\sum^{-1}\)</span> <span class="math display">\[\frac{\partial  \ell}{\partial  \sum} = \frac{m}{2}(\sum)^{-1} +\frac{1}{2}(\sum)^{-1}(\sum_{i = 1}^{m}(x - \mu_{y^{(i)}})(x -\mu_{y^{(i)}})^T)(\sum)^{-1} = 0\]</span> So the covariance matrix is： <span class="math display">\[\sum = \frac{\sum_{i = 1}^{m}(x - \mu_{y^{(i)}})(x -\mu_{y^{(i)}})^T}{m}\]</span> Proof finished.</p><h3 id="sub-problem-e">Sub Problem (e)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> statistics <span class="hljs-keyword">import</span> covariance<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> util<br><br><span class="hljs-keyword">from</span> linear_model <span class="hljs-keyword">import</span> LinearModel<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">train_path, eval_path, pred_path</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Problem 1(e): Gaussian discriminant analysis (GDA)</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        train_path: Path to CSV file containing dataset for training.</span><br><span class="hljs-string">        eval_path: Path to CSV file containing dataset for evaluation.</span><br><span class="hljs-string">        pred_path: Path to save predictions.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># Load dataset</span><br>    x_train, y_train = util.load_dataset(train_path, add_intercept=<span class="hljs-literal">False</span>)<br><br>    <span class="hljs-comment"># *** START CODE HERE ***</span><br>    model = GDA()<br>    model.fit(x_train, y_train)<br>    util.plot(x_train, y_train,model.theta,<span class="hljs-string">&#x27;output/p01e.png&#x27;</span>)<br>    x_out,y_out = util.load_dataset(eval_path, add_intercept=<span class="hljs-literal">True</span>)<br>    prediction = model.predict(x_out)<br>    np.savetxt(pred_path,prediction &gt; <span class="hljs-number">0.5</span>, fmt=<span class="hljs-string">&#x27;%d&#x27;</span>)<br>    <span class="hljs-comment"># *** END CODE HERE ***</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">GDA</span>(<span class="hljs-title class_ inherited__">LinearModel</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Gaussian Discriminant Analysis.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Example usage:</span><br><span class="hljs-string">        &gt; clf = GDA()</span><br><span class="hljs-string">        &gt; clf.fit(x_train, y_train)</span><br><span class="hljs-string">        &gt; clf.predict(x_eval)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, x, y</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Fit a GDA model to training set given by x and y.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x: Training example inputs. Shape (m, n).</span><br><span class="hljs-string">            y: Training example labels. Shape (m,).</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            theta: GDA model parameters.</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># *** START CODE HERE ***</span><br>        m,n = x.shape<br>        phi = <span class="hljs-built_in">sum</span>(y == <span class="hljs-number">1</span>) / m<br>        u0 = np.<span class="hljs-built_in">sum</span>(x[y == <span class="hljs-number">0</span>],axis=<span class="hljs-number">0</span>) / (m - <span class="hljs-built_in">sum</span>(y == <span class="hljs-number">1</span>))<br>        u1 = np.<span class="hljs-built_in">sum</span>(x[y == <span class="hljs-number">1</span>],axis=<span class="hljs-number">0</span>) / <span class="hljs-built_in">sum</span>(y == <span class="hljs-number">1</span>)<br>        Covariance = ((x[y == <span class="hljs-number">0</span>] - u0).T.dot(x[y == <span class="hljs-number">0</span>] - u0) + (x[y == <span class="hljs-number">1</span>] - u1).T.dot(x[y == <span class="hljs-number">1</span>] - u1))<br>        inverse_covariance = np.linalg.inv(Covariance)<br>        self.theta = np.zeros(n + <span class="hljs-number">1</span>)<br>        self.theta[<span class="hljs-number">0</span>] = (u0 + u1).dot(inverse_covariance).dot(u0 - u1) * <span class="hljs-number">0.5</span><br>        self.theta[<span class="hljs-number">1</span>:] =  inverse_covariance.dot(u1 - u0)<br>        <span class="hljs-keyword">return</span> self.theta<br><br>        <span class="hljs-comment"># *** END CODE HERE ***</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Make a prediction given new inputs x.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x: Inputs of shape (m, n).</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            Outputs of shape (m,).</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># *** START CODE HERE ***</span><br>        <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> / (<span class="hljs-number">1</span> + np.exp(-x.dot(self.theta)))<br>        <span class="hljs-comment"># *** END CODE HERE</span><br><br></code></pre></td></tr></table></figure><p>Use GDA parameter analysis to write the fit function, and it is thesame with the linear analysis in sub problem (b) in main.</p><p><strong>Remember to give theta the value by rules from thenotes</strong></p><h3 id="sub-problem-f">Sub Problem (f)</h3><h3 id="sub-problem-g">Sub Problem (g)</h3><h3 id="sub-problem-h">Sub Problem (h)</h3><h2 id="problem-2">Problem 2</h2><h3 id="sub-problem-a-1">Sub Problem (a)</h3><p><span class="math display">\[p(y = 1,t = 1,x) = p(y = 1|t = 1,x)p(t = 1 | x)p(x)\\= p(t = 1|y = 1)p(y = 1|x)p(x)\]</span></p><p>From the known factors： <span class="math display">\[p(t = 1|y = 1) = 1\\p(y = 1|t = 1,x) = p(y = 1|t = 1)\]</span> So we can derivate： <span class="math display">\[\frac{p(t = 1|x)}{p(y = 1|x)} = \frac{p(t = 1|y = 1,x)}{p(y = 1|t =1,x)} = \frac{1}{p(y = 1 | t = 1)}\]</span> From the problem we know it is a constant.</p><h3 id="sub-problem-b-1">Sub Problem (b)</h3><p>From sub problem (a) we know： <span class="math display">\[h(x) \approx p(y = 1|x) \approx \alpha\]</span></p><h3 id="sub-problem-cde">Sub Problem (c,d,e)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> util<br><br><span class="hljs-keyword">from</span> p01b_logreg <span class="hljs-keyword">import</span> LogisticRegression<br><br><span class="hljs-comment"># Character to replace with sub-problem letter in plot_path/pred_path</span><br>WILDCARD = <span class="hljs-string">&#x27;X&#x27;</span><br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">train_path, valid_path, test_path, pred_path</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Problem 2: Logistic regression for incomplete, positive-only labels.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Run under the following conditions:</span><br><span class="hljs-string">        1. on y-labels,</span><br><span class="hljs-string">        2. on l-labels,</span><br><span class="hljs-string">        3. on l-labels with correction factor alpha.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        train_path: Path to CSV file containing training set.</span><br><span class="hljs-string">        valid_path: Path to CSV file containing validation set.</span><br><span class="hljs-string">        test_path: Path to CSV file containing test set.</span><br><span class="hljs-string">        pred_path: Path to save predictions.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    pred_path_c = pred_path.replace(WILDCARD, <span class="hljs-string">&#x27;c&#x27;</span>)<br>    pred_path_d = pred_path.replace(WILDCARD, <span class="hljs-string">&#x27;d&#x27;</span>)<br>    pred_path_e = pred_path.replace(WILDCARD, <span class="hljs-string">&#x27;e&#x27;</span>)<br><br>    <span class="hljs-comment"># *** START CODE HERE ***</span><br>    <span class="hljs-comment">#######################################################################################</span><br>    <span class="hljs-comment"># Problem (c)</span><br>    x_train, t_train = util.load_dataset(train_path, label_col=<span class="hljs-string">&#x27;t&#x27;</span>, add_intercept=<span class="hljs-literal">True</span>)<br>    x_test, t_test = util.load_dataset(test_path, label_col=<span class="hljs-string">&#x27;t&#x27;</span>, add_intercept=<span class="hljs-literal">True</span>)<br><br>    model_t = LogisticRegression()<br>    model_t.fit(x_train, t_train)<br><br>    util.plot(x_test, t_test, model_t.theta, <span class="hljs-string">&#x27;output/p02c.png&#x27;</span>)<br><br>    t_pred_c = model_t.predict(x_test)<br>    np.savetxt(pred_path_c, t_pred_c &gt; <span class="hljs-number">0.5</span>, fmt=<span class="hljs-string">&#x27;%d&#x27;</span>)<br>    <span class="hljs-comment">#######################################################################################</span><br>    <span class="hljs-comment"># Problem (d)</span><br>    x_train, y_train = util.load_dataset(train_path, label_col=<span class="hljs-string">&#x27;y&#x27;</span>, add_intercept=<span class="hljs-literal">True</span>)<br>    x_test, y_test = util.load_dataset(test_path, label_col=<span class="hljs-string">&#x27;y&#x27;</span>, add_intercept=<span class="hljs-literal">True</span>)<br><br>    model_y = LogisticRegression()<br>    model_y.fit(x_train, y_train)<br><br>    util.plot(x_test, y_test, model_y.theta, <span class="hljs-string">&#x27;output/p02d.png&#x27;</span>)<br><br>    y_pred = model_y.predict(x_test)<br>    np.savetxt(pred_path_d, y_pred &gt; <span class="hljs-number">0.5</span>, fmt=<span class="hljs-string">&#x27;%d&#x27;</span>)<br>    <span class="hljs-comment">#######################################################################################  </span><br>    <span class="hljs-comment"># Problem (e)</span><br>    x_valid, y_valid = util.load_dataset(valid_path, label_col=<span class="hljs-string">&#x27;y&#x27;</span>, add_intercept=<span class="hljs-literal">True</span>)<br><br>    alpha = np.mean(model_y.predict(x_valid))<br><br>    correction = <span class="hljs-number">1</span> + np.log(<span class="hljs-number">2</span> / alpha - <span class="hljs-number">1</span>) / model_y.theta[<span class="hljs-number">0</span>]<br>    util.plot(x_test, t_test, model_y.theta, <span class="hljs-string">&#x27;output/p02e.png&#x27;</span>, correction)<br><br>    t_pred_e = y_pred / alpha<br>    np.savetxt(pred_path_e, t_pred_e &gt; <span class="hljs-number">0.5</span>, fmt=<span class="hljs-string">&#x27;%d&#x27;</span>)<br>    <span class="hljs-comment">#######################################################################################</span><br>    <span class="hljs-comment"># *** END CODER HERE</span><br><br></code></pre></td></tr></table></figure><h2 id="problem-3">Problem 3</h2><h3 id="sub-problem-a-2">Sub Problem (a)</h3><p>Poisson distribution can be written as： <span class="math display">\[p(y;\lambda) = \frac{1}{y!}exp\{ylog\lambda - \lambda\}\]</span> For the parameters in exponential family： <span class="math display">\[b(y) = \frac{1}{y!}\\\eta = log\lambda\\T(y) = y \\\alpha(\eta) = \exp\{\eta\}\]</span> Proof finished.</p><h3 id="sub-problem-b-2">Sub Problem (b)</h3><p><span class="math display">\[h_{\theta}(x) = \lambda = exp\{\theta^Tx\}\]</span></p><h3 id="sub-problem-c-1">Sub Problem (c)</h3><p><span class="math display">\[log\,p(y^{(i)}|x^{(i)};\theta) =log\,\frac{1}{y^{(i)}!}exp\{\theta^Tx^{(i)}y^{(i)} -exp\{\theta^Tx^{(i)}\}\} \\\]</span></p><p>So we take the derivative of <span class="math inline">\(\theta_j\)</span>： <span class="math display">\[\frac{\partial  log\,p(y^{(i)}|x^{(i)};\theta)}{\partial  \theta_j} =x_{j}^{(i)}y^{(i)} - x_{j}^{(i)}exp\{\theta^Tx^{(i)}\}\]</span> The adjustment to the <span class="math inline">\(\theta_j\)</span> is： <span class="math display">\[\theta_j = \theta_j + \alpha(x_{j}^{(i)}y^{(i)} -x_{j}^{(i)}exp\{\theta^Tx^{(i)}\})\]</span></p><h3 id="sub-problem-d-1">Sub Problem (d)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> util<br><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">from</span> linear_model <span class="hljs-keyword">import</span> LinearModel<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">lr, train_path, eval_path, pred_path</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Problem 3(d): Poisson regression with gradient ascent.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        lr: Learning rate for gradient ascent.</span><br><span class="hljs-string">        train_path: Path to CSV file containing dataset for training.</span><br><span class="hljs-string">        eval_path: Path to CSV file containing dataset for evaluation.</span><br><span class="hljs-string">        pred_path: Path to save predictions.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># Load training set</span><br>    x_train, y_train = util.load_dataset(train_path, add_intercept=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># *** START CODE HERE ***</span><br>    model = PoissonRegression(step_size=lr,eps=<span class="hljs-number">1e-5</span>)<br>    model.fit(x_train, y_train)<br>    x_out,y_out = util.load_dataset(eval_path, add_intercept=<span class="hljs-literal">True</span>)<br>    prediction = model.predict(x_out)<br>    np.savetxt(pred_path,prediction &gt; <span class="hljs-number">0.5</span>, fmt=<span class="hljs-string">&#x27;%d&#x27;</span>)<br>    plt.figure()<br>    plt.plot(y_out,prediction,<span class="hljs-string">&#x27;bx&#x27;</span>)<br>    plt.xlabel(<span class="hljs-string">&#x27;True data&#x27;</span>)<br>    plt.ylabel(<span class="hljs-string">&#x27;Predict data&#x27;</span>)<br>    plt.savefig(<span class="hljs-string">&#x27;p03d.png&#x27;</span>)<br>    <span class="hljs-comment"># *** END CODE HERE ***</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">PoissonRegression</span>(<span class="hljs-title class_ inherited__">LinearModel</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Poisson Regression.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Example usage:</span><br><span class="hljs-string">        &gt; clf = PoissonRegression(step_size=lr)</span><br><span class="hljs-string">        &gt; clf.fit(x_train, y_train)</span><br><span class="hljs-string">        &gt; clf.predict(x_eval)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, x, y</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Run gradient ascent to maximize likelihood for Poisson regression.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x: Training example inputs. Shape (m, n).</span><br><span class="hljs-string">            y: Training example labels. Shape (m,).</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># *** START CODE HERE ***</span><br>        m,n = x.shape<br>        self.theta = np.zeros(n)<br>        <span class="hljs-keyword">while</span> <span class="hljs-literal">True</span>:<br>            theta = np.copy(self.theta)<br>            self.theta += self.step_size * (x.T.dot(y) - x.T.dot(np.exp(x.dot(self.theta))))<br>            <span class="hljs-keyword">if</span> np.linalg.norm(self.theta - theta,<span class="hljs-built_in">ord</span>=<span class="hljs-number">1</span>) &lt; self.eps:<br>                <span class="hljs-keyword">break</span><br>        <span class="hljs-comment"># *** END CODE HERE ***</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Make a prediction given inputs x.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x: Inputs of shape (m, n).</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            Floating-point prediction for each input, shape (m,).</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># *** START CODE HERE ***</span><br>        <span class="hljs-keyword">return</span> np.exp(x.dot(self.theta))<br>        <span class="hljs-comment"># *** END CODE HERE ***</span><br><br></code></pre></td></tr></table></figure><h2 id="problem-4">Problem 4</h2><h3 id="sub-problem-a-3">Sub Problem (a)</h3><p>Start with the hint： <span class="math display">\[\frac{\partial }{\partial  \eta} \int p(y;\eta)dy = \int \frac{\partial}{\partial  \eta}p(y;\eta)dy = 0\\\int \frac{\partial }{\partial  \eta}p(y;\eta)dy = \int b(y)(T(y) -\frac{\partial  \alpha(\eta)}{\partial  \eta})exp\{\eta^TT(y) -\alpha(\eta)\} \\= \int (T(y) -\frac{\partial  \alpha(\eta)}{\partial  \eta})p(y;\eta)dy\\T(y) = y \\\int yp(y;\eta)dy = \frac{\partial  \alpha(\eta)}{\partial  \eta}\intp(y;\eta)dy = \frac{\partial  \alpha(\eta)}{\partial  \eta}\\E(Y|X;\eta) = E(Y;\eta) = \frac{\partial  \alpha(\eta)}{\partial  \eta}\]</span> Proof finished.</p><h3 id="sub-problem-b-3">Sub Problem (b)</h3><p>From the hint in sub problem (a) and the sub problem (a) itself，wecan derivate： <span class="math display">\[\frac{\partial }{\partial  \eta}\int yp(y;\eta)dy = \frac{\partial^2}{\partial  \eta^2}\alpha(\eta) \\\frac{\partial }{\partial  \eta}\int yp(y;\eta)dy = \int \frac{\partial}{\partial  \eta}(yp(y;\eta))dy \\= \int y(y\, -\,\frac{\partial  \alpha(\eta)}{\partial  \eta})p(y;\eta)dy \\= E(Y^2;\eta) - (E(Y;\eta))^2 \\= \frac{\partial ^2}{\partial  \eta^2}\alpha(\eta)\]</span> So the variance is： <span class="math display">\[Var(Y|X;\eta) = Var(Y;\eta) = E(Y^2;\eta) - (E(Y;\eta))^2= \frac{\partial ^2}{\partial  \eta^2}\alpha(\eta)\]</span></p><h3 id="sub-problem-c-2">Sub Problem (c)</h3><p><span class="math display">\[\ell(\theta) = -\sum_{i = 1}^{m}log(p(y^{(i)}|x^{(i)};\theta)) \\= -\sum_{i = 1}^{m}(log(b(y)\, + \,(\eta^TT(y) \, - \,\alpha(\eta)))\]</span></p><p>So the derivative is： <span class="math display">\[\frac{\partial  \ell (\theta)}{\partial  \theta_j} = \sum_{i =1}^{m}x_{j}^{(i)}\frac{\partial  \alpha(\theta^Tx)}{\partial  \theta_j}- x_j^{(i)}y^{(i)}\]</span> The positive definiteness has been proved before, so we don'tprove again.</p><h2 id="problem-5">Problem 5</h2><h3 id="sub-problem-a-4">Sub Problem (a)</h3><h4 id="problem-i">problem i</h4><p>Vectorize the <span class="math inline">\(X,Y,\theta\)</span>，and wedefine the weight matrix： <span class="math display">\[W_{ij} = \frac{1}{2}w^{(i)} \;(i = j)\\W_{ij} = 0\;\;(i \neq j)\]</span> So it can be easily proved.</p><h4 id="problem-ii">problem ii</h4><p><span class="math display">\[\bigtriangledown_{\theta}J(\theta) =\bigtriangledown_{\theta}(\theta^TX^TWX\theta - y^TWX\theta -\theta^TX^TWy + y^TWy) \\= \bigtriangledown_{\theta}(\theta^TX^TWX\theta - 2y^TWX\theta)\\= 2X^TWX\theta - 2y^TWX = 0\]</span></p><p>So the learning parameter vector <span class="math inline">\(\theta\)</span> is： <span class="math display">\[\theta = (X^TWX)^{-1}y^TWX\]</span></p><h4 id="problem-iii">problem iii</h4><p><span class="math display">\[\frac{\partial  \ell(\theta)}{\partial  \theta_j} = \sum_{i =1}^{m}-\frac{(y^{(i)} - \theta^Tx^{(i)})}{(\sigma^{(i)})^2}x_{j}^{(i)}\]</span></p><p>So it is a weighted gradient descent, and the weight is about thevariance <span class="math inline">\(\sigma\)</span></p><h3 id="sub-problem-b-4">Sub Problem (b)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> util<br><br><span class="hljs-keyword">from</span> linear_model <span class="hljs-keyword">import</span> LinearModel<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">tau, train_path, eval_path</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Problem 5(b): Locally weighted regression (LWR)</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        tau: Bandwidth parameter for LWR.</span><br><span class="hljs-string">        train_path: Path to CSV file containing dataset for training.</span><br><span class="hljs-string">        eval_path: Path to CSV file containing dataset for evaluation.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># Load training set</span><br>    x_train, y_train = util.load_dataset(train_path, add_intercept=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># *** START CODE HERE ***</span><br>    <span class="hljs-comment"># Fit a LWR model</span><br>    <span class="hljs-comment"># Get MSE value on the validation set</span><br>    <span class="hljs-comment"># Plot validation predictions on top of training set</span><br>    <span class="hljs-comment"># No need to save predictions</span><br>    <span class="hljs-comment"># Plot data</span><br>    <span class="hljs-comment"># *** END CODE HERE ***</span><br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">LocallyWeightedLinearRegression</span>(<span class="hljs-title class_ inherited__">LinearModel</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Locally Weighted Regression (LWR).</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Example usage:</span><br><span class="hljs-string">        &gt; clf = LocallyWeightedLinearRegression(tau)</span><br><span class="hljs-string">        &gt; clf.fit(x_train, y_train)</span><br><span class="hljs-string">        &gt; clf.predict(x_eval)</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, tau</span>):<br>        <span class="hljs-built_in">super</span>(LocallyWeightedLinearRegression, self).__init__()<br>        self.tau = tau<br>        self.x = <span class="hljs-literal">None</span><br>        self.y = <span class="hljs-literal">None</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">fit</span>(<span class="hljs-params">self, x, y</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Fit LWR by saving the training set.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># *** START CODE HERE ***</span><br>        self.x,self.y = x,y<br>        <span class="hljs-comment"># *** END CODE HERE ***</span><br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">predict</span>(<span class="hljs-params">self, x</span>):<br>        <span class="hljs-string">&quot;&quot;&quot;Make predictions given inputs x.</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Args:</span><br><span class="hljs-string">            x: Inputs of shape (m, n).</span><br><span class="hljs-string"></span><br><span class="hljs-string">        Returns:</span><br><span class="hljs-string">            Outputs of shape (m,).</span><br><span class="hljs-string">        &quot;&quot;&quot;</span><br>        <span class="hljs-comment"># *** START CODE HERE ***</span><br>        m,n = x.shape<br>        pred = np.zeros(n)<br>        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(m):<br>            Weight = np.diag(np.exp(-np.<span class="hljs-built_in">sum</span>(self.x - x[i]) ** <span class="hljs-number">2</span>,axis=<span class="hljs-number">1</span>) / (<span class="hljs-number">2</span> * (self.tau ** <span class="hljs-number">2</span>)))<br>            pred[i] = np.linalg.inv(self.x.T.dot(Weight).dot(self.x)).dot(self.x.T).dot(Weight).dot(self.y).T.dot(x[i])<br>        <span class="hljs-keyword">return</span> pred<br>        <span class="hljs-comment"># *** END CODE HERE ***</span><br><br></code></pre></td></tr></table></figure><h3 id="sub-problem-c-3">Sub Problem (c)</h3><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> matplotlib.pyplot <span class="hljs-keyword">as</span> plt<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br><span class="hljs-keyword">import</span> util<br><br><span class="hljs-keyword">from</span> p05b_lwr <span class="hljs-keyword">import</span> LocallyWeightedLinearRegression<br><br><br><span class="hljs-keyword">def</span> <span class="hljs-title function_">main</span>(<span class="hljs-params">tau_values, train_path, valid_path, test_path, pred_path</span>):<br>    <span class="hljs-string">&quot;&quot;&quot;Problem 5(b): Tune the bandwidth paramater tau for LWR.</span><br><span class="hljs-string"></span><br><span class="hljs-string">    Args:</span><br><span class="hljs-string">        tau_values: List of tau values to try.</span><br><span class="hljs-string">        train_path: Path to CSV file containing training set.</span><br><span class="hljs-string">        valid_path: Path to CSV file containing validation set.</span><br><span class="hljs-string">        test_path: Path to CSV file containing test set.</span><br><span class="hljs-string">        pred_path: Path to save predictions.</span><br><span class="hljs-string">    &quot;&quot;&quot;</span><br>    <span class="hljs-comment"># Load training set</span><br>    x_train, y_train = util.load_dataset(train_path, add_intercept=<span class="hljs-literal">True</span>)<br><br>    <span class="hljs-comment"># *** START CODE HERE ***</span><br>    <span class="hljs-comment"># Search tau_values for the best tau (lowest MSE on the validation set)</span><br>    <span class="hljs-comment"># Fit a LWR model with the best tau value</span><br>    <span class="hljs-comment"># Run on the test set to get the MSE value</span><br>    <span class="hljs-comment"># Save predictions to pred_path</span><br>    <span class="hljs-comment"># Plot data</span><br>    x_eval, y_eval = util.load_dataset(valid_path, add_intercept=<span class="hljs-literal">True</span>)<br>    x_test, y_test = util.load_dataset(test_path, add_intercept=<span class="hljs-literal">True</span>)<br>    model = LocallyWeightedLinearRegression(tau=<span class="hljs-number">0.5</span>)<br>    model.fit(x_train, y_train)<br>    MSE = []<br>    <span class="hljs-keyword">for</span> tau <span class="hljs-keyword">in</span> tau_values:<br>        model.tau = tau<br>        pred = model.predict(x_eval)<br>        squared_estimate = np.mean((pred - y_eval) ** <span class="hljs-number">2</span>)<br>        MSE.append(squared_estimate)<br>        <br>        plt.figure()<br>        plt.title(<span class="hljs-string">&#x27;tau = &#123;&#125;&#x27;</span>.<span class="hljs-built_in">format</span>(tau))<br>        plt.plot(x_train, y_train, <span class="hljs-string">&#x27;bx&#x27;</span>, linewidth=<span class="hljs-number">2</span>)<br>        plt.plot(x_eval, pred, <span class="hljs-string">&#x27;ro&#x27;</span>, linewidth=<span class="hljs-number">2</span>)<br>        plt.xlabel(<span class="hljs-string">&#x27;x&#x27;</span>)<br>        plt.ylabel(<span class="hljs-string">&#x27;y&#x27;</span>)<br>        plt.savefig(<span class="hljs-string">&#x27;p05c_tau_&#123;&#125;.png&#x27;</span>.<span class="hljs-built_in">format</span>(tau))<br><br>    tau_output = tau_values[np.argmin(MSE)]<br>    model.tau = tau_output<br>    pred = model.predict(x_test)<br>    np.savetxt(pred_path,pred)<br>    mse = np.mean((pred - y_eval) ** <span class="hljs-number">2</span>)<br><br><br>    <span class="hljs-comment"># *** END CODE HERE ***</span><br><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>machine learning</category>
      
      <category>CS229</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CS229</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Chap2 灰度变换与空间滤波</title>
    <link href="/2022/04/11/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/chap2/"/>
    <url>/2022/04/11/%E6%95%B0%E5%AD%97%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86/chap2/</url>
    
    <content type="html"><![CDATA[<h2 id="灰度变换函数">灰度变换函数</h2><h3 id="imadjust-和-stretchlim">imadjust 和 stretchlim</h3><p>函数imadjust是一个基本的图像处理函数工具箱函数，语法格式为：</p><figure class="highlight matlab"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs matlab">g = imadjust(f,[low_in high_in], [low_out high_out], <span class="hljs-built_in">gamma</span><br></code></pre></td></tr></table></figure><p>将处在[low_outhigh_out]区间的灰度值直接映射，其余值在区间端点截断</p><p>eg：明暗反转</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab">g1 = imadjust(f,[<span class="hljs-number">0</span>,<span class="hljs-number">1</span>],[<span class="hljs-number">1</span> <span class="hljs-number">0</span>])<br></code></pre></td></tr></table></figure><p>有时能够自动地使用函数imadjust而不必关心上面讨论的低参数或者高参数是非常有用的。这时可使用函数strechlim，其基本语法为</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs matlab">Low_High = strechlim(f)<br><span class="hljs-comment">% 返回一个二元向量，用于实现对比度拉伸，增强原图对比度</span><br></code></pre></td></tr></table></figure><h3 id="对数及对比度拉伸变换">对数及对比度拉伸变换</h3><p>对数和对比度拉伸变换是动态范围运算基本工具。对数变换通过如下表达式实现：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab">g = c * <span class="hljs-built_in">log</span>(<span class="hljs-number">1</span> + f)<br></code></pre></td></tr></table></figure><p>主要应用是压缩动态范围。例如当傅里叶频谱的取值区间为[0,10e6]或更高时，高值部分占优势，低灰度值的可见细节部分易丢失，通过计算对数让其变得更易处理</p><p>执行对数变换时，我们希望使得压缩值出现在显示的完整范围内，例如8bit:</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab">gs = im2uint8(mat2gray(g));<br></code></pre></td></tr></table></figure><p>matgray()限制到区间[0,1]，im2uint8先知道[0,255]</p><p>sigmoid函数是对比度拉伸变换函数 <span class="math display">\[s = T(r) = \frac{1}{1 + (\frac{m}{r})^E}\]</span></p><ul><li>r为输入图像的灰度</li><li>s是输出图像的相应灰度值</li><li>E来控制该函数的斜率</li></ul><p>实现：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs matlab">g = im2uint8(mat2gray(<span class="hljs-built_in">log</span>(<span class="hljs-number">1</span> + double(f))));<br>imshow(g)<br></code></pre></td></tr></table></figure><h3 id="指定任意灰度变换">指定任意灰度变换</h3><p>设T()是一个列向量，表示变换函数</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs matlab">g = interp1(z,T,f);<br></code></pre></td></tr></table></figure><p>f为输入图像，g为输出图像，T为前述列向量，z是一个长度与T相同的列向量，形成方式如下：</p><figure class="highlight matlab"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs matlab">z = <span class="hljs-built_in">linspace</span>(<span class="hljs-number">0</span>,<span class="hljs-number">1</span>,<span class="hljs-built_in">numel</span>(T));<br><span class="hljs-comment">%该函数在a,b(前两个参数构成的区间)进行线性间隔取值</span><br></code></pre></td></tr></table></figure><p>对f中的一个像素值，interp1先寻找横坐标值z，然后寻找T中的相应值，并将找到的内插值输出到g</p><figure><img src="/.com//1.1.png" alt="test"><figcaption aria-hidden="true">test</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>数字图像处理</category>
      
    </categories>
    
    
    <tags>
      
      <tag>数字图像处理</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>博客构建日记</title>
    <link href="/2022/04/10/log/"/>
    <url>/2022/04/10/log/</url>
    
    <content type="html"><![CDATA[<h3 id="section">2022/4/10</h3><p>本站点初步搭建配置完成</p>]]></content>
    
    
    
  </entry>
  
  
  
  <entry>
    <title>CSAPP datalab总结</title>
    <link href="/2022/04/10/CSAPP/datalab/"/>
    <url>/2022/04/10/CSAPP/datalab/</url>
    
    <content type="html"><![CDATA[<p>本文介绍CSAPP中datalab各小题的解题步骤</p><h2 id="int-and-boolean-algebra">Int and boolean algebra</h2><h4 id="bitxor">bitXor</h4><figure class="highlight c"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></div></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * bitXor - x^y using only ~ and &amp; </span><br><span class="hljs-comment"> *   Example: bitXor(4, 5) = 1</span><br><span class="hljs-comment"> *   Legal ops: ~ &amp;</span><br><span class="hljs-comment"> *   Max ops: 14</span><br><span class="hljs-comment"> *   Rating: 1</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">bitXor</span><span class="hljs-params">(<span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y)</span> &#123;<br>  <span class="hljs-keyword">return</span> (~x) &amp; y | x &amp; (~y);<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>题目要求:</strong> 用&amp;和~实现^</p><p><strong>思路:</strong> 异或运算，即x与y不同时结果为1，(~x) &amp;y能够使得结果中x为0，y为1的情况，而x &amp;(~y)则处理x为1，y为0的情况，两结果的并即可实现x^y</p><h4 id="tmin">tmin</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * tmin - return minimum two&#x27;s complement integer </span><br><span class="hljs-comment"> *   Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</span><br><span class="hljs-comment"> *   Max ops: 4</span><br><span class="hljs-comment"> *   Rating: 1</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">tmin</span><span class="hljs-params">(<span class="hljs-type">void</span>)</span> &#123;<br><br>  <span class="hljs-keyword">return</span> <span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">31</span>;<br><br>&#125;<br></code></pre></td></tr></table></figure><p><strong>题目要求:</strong> 求最小的二进制补码int</p><p><strong>思路:</strong> 直接用1 &lt;&lt; 31即可</p><h4 id="istmax">isTmax</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * isTmax - returns 1 if x is the maximum, two&#x27;s complement number,</span><br><span class="hljs-comment"> *     and 0 otherwise </span><br><span class="hljs-comment"> *   Legal ops: ! ~ &amp; ^ | +</span><br><span class="hljs-comment"> *   Max ops: 10</span><br><span class="hljs-comment"> *   Rating: 1</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">isTmax</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>  <span class="hljs-keyword">return</span> !(~(x + <span class="hljs-number">1</span> + x)) &amp; !!(~x);<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>题目要求:</strong> 若<span class="math inline">\(x=0x80000000u\)</span>则返回1，否则返回0</p><p><strong>思路：</strong> 观察<span class="math inline">\(0x80000000\)</span>​u的特点，只有首位为1，且左移一位后就变为0，注意到左移1位后为0除<span class="math inline">\(0x80000000\)</span>外只有0，故再排除0即可</p><h4 id="alloddbits">allOddBits</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * allOddBits - return 1 if all odd-numbered bits in word set to 1</span><br><span class="hljs-comment"> *   where bits are numbered from 0 (least significant) to 31 (most significant)</span><br><span class="hljs-comment"> *   Examples allOddBits(0xFFFFFFFD) = 0, allOddBits(0xAAAAAAAA) = 1</span><br><span class="hljs-comment"> *   Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</span><br><span class="hljs-comment"> *   Max ops: 12</span><br><span class="hljs-comment"> *   Rating: 2</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">allOddBits</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>  <span class="hljs-type">int</span> mask = <span class="hljs-number">0xAA</span>+(<span class="hljs-number">0xAA</span>&lt;&lt;<span class="hljs-number">8</span>);<br>  mask=mask+(mask&lt;&lt;<span class="hljs-number">16</span>);<br>  <span class="hljs-keyword">return</span> !((mask&amp;x)^mask);<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>题目要求:</strong> 若参数x的奇数位都是1则返回1，否则返回0</p><p><strong>思路:</strong> 先构造一个奇数位全部为1的<span class="math inline">\(mask=0xAAAAAAAA\)</span>​​​，然后x与mask做与运算，当且仅当x奇数位均为1时，<span class="math inline">\(x \&amp; mask =mask\)</span>​​​​，所以只有x奇数位均为1时，<span class="math inline">\(x\&amp; mask\)</span>​与mask的异或为0​​​，再取反即可完成</p><h4 id="negate">negate</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * negate - return -x </span><br><span class="hljs-comment"> *   Example: negate(1) = -1.</span><br><span class="hljs-comment"> *   Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</span><br><span class="hljs-comment"> *   Max ops: 5</span><br><span class="hljs-comment"> *   Rating: 2</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">negate</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>  <span class="hljs-keyword">return</span> (~x) + <span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>题目要求:</strong> 返回参数的相反数</p><p><strong>思路:</strong> 取反+1即可</p><h4 id="isasciidigit">isAsciiDigit</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * isAsciiDigit - return 1 if 0x30 &lt;= x &lt;= 0x39 (ASCII codes for characters &#x27;0&#x27; to &#x27;9&#x27;)</span><br><span class="hljs-comment"> *   Example: isAsciiDigit(0x35) = 1.</span><br><span class="hljs-comment"> *            isAsciiDigit(0x3a) = 0.</span><br><span class="hljs-comment"> *            isAsciiDigit(0x05) = 0.</span><br><span class="hljs-comment"> *   Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt; </span><br><span class="hljs-comment"> *   Max ops: 15</span><br><span class="hljs-comment"> *   Rating: 3</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">isAsciiDigit</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>  <span class="hljs-keyword">return</span> !((x + (~<span class="hljs-number">0x30</span>) + <span class="hljs-number">1</span>) &gt;&gt; <span class="hljs-number">31</span>) &amp; !((<span class="hljs-number">0x39</span> + (~x)+ <span class="hljs-number">1</span>) &gt;&gt; <span class="hljs-number">31</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>题目要求:</strong>若x是处于0-9之间的ASCII码(也就是0x30-0x39)则返回1，否则返回0</p><p><strong>思路:</strong> 由上一轮的取反得到灵感，本题中需要满足<span class="math inline">\(x - 0x30 \geq 0 \bigcap 0x39 - x \geq0\)</span>​​，​​判断两式首位符号位是否为0即可确定两式均大于等于0</p><h4 id="conditional">conditional</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * conditional - same as x ? y : z </span><br><span class="hljs-comment"> *   Example: conditional(2,4,5) = 4</span><br><span class="hljs-comment"> *   Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</span><br><span class="hljs-comment"> *   Max ops: 16</span><br><span class="hljs-comment"> *   Rating: 3</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">conditional</span><span class="hljs-params">(<span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y, <span class="hljs-type">int</span> z)</span> &#123;<br>  x = !!x;<br>  x = ~x + <span class="hljs-number">1</span>;<br>  <span class="hljs-keyword">return</span> (x &amp; y) | (~x &amp; z);<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>题目要求:</strong> 用给定运算符完成等同于三目运算符?:的作用</p><p><strong>思路:</strong>注意到关键点：-1的补码为0xFFFFFFFF，0的补码为0x00000000，且它们相互互为反码，所以对任意intx，有<span class="math inline">\(x \; \&amp; \; (-1) = x \; \bigcap \; x\; \&amp;\; 0 =0\)</span>​​​，所以对x调整，使得x为0的时候​，x可取z，x非0则取y，利用上述性质，先将任意非0的x调整为1，然后取-1，这两部操作对为0值的x则没有变化，然后利用此性质取最后一式即可</p><h4 id="islessorequal">isLessOrEqual</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * isLessOrEqual - if x &lt;= y  then return 1, else return 0 </span><br><span class="hljs-comment"> *   Example: isLessOrEqual(4,5) = 1.</span><br><span class="hljs-comment"> *   Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</span><br><span class="hljs-comment"> *   Max ops: 24</span><br><span class="hljs-comment"> *   Rating: 3</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">isLessOrEqual</span><span class="hljs-params">(<span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y)</span> &#123;<br>  <span class="hljs-type">int</span> b1 = x &gt;&gt; <span class="hljs-number">31</span>,b2 = y &gt;&gt; <span class="hljs-number">31</span>;<br>  x = x + ~(<span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">31</span>) + <span class="hljs-number">1</span>;<br>  y = y + ~(<span class="hljs-number">1</span> &lt;&lt; <span class="hljs-number">31</span>) + <span class="hljs-number">1</span>;<br>  <span class="hljs-type">int</span> NotbitXor = !(b1 ^ b2);<br>  <span class="hljs-comment">//printf(&quot;%d %d\n&quot;,!!(b1 ^ b2),!!(b1 &amp; (!b2)));</span><br>  <span class="hljs-keyword">return</span> (!NotbitXor) &amp; (b1 &gt;&gt; <span class="hljs-number">31</span>) | NotbitXor &amp; (!((y + (~x) + <span class="hljs-number">1</span>)&gt;&gt; <span class="hljs-number">31</span> &amp; <span class="hljs-number">1</span>));<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>题目要求:</strong> 给定int参数x，y：若<span class="math inline">\(\, x \leq y \,\)</span>​​则返回1，否则返回0</p><p><strong>思路:</strong> 最朴素的思路是<span class="math inline">\(\, y- x \geq 0\,\)</span>​​​然后判断结果的符号位是否为0，但是会出现问题在于当x，y均为负数时可能会发生溢出，导致结果出现偏差，所以要对两个参数的首位符号位进行分类讨论：若<span class="math inline">\(\, x[31] = 1\,\)</span>​​​且<span class="math inline">\(\, y[31] = 0\,\)</span>​​​时可直接判断；若<span class="math inline">\(\, x[31] = 1\,\)</span>​​​且<span class="math inline">\(\, y[31] =1\,\)</span>​​​时，比较剩余31位的大小，有<span class="math inline">\(\,y[30:0] \geq x[30:0]\,\)</span>​​​时结果为1；而若<span class="math inline">\(\, x[31] = 0\,\)</span>​​​且<span class="math inline">\(\, y[31] =0\,\)</span>​​​时，比较剩余31位的大小，有<span class="math inline">\(\,y[30:0] \leqx[30:0]\,\)</span>​​​​时结果为1，而这两种不同情况可以用同一个表达式判断，这样就在Maxops内得到了结果</p><h4 id="logicalneg">logicalNeg</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * logicalNeg - implement the ! operator, using all of </span><br><span class="hljs-comment"> *              the legal operators except !</span><br><span class="hljs-comment"> *   Examples: logicalNeg(3) = 0, logicalNeg(0) = 1</span><br><span class="hljs-comment"> *   Legal ops: ~ &amp; ^ | + &lt;&lt; &gt;&gt;</span><br><span class="hljs-comment"> *   Max ops: 12</span><br><span class="hljs-comment"> *   Rating: 4 </span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">logicalNeg</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>  <span class="hljs-keyword">return</span> ((x|(~x+<span class="hljs-number">1</span>))&gt;&gt;<span class="hljs-number">31</span>)+<span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>题目要求:</strong> 用所给符号实现!运算符</p><p><strong>思路:</strong>同conditional一题中得到的性质，只有0本身和其相反数的符号位均为0，利用此性质我们可以取x本身和-x的或的符号位（通过左移），这样若符号位非0，则取值为-1，再加1即可得到正确结果</p><h4 id="howmanybits">howManyBits</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* howManyBits - return the minimum number of bits required to represent x in</span><br><span class="hljs-comment"> *             two&#x27;s complement</span><br><span class="hljs-comment"> *  Examples: howManyBits(12) = 5</span><br><span class="hljs-comment"> *            howManyBits(298) = 10</span><br><span class="hljs-comment"> *            howManyBits(-5) = 4</span><br><span class="hljs-comment"> *            howManyBits(0)  = 1</span><br><span class="hljs-comment"> *            howManyBits(-1) = 1</span><br><span class="hljs-comment"> *            howManyBits(0x80000000) = 32</span><br><span class="hljs-comment"> *  Legal ops: ! ~ &amp; ^ | + &lt;&lt; &gt;&gt;</span><br><span class="hljs-comment"> *  Max ops: 90</span><br><span class="hljs-comment"> *  Rating: 4</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">howManyBits</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>  <span class="hljs-type">int</span> b16,b8,b4,b2,b1,b0;<br>  <span class="hljs-type">int</span> flag=x&gt;&gt;<span class="hljs-number">31</span>;<br>  x=(flag&amp;~x)|(~flag&amp;x);<br>  b16=!!(x&gt;&gt;<span class="hljs-number">16</span>) &lt;&lt;<span class="hljs-number">4</span>;<br>  x&gt;&gt;=b16;<br>  b8=!!(x&gt;&gt;<span class="hljs-number">8</span>)&lt;&lt;<span class="hljs-number">3</span>;<br>  x &gt;&gt;= b8;<br>  b4 = !!(x &gt;&gt; <span class="hljs-number">4</span>) &lt;&lt; <span class="hljs-number">2</span>;<br>  x &gt;&gt;= b4;<br>  b2 = !!(x &gt;&gt; <span class="hljs-number">2</span>) &lt;&lt; <span class="hljs-number">1</span>;<br>  x &gt;&gt;= b2;<br>  b1 = !!(x &gt;&gt; <span class="hljs-number">1</span>);<br>  x &gt;&gt;= b1;<br>  b0 = x;<br>  <span class="hljs-keyword">return</span> b0+b1+b2+b4+b8+b16+<span class="hljs-number">1</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>题目要求:</strong>在90个运算符内实现计算参数x的位数的功能</p><p><strong>思路:</strong>本题采用二分法的思想简化步骤，由题目逻辑，可将参数取绝对值(该操作对该数的最小位数表示的数值未进行改变)，然后寻找第一个1，再加上一表示符号位要占用1位即可</p><h2 id="float">Float</h2><h3 id="ieee-754-float-standard">IEEE 754 Float Standard</h3><p>本主题简略讲解本章中比较重要且容易忘记的一个内容: IEEE 浮点表示法</p><p>该表示法同科学计数法，由 <span class="math inline">\((-1)^{sign}\times (1 + frac)^{exp + 127}\)</span>​ 表示</p><p>需要注意的是，由于非0数必有1位为1，故我们为了省去一位的空间增加精度，默认非0数均存在首位为1，为了使exp尽可能取到最大的正值与负值，我们将其偏移127即可</p><p>一个float是一个长为32位的值，我们记为f[31:0]，其首位f[31]为符号位(signbit)，首位后8位f[30:23]为指数值，其余位f[22:0]为尾数位</p><p>当符号位，指数位，尾数位取值为不同情形时，表示的情况也不同：</p><ul><li><span class="math inline">\(exp = 0\; ,\; frac = 0\)</span>​​时表示0值</li><li><span class="math inline">\(exp = 0\; , \; frac \neq 0\)</span>​时表示正负非规格化数</li><li><span class="math inline">\(1 \leq exp \leq 254\; , \; frac \in\mathbb{N}\)</span>​ 时表示正负浮点数</li><li><span class="math inline">\(exp = 255\; , \; frac = 0\)</span>时表示正/负无穷</li><li><span class="math inline">\(exp = 255\; , \; frac \neq 0\)</span>时表示NaN</li></ul><h4 id="floatscale2">floatScale2</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * floatScale2 - Return bit-level equivalent of expression 2*f for</span><br><span class="hljs-comment"> *   floating point argument f.</span><br><span class="hljs-comment"> *   Both the argument and result are passed as unsigned int&#x27;s, but</span><br><span class="hljs-comment"> *   they are to be interpreted as the bit-level representation of</span><br><span class="hljs-comment"> *   single-precision floating point values.</span><br><span class="hljs-comment"> *   When argument is NaN, return argument</span><br><span class="hljs-comment"> *   Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. also if, while</span><br><span class="hljs-comment"> *   Max ops: 30</span><br><span class="hljs-comment"> *   Rating: 4</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">unsigned</span> <span class="hljs-title function_">floatScale2</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> uf)</span> &#123;<br>  <span class="hljs-type">int</span> <span class="hljs-built_in">exp</span> = (<span class="hljs-number">0x7f800000</span> &amp; uf) &gt;&gt; <span class="hljs-number">23</span>;<br>  <span class="hljs-type">int</span> sign = uf &amp; <span class="hljs-number">0x80000000</span>;<br>  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">exp</span> == <span class="hljs-number">0</span>)<br>    <span class="hljs-keyword">return</span> (uf &lt;&lt; <span class="hljs-number">1</span>) | sign;<br>  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">exp</span> == <span class="hljs-number">255</span>)<br>    <span class="hljs-keyword">return</span> uf;<br>  <span class="hljs-built_in">exp</span>++;<br>  <span class="hljs-keyword">if</span> (<span class="hljs-built_in">exp</span> == <span class="hljs-number">255</span>)<br>    <span class="hljs-keyword">return</span> (<span class="hljs-number">0x7f800000</span> | sign);<br>  <span class="hljs-keyword">return</span> (uf &amp; <span class="hljs-number">0x807fffff</span>) | (<span class="hljs-built_in">exp</span> &lt;&lt; <span class="hljs-number">23</span>);<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>题目要求:</strong>传入一个代表float的unsigned值uf，返回2*uf的结果</p><p><strong>思路:</strong> 由于要返回乘2的结果，我们只需给expbit加1即可，无须改动sign bit与fracbit的值，由此思路我们分别取出sign的值和exp的值，若exp=0，给frac左移一位即可；若exp=255(uf=inf)，则返回原数；若exp=254(2*uf=inf)，则返回NaN代表的值(根据sign决定是正/负无穷)；除此之外的情况，将改变后的exp放入原数的exp位置并返回即可</p><h4 id="floatfloat2int">floatFloat2Int</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * floatFloat2Int - Return bit-level equivalent of expression (int) f</span><br><span class="hljs-comment"> *   for floating point argument f.</span><br><span class="hljs-comment"> *   Argument is passed as unsigned int, but</span><br><span class="hljs-comment"> *   it is to be interpreted as the bit-level representation of a</span><br><span class="hljs-comment"> *   single-precision floating point value.</span><br><span class="hljs-comment"> *   Anything out of range (including NaN and infinity) should return</span><br><span class="hljs-comment"> *   0x80000000u.</span><br><span class="hljs-comment"> *   Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. also if, while</span><br><span class="hljs-comment"> *   Max ops: 30</span><br><span class="hljs-comment"> *   Rating: 4</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">floatFloat2Int</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> uf)</span> &#123;<br>  <span class="hljs-type">int</span> sign = uf &gt;&gt; <span class="hljs-number">31</span>;<br>  <span class="hljs-type">int</span> <span class="hljs-built_in">exp</span> = ((uf &amp; <span class="hljs-number">0x7f800000</span>) &gt;&gt; <span class="hljs-number">23</span>) - <span class="hljs-number">127</span>;<br>  <span class="hljs-type">int</span> frac = (uf&amp;<span class="hljs-number">0x007fffff</span>) | <span class="hljs-number">0x00800000</span>;<br>  <span class="hljs-keyword">if</span>(<span class="hljs-built_in">exp</span> &gt; <span class="hljs-number">31</span>)  <span class="hljs-keyword">return</span> <span class="hljs-number">0x80000000</span>;<br>  <span class="hljs-keyword">if</span>(<span class="hljs-built_in">exp</span> &lt; <span class="hljs-number">0</span> || !(uf&amp;<span class="hljs-number">0x7fffffff</span>)) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>  <span class="hljs-keyword">if</span>(<span class="hljs-built_in">exp</span> &gt; <span class="hljs-number">23</span>) frac = frac &lt;&lt; (<span class="hljs-built_in">exp</span> - <span class="hljs-number">23</span>);<br>  <span class="hljs-keyword">else</span> frac = frac &gt;&gt; (<span class="hljs-number">23</span> - <span class="hljs-built_in">exp</span>);<br>  <span class="hljs-keyword">if</span>(!((frac &gt;&gt; <span class="hljs-number">31</span> ^ sign))) <span class="hljs-keyword">return</span> frac;<br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(frac &gt;&gt; <span class="hljs-number">31</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0x80000000</span>;<br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">return</span> -frac;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>题目要求:</strong> 传入一个f的bit表示uf，返回该数的int值(相当于一个类型转换)</p><p><strong>思路:</strong> 将该数分解成sign bit/exp bit/fracbit，若exp大于31，则int溢出无法表示，故按题目要求返回0x80000000；若exp&lt; 0或原数的exp和frac位均为0，则按题目要求返回0；若exp &gt;23，先处理frac，将frac右移exp -23位(这样可以和后面处理正常位数同时处理)；还剩一种<span class="math inline">\(\, 0 \leq exp \leq23\,\)</span>​​的情况，与上一种处理方式相同；最后根据signbit分类讨论后输出即可。</p><h4 id="floatpower2">floatPower2</h4><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* </span><br><span class="hljs-comment"> * floatPower2 - Return bit-level equivalent of the expression 2.0^x</span><br><span class="hljs-comment"> *   (2.0 raised to the power x) for any 32-bit integer x.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> *   The unsigned value that is returned should have the identical bit</span><br><span class="hljs-comment"> *   representation as the single-precision floating-point number 2.0^x.</span><br><span class="hljs-comment"> *   If the result is too small to be represented as a denorm, return</span><br><span class="hljs-comment"> *   0. If too large, return +INF.</span><br><span class="hljs-comment"> * </span><br><span class="hljs-comment"> *   Legal ops: Any integer/unsigned operations incl. ||, &amp;&amp;. Also if, while </span><br><span class="hljs-comment"> *   Max ops: 30 </span><br><span class="hljs-comment"> *   Rating: 4</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">unsigned</span> <span class="hljs-title function_">floatPower2</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> &#123;<br>  <span class="hljs-keyword">if</span> (x &gt; <span class="hljs-number">127</span>)<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0x7f800000</span>;<br>  <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (x &lt; <span class="hljs-number">-127</span>)<br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0x0</span>;<br>  <span class="hljs-keyword">else</span><br>    <span class="hljs-keyword">return</span> (x + <span class="hljs-number">127</span>) &lt;&lt; <span class="hljs-number">23</span>;<br>&#125;<br></code></pre></td></tr></table></figure><p><strong>题目要求:</strong> 传入一个int参数x(floatbit表示下的指数值)，返回<span class="math inline">\(2^{x}\)</span>​的指数表示​​</p><p><strong>思路:</strong>若x大于127则溢出，返回+inf；若x小于-127，则过小无法表示，故返回0；当<span class="math inline">\(-127 &lt; x &lt;127\)</span>​，直接将x+127放入指数为并返回即可</p><h2 id="测试结果">测试结果</h2><figure><img src="/.com//CSAPP\write-ups\datalab\1.1.png" alt="test"><figcaption aria-hidden="true">test</figcaption></figure>]]></content>
    
    
    <categories>
      
      <category>计算机基础</category>
      
      <category>CSAPP</category>
      
    </categories>
    
    
    <tags>
      
      <tag>CSAPP</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Hello World</title>
    <link href="/2022/04/09/hello-world/"/>
    <url>/2022/04/09/hello-world/</url>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/">Hexo</a>! This is your veryfirst post. Check <a href="https://hexo.io/docs/">documentation</a> formore info. If you get any problems when using Hexo, you can find theanswer in <a href="https://hexo.io/docs/troubleshooting.html">troubleshooting</a> oryou can ask me on <a href="https://github.com/hexojs/hexo/issues">GitHub</a>.</p><h2 id="quick-start">Quick Start</h2><h3 id="create-a-new-post">Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><div class="code-wrapper"><pre><span class="line">1</span><br></pre></div></td><td class="code"><pre><code class="hljs bash">$ hexo new <span class="hljs-string">&quot;My New Post&quot;</span><br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html">Writing</a></p><h3 id="run-server">Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo server<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html">Server</a></p><h3 id="generate-static-files">Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo generate<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html">Generating</a></p><h3 id="deploy-to-remote-sites">Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ hexo deploy<br></code></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/one-command-deployment.html">Deployment</a></p><p><span class="math display">\[x \leq 1\]</span></p>]]></content>
    
    
    
  </entry>
  
  
  
  
</search>
